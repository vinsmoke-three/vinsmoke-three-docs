<!doctype html><html lang=ja class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=ChatGPTの仕組みを理解し、PyTorchを使ってGPTモデルをゼロから実装する詳細チュートリアル。Self-Attention、位置エンコーディング、重み初期化、テキスト生成アルゴリズムまで完全解説><meta name=author content=vinsmoke-three><link href=https://vinsmoke-three.com/LLM/05_Let%27s_build_GPT_from_scratch/ rel=canonical><link href=../04_the_huggingface_tokenizers_library/ rel=prev><link href=../06_the_huggingface_datasets_library/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.20"><title>GPTをゼロから構築する完全ガイド - Transformerアーキテクチャの実装と解説 - vinsmoke-three - 機械学習・深層学習ドキュメント</title><link rel=stylesheet href=../../assets/stylesheets/main.e53b48f4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-BXKYE0NT9N"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-BXKYE0NT9N",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-BXKYE0NT9N",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#gpt-transformer class=md-skip> コンテンツにスキップ </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=ヘッダー> <a href=../.. title="vinsmoke-three - 機械学習・深層学習ドキュメント" class="md-header__button md-logo" aria-label="vinsmoke-three - 機械学習・深層学習ドキュメント" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 14.27 10.64 13A11.24 11.24 0 0 0 5 10.18v6.95c2.61.34 5 1.34 7 2.82 2-1.48 4.39-2.48 7-2.82v-6.95c-2.16.39-4.09 1.39-5.64 2.82M19 8.15c.65-.1 1.32-.15 2-.15v11c-3.5 0-6.64 1.35-9 3.54C9.64 20.35 6.5 19 3 19V8c.68 0 1.35.05 2 .15 2.69.41 5.1 1.63 7 3.39 1.9-1.76 4.31-2.98 7-3.39M12 6c.27 0 .5-.1.71-.29.19-.21.29-.44.29-.71s-.1-.5-.29-.71C12.5 4.11 12.27 4 12 4s-.5.11-.71.29c-.18.21-.29.45-.29.71s.11.5.29.71c.21.19.45.29.71.29m2.12 1.12a2.997 2.997 0 1 1-4.24-4.24 2.997 2.997 0 1 1 4.24 4.24"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> vinsmoke-three - 機械学習・深層学習ドキュメント </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> GPTをゼロから構築する完全ガイド - Transformerアーキテクチャの実装と解説 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=検索 placeholder=検索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=検索> <a href=javascript:void(0) class="md-search__icon md-icon" title=共有 aria-label=共有 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=クリア aria-label=クリア tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 検索を初期化 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=タブ data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../PyTorch/00_setup/ class=md-tabs__link> PyTorch </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../00_illustrated_transformer/ class=md-tabs__link> LLM </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=ナビゲーション data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="vinsmoke-three - 機械学習・深層学習ドキュメント" class="md-nav__button md-logo" aria-label="vinsmoke-three - 機械学習・深層学習ドキュメント" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 14.27 10.64 13A11.24 11.24 0 0 0 5 10.18v6.95c2.61.34 5 1.34 7 2.82 2-1.48 4.39-2.48 7-2.82v-6.95c-2.16.39-4.09 1.39-5.64 2.82M19 8.15c.65-.1 1.32-.15 2-.15v11c-3.5 0-6.64 1.35-9 3.54C9.64 20.35 6.5 19 3 19V8c.68 0 1.35.05 2 .15 2.69.41 5.1 1.63 7 3.39 1.9-1.76 4.31-2.98 7-3.39M12 6c.27 0 .5-.1.71-.29.19-.21.29-.44.29-.71s-.1-.5-.29-.71C12.5 4.11 12.27 4 12 4s-.5.11-.71.29c-.18.21-.29.45-.29.71s.11.5.29.71c.21.19.45.29.71.29m2.12 1.12a2.997 2.997 0 1 1-4.24-4.24 2.997 2.997 0 1 1 4.24 4.24"/></svg> </a> vinsmoke-three - 機械学習・深層学習ドキュメント </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> PyTorch </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> PyTorch </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../PyTorch/00_setup/ class=md-nav__link> <span class=md-ellipsis> 0. setup </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/01_pytorch_fundamentals/ class=md-nav__link> <span class=md-ellipsis> 1. PyTorch fundamentals </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/02_pytorch_workflow/ class=md-nav__link> <span class=md-ellipsis> 2. PyTorch workflow </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/03_pytorch_classification/ class=md-nav__link> <span class=md-ellipsis> 3. PyTorch classification </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/04_pytorch_computer_vision/ class=md-nav__link> <span class=md-ellipsis> 4. PyTorch computer vision </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/05_pytorch_custom_datasets/ class=md-nav__link> <span class=md-ellipsis> 5. PyTorch custom datasets </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/06_pytorch_modular/ class=md-nav__link> <span class=md-ellipsis> 6. PyTorch modular </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/07_pytorch_transfer_learning/ class=md-nav__link> <span class=md-ellipsis> 7. PyTorch transfer learning </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/08_pytorch_experiment_tracking/ class=md-nav__link> <span class=md-ellipsis> 8. PyTorch experiment tracking </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/09_pytorch_paper_replicating/ class=md-nav__link> <span class=md-ellipsis> 9. PyTorch paper replicating </span> </a> </li> <li class=md-nav__item> <a href=../../PyTorch/10_pytorch_model_deployment/ class=md-nav__link> <span class=md-ellipsis> 10. PyTorch model deployment </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> LLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../00_illustrated_transformer/ class=md-nav__link> <span class=md-ellipsis> 0. The illustrated transformer </span> </a> </li> <li class=md-nav__item> <a href=../01_transformer_models/ class=md-nav__link> <span class=md-ellipsis> 1. Transformer models </span> </a> </li> <li class=md-nav__item> <a href=../02_using_transformers/ class=md-nav__link> <span class=md-ellipsis> 2. Using transformers </span> </a> </li> <li class=md-nav__item> <a href=../03_fine_tuning_a_pretrained_model/ class=md-nav__link> <span class=md-ellipsis> 3. Fine-tuning a pretrained model </span> </a> </li> <li class=md-nav__item> <a href=../04_the_huggingface_tokenizers_library/ class=md-nav__link> <span class=md-ellipsis> 4. Tokenizers library </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 5. Let't build GPT from scratch </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 5. Let't build GPT from scratch </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目次> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目次 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 概要 </span> </a> </li> <li class=md-nav__item> <a href=#1 class=md-nav__link> <span class=md-ellipsis> 1. 言語モデリングの基礎と開発環境構築 </span> </a> </li> <li class=md-nav__item> <a href=#2 class=md-nav__link> <span class=md-ellipsis> 2. データセットの準備とトークン化 </span> </a> </li> <li class=md-nav__item> <a href=#3 class=md-nav__link> <span class=md-ellipsis> 3. バッチ処理とベースラインモデル </span> </a> </li> <li class=md-nav__item> <a href=#4-self-attention class=md-nav__link> <span class=md-ellipsis> 4. Self-Attentionメカニズムの構築 </span> </a> </li> <li class=md-nav__item> <a href=#5-transformer class=md-nav__link> <span class=md-ellipsis> 5. マルチヘッドアテンションとTransformerブロック </span> </a> </li> <li class=md-nav__item> <a href=#6-gpt class=md-nav__link> <span class=md-ellipsis> 6. 完全なGPTモデルの構築 </span> </a> </li> <li class=md-nav__item> <a href=#7 class=md-nav__link> <span class=md-ellipsis> 7. 最終実装とテキスト生成 </span> </a> </li> <li class=md-nav__item> <a href=#8 class=md-nav__link> <span class=md-ellipsis> 8. 参考資料 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../06_the_huggingface_datasets_library/ class=md-nav__link> <span class=md-ellipsis> 6. Datasets library </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> 7. Classical NLP Tasks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> 7. Classical NLP Tasks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ClassicalNLP/71_token_classification/ class=md-nav__link> <span class=md-ellipsis> Token Classification </span> </a> </li> <li class=md-nav__item> <a href=../ClassicalNLP/72_masked_language_modeling/ class=md-nav__link> <span class=md-ellipsis> Masked Language Modeling </span> </a> </li> <li class=md-nav__item> <a href=../ClassicalNLP/73_translation/ class=md-nav__link> <span class=md-ellipsis> Translation </span> </a> </li> <li class=md-nav__item> <a href=../ClassicalNLP/74_summarization/ class=md-nav__link> <span class=md-ellipsis> Summarization </span> </a> </li> <li class=md-nav__item> <a href=../ClassicalNLP/75_question_answering/ class=md-nav__link> <span class=md-ellipsis> Question Answering </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目次> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目次 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 概要 </span> </a> </li> <li class=md-nav__item> <a href=#1 class=md-nav__link> <span class=md-ellipsis> 1. 言語モデリングの基礎と開発環境構築 </span> </a> </li> <li class=md-nav__item> <a href=#2 class=md-nav__link> <span class=md-ellipsis> 2. データセットの準備とトークン化 </span> </a> </li> <li class=md-nav__item> <a href=#3 class=md-nav__link> <span class=md-ellipsis> 3. バッチ処理とベースラインモデル </span> </a> </li> <li class=md-nav__item> <a href=#4-self-attention class=md-nav__link> <span class=md-ellipsis> 4. Self-Attentionメカニズムの構築 </span> </a> </li> <li class=md-nav__item> <a href=#5-transformer class=md-nav__link> <span class=md-ellipsis> 5. マルチヘッドアテンションとTransformerブロック </span> </a> </li> <li class=md-nav__item> <a href=#6-gpt class=md-nav__link> <span class=md-ellipsis> 6. 完全なGPTモデルの構築 </span> </a> </li> <li class=md-nav__item> <a href=#7 class=md-nav__link> <span class=md-ellipsis> 7. 最終実装とテキスト生成 </span> </a> </li> <li class=md-nav__item> <a href=#8 class=md-nav__link> <span class=md-ellipsis> 8. 参考資料 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=gpt-transformer>GPTをゼロから構築する完全ガイド - Transformerアーキテクチャの実装と解説<a class=headerlink href=#gpt-transformer title="Permanent link">&para;</a></h1> <h2 id=_1>概要<a class=headerlink href=#_1 title="Permanent link">&para;</a></h2> <p>本ガイドでは、<strong>GPT（Generative Pre-trained Transformer）</strong>をPyTorchを使って一から実装する方法を詳しく解説します。単なるコードのコピー&amp;ペーストではなく、各コンポーネントの理論的背景から実装の詳細、最適化手法まで体系的に学習できる内容となっています。</p> <h3 id=_2>学習目標<a class=headerlink href=#_2 title="Permanent link">&para;</a></h3> <p>このガイドを修了することで、以下の知識とスキルを身につけることができます：</p> <p><strong>基礎理解</strong></p> <ul> <li>ChatGPT・GPTの動作原理とTransformerアーキテクチャの理解</li> <li>文字レベル言語モデリングの仕組み</li> <li>トークン化・エンコーディングの設計と実装</li> <li>データ準備とバッチ処理の最適化手法</li> </ul> <p><strong>コア実装技術</strong></p> <ul> <li>BigramモデルからGPTへの段階的構築</li> <li>Self-Attentionメカニズムの数学的理解と実装</li> <li>Multi-Head AttentionとFeed-Forward Networkの構築</li> <li>位置エンコーディングと重み初期化の詳細実装</li> </ul> <p><strong>高度な技術要素</strong></p> <ul> <li>Pre-Norm vs Post-Normアーキテクチャの比較理解</li> <li>残差接続とLayer Normalizationの効果</li> <li>オートリグレッシブなテキスト生成アルゴリズム</li> <li>損失関数の設計と訓練ループの最適化</li> </ul> <h3 id=_3>前提知識<a class=headerlink href=#_3 title="Permanent link">&para;</a></h3> <p>このガイドを最大限活用するために、以下の知識があることを推奨します：</p> <ul> <li><strong>Python プログラミング</strong>: 基本的な構文、クラス、関数の理解</li> <li><strong>PyTorch 基礎</strong>: テンソル操作、自動微分、nn.Moduleの基本概念</li> <li><strong>深層学習の基本</strong>: ニューラルネットワーク、バックプロパゲーション、勾配降下法</li> <li><strong>線形代数</strong>: 行列乗算、ベクトル演算の基本概念</li> <li><strong>確率・統計</strong>: 確率分布、サンプリング手法の理解</li> </ul> <div class="admonition info"> <p class=admonition-title>参考資料</p> <p>本ガイドは <a href=https://karpathy.ai/ >Andrej Karpathy</a> 氏の「Let's build GPT: from scratch, in code, spelled out」を基に、日本語での詳細解説と追加の実践的な内容を加えたものです。</p> </div> <h3 id=_4>実装アーキテクチャ概要<a class=headerlink href=#_4 title="Permanent link">&para;</a></h3> <p>私たちが構築するGPTモデルは以下の主要コンポーネントから構成されています。</p> <p><img alt src=../05_Let%27s_build_%20GPT_from_scratch_files/Full_GPT_architecture.png></p> <h2 id=1>1. 言語モデリングの基礎と開発環境構築<a class=headerlink href=#1 title="Permanent link">&para;</a></h2> <h3 id=_5>言語モデリングとは<a class=headerlink href=#_5 title="Permanent link">&para;</a></h3> <p>言語モデリングは、<strong>テキストの確率分布を学習する</strong>機械学習タスクです。具体的には、与えられた文脈に基づいて「次に来る可能性の高い単語（またはトークン）」を予測することを学習します。</p> <p><strong>数学的表現</strong>： <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>P(x₁, x₂, ..., xₙ) = ∏ᵢ₌₁ⁿ P(xᵢ|x₁, x₂, ..., xᵢ₋₁)
</span></code></pre></div></p> <p>この式は、文章全体の確率を、各単語が前の文脈に条件付けられた確率の積として表現しています。</p> <h3 id=_6>なぜ文字レベル言語モデルなのか？<a class=headerlink href=#_6 title="Permanent link">&para;</a></h3> <p>このガイドでは、<strong>文字レベル（Character-level）</strong>の言語モデルを構築していきます。</p> <p><strong>利点</strong>:</p> <ul> <li><strong>シンプルさ</strong>: 語彙サイズが小さい（英語なら26文字 + 記号）</li> <li><strong>OOV問題の回避</strong>: 未知語（Out-of-Vocabulary）の問題が発生しない</li> <li><strong>理解しやすさ</strong>: トークン化の複雑さを避けて本質に集中できる</li> </ul> <p><strong>制約</strong>:</p> <ul> <li><strong>効率性</strong>: 単語レベルより長いシーケンスが必要</li> <li><strong>意味理解</strong>: 文字レベルから単語の意味を学習する必要がある</li> </ul> <h3 id=_7>開発環境とライブラリ<a class=headerlink href=#_7 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>DataLoader</span><span class=p>,</span> <span class=n>Dataset</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=c1># GPU利用可能性の確認</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=n>device</span> <span class=o>=</span> <span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;mps&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;使用デバイス: </span><span class=si>{</span><span class=n>device</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=2>2. データセットの準備とトークン化<a class=headerlink href=#2 title="Permanent link">&para;</a></h2> <h3 id=21-tiny-shakespeare>2.1 データセットの選択：Tiny Shakespeare<a class=headerlink href=#21-tiny-shakespeare title="Permanent link">&para;</a></h3> <p><strong>Tiny Shakespeare</strong>を使用する理由：</p> <ol> <li><strong>適度なサイズ</strong>: 約1.1MBで訓練に適している</li> <li><strong>構造化されたテキスト</strong>: 明確な文法と文体</li> <li><strong>英語圏での標準</strong>: 多くの研究で使用されている</li> <li><strong>複雑性のバランス</strong>: 単純すぎず、複雑すぎない</li> </ol> <h3 id=22>2.2 データ準備の詳細プロセス<a class=headerlink href=#22 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># データセットのダウンロード</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=err>!</span><span class=n>wget</span> <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>raw</span><span class=o>.</span><span class=n>githubusercontent</span><span class=o>.</span><span class=n>com</span><span class=o>/</span><span class=n>karpathy</span><span class=o>/</span><span class=n>char</span><span class=o>-</span><span class=n>rnn</span><span class=o>/</span><span class=n>master</span><span class=o>/</span><span class=n>data</span><span class=o>/</span><span class=n>tinyshakespeare</span><span class=o>/</span><span class=nb>input</span><span class=o>.</span><span class=n>txt</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># テキストファイルの読み込みと基本情報確認</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&quot;input.txt&quot;</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>    <span class=n>text</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;length of dataset in characters: &quot;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>text</span><span class=p>))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a>length of dataset in characters:  1115394
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># 最初の1000文字を確認してデータの内容を把握</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=nb>print</span><span class=p>(</span><span class=n>text</span><span class=p>[:</span><span class=mi>1000</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a>First Citizen:
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>Before we proceed any further, hear me speak.
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>All:
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>Speak, speak.
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>First Citizen:
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>You are all resolved rather to die than to famish?
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>All:
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>Resolved. resolved.
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>First Citizen:
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>First, you know Caius Marcius is chief enemy to the people.
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>All:
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>We know&#39;t, we know&#39;t.
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>First Citizen:
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>Let us kill him, and we&#39;ll have corn at our own price.
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a>Is&#39;t a verdict?
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a>All:
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>No more talking on&#39;t; let it be done: away, away!
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>Second Citizen:
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>One word, good citizens.
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a>First Citizen:
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a>We are accounted poor citizens, the patricians good.
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a>What authority surfeits on would relieve us: if they
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a>would yield us but the superfluity, while it were
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a>wholesome, we might guess they relieved us humanely;
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a>but they think we are too dear: the leanness that
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a>afflicts us, the object of our misery, is as an
</span><span id=__span-6-36><a id=__codelineno-6-36 name=__codelineno-6-36 href=#__codelineno-6-36></a>inventory to particularise their abundance; our
</span><span id=__span-6-37><a id=__codelineno-6-37 name=__codelineno-6-37 href=#__codelineno-6-37></a>sufferance is a gain to them Let us revenge this with
</span><span id=__span-6-38><a id=__codelineno-6-38 name=__codelineno-6-38 href=#__codelineno-6-38></a>our pikes, ere we become rakes: for the gods know I
</span><span id=__span-6-39><a id=__codelineno-6-39 name=__codelineno-6-39 href=#__codelineno-6-39></a>speak this in hunger for bread, not in thirst for revenge.
</span></code></pre></div></p> <h3 id=23-vocabulary>2.3 語彙（Vocabulary）の構築<a class=headerlink href=#23-vocabulary title="Permanent link">&para;</a></h3> <p>テキストデータを数値形式に変換するため、まずデータセット内の<strong>全ユニーク文字を特定</strong>します：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># データセット内の全ユニーク文字の抽出と語彙構築</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=n>chars</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>text</span><span class=p>)))</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>chars</span><span class=p>)</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>chars</span><span class=p>))</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=nb>print</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a> !$&amp;&#39;,-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>65
</span></code></pre></div></p> <h3 id=24-tokenization>2.4 トークン化（Tokenization）の実装<a class=headerlink href=#24-tokenization title="Permanent link">&para;</a></h3> <p>コンピュータは文字を直接理解できないため、<strong>文字↔数値の双方向マッピング</strong>を作成します：</p> <h4 id=_8>エンコーディング設計の原則<a class=headerlink href=#_8 title="Permanent link">&para;</a></h4> <ol> <li><strong>一意性</strong>: 各文字に唯一のIDを割り当て</li> <li><strong>可逆性</strong>: 数値から文字への復元が完全に可能</li> <li><strong>効率性</strong>: シンプルで高速な変換</li> </ol> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># 文字→整数、整数→文字のマッピング辞書を作成</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>stoi</span> <span class=o>=</span> <span class=p>{</span> <span class=n>ch</span><span class=p>:</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>ch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>chars</span><span class=p>)}</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=nb>print</span><span class=p>(</span><span class=n>stoi</span><span class=p>)</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>itos</span> <span class=o>=</span> <span class=p>{</span> <span class=n>i</span><span class=p>:</span><span class=n>ch</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>ch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>chars</span><span class=p>)}</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=nb>print</span><span class=p>(</span><span class=n>itos</span><span class=p>)</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=c1># エンコーダー関数: 文字列を整数リストに変換</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a><span class=n>encode</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>s</span><span class=p>:</span> <span class=p>[</span><span class=n>stoi</span><span class=p>[</span><span class=n>c</span><span class=p>]</span> <span class=k>for</span> <span class=n>c</span> <span class=ow>in</span> <span class=n>s</span><span class=p>]</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=c1># デコーダー関数: 整数リストを文字列に変換</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a><span class=n>decode</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>l</span><span class=p>:</span> <span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=n>itos</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>l</span><span class=p>])</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=nb>print</span><span class=p>(</span><span class=n>encode</span><span class=p>(</span><span class=s2>&quot;hii there&quot;</span><span class=p>))</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a><span class=nb>print</span><span class=p>(</span><span class=n>decode</span><span class=p>(</span><span class=n>encode</span><span class=p>(</span><span class=s2>&quot;hii there&quot;</span><span class=p>)))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a>{&#39;\n&#39;: 0, &#39; &#39;: 1, &#39;!&#39;: 2, &#39;$&#39;: 3, &#39;&amp;&#39;: 4, &quot;&#39;&quot;: 5, &#39;,&#39;: 6, &#39;-&#39;: 7, &#39;.&#39;: 8, &#39;3&#39;: 9, &#39;:&#39;: 10, &#39;;&#39;: 11, &#39;?&#39;: 12, &#39;A&#39;: 13, &#39;B&#39;: 14, &#39;C&#39;: 15, &#39;D&#39;: 16, &#39;E&#39;: 17, &#39;F&#39;: 18, &#39;G&#39;: 19, &#39;H&#39;: 20, &#39;I&#39;: 21, &#39;J&#39;: 22, &#39;K&#39;: 23, &#39;L&#39;: 24, &#39;M&#39;: 25, &#39;N&#39;: 26, &#39;O&#39;: 27, &#39;P&#39;: 28, &#39;Q&#39;: 29, &#39;R&#39;: 30, &#39;S&#39;: 31, &#39;T&#39;: 32, &#39;U&#39;: 33, &#39;V&#39;: 34, &#39;W&#39;: 35, &#39;X&#39;: 36, &#39;Y&#39;: 37, &#39;Z&#39;: 38, &#39;a&#39;: 39, &#39;b&#39;: 40, &#39;c&#39;: 41, &#39;d&#39;: 42, &#39;e&#39;: 43, &#39;f&#39;: 44, &#39;g&#39;: 45, &#39;h&#39;: 46, &#39;i&#39;: 47, &#39;j&#39;: 48, &#39;k&#39;: 49, &#39;l&#39;: 50, &#39;m&#39;: 51, &#39;n&#39;: 52, &#39;o&#39;: 53, &#39;p&#39;: 54, &#39;q&#39;: 55, &#39;r&#39;: 56, &#39;s&#39;: 57, &#39;t&#39;: 58, &#39;u&#39;: 59, &#39;v&#39;: 60, &#39;w&#39;: 61, &#39;x&#39;: 62, &#39;y&#39;: 63, &#39;z&#39;: 64}
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>{0: &#39;\n&#39;, 1: &#39; &#39;, 2: &#39;!&#39;, 3: &#39;$&#39;, 4: &#39;&amp;&#39;, 5: &quot;&#39;&quot;, 6: &#39;,&#39;, 7: &#39;-&#39;, 8: &#39;.&#39;, 9: &#39;3&#39;, 10: &#39;:&#39;, 11: &#39;;&#39;, 12: &#39;?&#39;, 13: &#39;A&#39;, 14: &#39;B&#39;, 15: &#39;C&#39;, 16: &#39;D&#39;, 17: &#39;E&#39;, 18: &#39;F&#39;, 19: &#39;G&#39;, 20: &#39;H&#39;, 21: &#39;I&#39;, 22: &#39;J&#39;, 23: &#39;K&#39;, 24: &#39;L&#39;, 25: &#39;M&#39;, 26: &#39;N&#39;, 27: &#39;O&#39;, 28: &#39;P&#39;, 29: &#39;Q&#39;, 30: &#39;R&#39;, 31: &#39;S&#39;, 32: &#39;T&#39;, 33: &#39;U&#39;, 34: &#39;V&#39;, 35: &#39;W&#39;, 36: &#39;X&#39;, 37: &#39;Y&#39;, 38: &#39;Z&#39;, 39: &#39;a&#39;, 40: &#39;b&#39;, 41: &#39;c&#39;, 42: &#39;d&#39;, 43: &#39;e&#39;, 44: &#39;f&#39;, 45: &#39;g&#39;, 46: &#39;h&#39;, 47: &#39;i&#39;, 48: &#39;j&#39;, 49: &#39;k&#39;, 50: &#39;l&#39;, 51: &#39;m&#39;, 52: &#39;n&#39;, 53: &#39;o&#39;, 54: &#39;p&#39;, 55: &#39;q&#39;, 56: &#39;r&#39;, 57: &#39;s&#39;, 58: &#39;t&#39;, 59: &#39;u&#39;, 60: &#39;v&#39;, 61: &#39;w&#39;, 62: &#39;x&#39;, 63: &#39;y&#39;, 64: &#39;z&#39;}
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>[46, 47, 47, 1, 58, 46, 43, 56, 43]
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>hii there
</span></code></pre></div></p> <h3 id=25>2.5 データセットの準備と分割<a class=headerlink href=#25 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># 全テキストデータをPyTorchテンソルに変換</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=n>data</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>encode</span><span class=p>(</span><span class=n>text</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a><span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>data</span><span class=o>.</span><span class=n>dtype</span><span class=p>)</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=p>[:</span><span class=mi>100</span><span class=p>])</span>  <span class=c1># 最初の100文字の数値表現を確認</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a>torch.Size([1115394]) torch.int64
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])
</span></code></pre></div></p> <p><strong>訓練/検証分割</strong>: </p> <p>訓練用と検証用のデータセットを作成します。 データの最初の90%を訓練データ、最後の10%を検証データとして使用し、モデルの過学習を評価します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># データを訓練用（90%）と検証用（10%）に分割</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=n>n</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=mf>0.9</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>))</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=n>train_data</span> <span class=o>=</span> <span class=n>data</span><span class=p>[:</span><span class=n>n</span><span class=p>]</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=n>val_data</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>n</span><span class=p>:]</span>
</span></code></pre></div> <h2 id=3>3. バッチ処理とベースラインモデル<a class=headerlink href=#3 title="Permanent link">&para;</a></h2> <h3 id=31>3.1 バッチ処理とシーケンス構築<a class=headerlink href=#31 title="Permanent link">&para;</a></h3> <p><strong>チャンク処理</strong>: Transformerは全テキストを一度に処理できないため、データの「小さなランダムなチャンク」をサンプリングして訓練します。</p> <ul> <li>ブロックサイズ: チャンクの最大長。「コンテキスト長」とも呼ばれる。</li> <li>複数の例のパック: 各チャンクには、文脈とその次のターゲット文字の複数の予測例が含まれる。</li> <li>バッチ処理: GPUの効率的な利用のため、「複数のチャンクを単一のテンソルにまとめてスタックする」。</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=n>block_size</span> <span class=o>=</span> <span class=mi>8</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>train_data</span><span class=p>[:</span><span class=n>block_size</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a>tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># 単一のチャンクから複数の訓練例を生成する仕組みを確認</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>train_data</span><span class=p>[:</span><span class=n>block_size</span><span class=p>]</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a><span class=n>y</span> <span class=o>=</span> <span class=n>train_data</span><span class=p>[</span><span class=mi>1</span><span class=p>:</span><span class=n>block_size</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a><span class=nb>print</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a><span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>block_size</span><span class=p>):</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>    <span class=n>context</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:</span><span class=n>t</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>    <span class=n>target</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>t</span><span class=p>]</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>t</span><span class=si>}</span><span class=s2>. when input is </span><span class=si>{</span><span class=n>context</span><span class=si>}</span><span class=s2> the target: </span><span class=si>{</span><span class=n>target</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>tensor([47, 56, 57, 58,  1, 15, 47, 58])
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>0. when input is tensor([18]) the target: 47
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>1. when input is tensor([18, 47]) the target: 56
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>2. when input is tensor([18, 47, 56]) the target: 57
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>3. when input is tensor([18, 47, 56, 57]) the target: 58
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>4. when input is tensor([18, 47, 56, 57, 58]) the target: 1
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>5. when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>6. when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>7. when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58
</span></code></pre></div></p> <p><strong>バッチ処理</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>1337</span><span class=p>)</span>  <span class=c1># 乱数シードを固定して再現性を確保</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>4</span>           <span class=c1># バッチサイズ（同時に処理するデータ数）</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a><span class=n>block_size</span> <span class=o>=</span> <span class=mi>8</span>           <span class=c1># 1サンプルのコンテキスト長（トークン数）</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=k>def</span><span class=w> </span><span class=nf>get_batch</span><span class=p>(</span><span class=n>split</span><span class=p>):</span>
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a>    <span class=c1># データセットの選択：trainまたはvalidation</span>
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a>    <span class=n>data</span> <span class=o>=</span> <span class=n>train_data</span> <span class=k>if</span> <span class=n>split</span> <span class=o>==</span> <span class=s1>&#39;train&#39;</span> <span class=k>else</span> <span class=n>val_data</span>
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a>
</span><span id=__span-18-9><a id=__codelineno-18-9 name=__codelineno-18-9 href=#__codelineno-18-9></a>    <span class=c1># ランダムな開始位置を生成（batch_size個）</span>
</span><span id=__span-18-10><a id=__codelineno-18-10 name=__codelineno-18-10 href=#__codelineno-18-10></a>    <span class=c1># len(data) - block_sizeにすることで、境界オーバーを防ぐ</span>
</span><span id=__span-18-11><a id=__codelineno-18-11 name=__codelineno-18-11 href=#__codelineno-18-11></a>    <span class=n>ix</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span> <span class=o>-</span> <span class=n>block_size</span><span class=p>,</span> <span class=p>(</span><span class=n>batch_size</span><span class=p>,))</span>  
</span><span id=__span-18-12><a id=__codelineno-18-12 name=__codelineno-18-12 href=#__codelineno-18-12></a>
</span><span id=__span-18-13><a id=__codelineno-18-13 name=__codelineno-18-13 href=#__codelineno-18-13></a>    <span class=c1># 入力シーケンス（x）：各開始位置からblock_size分のデータを取得</span>
</span><span id=__span-18-14><a id=__codelineno-18-14 name=__codelineno-18-14 href=#__codelineno-18-14></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>block_size</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ix</span><span class=p>])</span> 
</span><span id=__span-18-15><a id=__codelineno-18-15 name=__codelineno-18-15 href=#__codelineno-18-15></a>
</span><span id=__span-18-16><a id=__codelineno-18-16 name=__codelineno-18-16 href=#__codelineno-18-16></a>    <span class=c1># ターゲットシーケンス（y）：xより1つずつ後ろにシフトしたデータ</span>
</span><span id=__span-18-17><a id=__codelineno-18-17 name=__codelineno-18-17 href=#__codelineno-18-17></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>block_size</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ix</span><span class=p>])</span>  
</span><span id=__span-18-18><a id=__codelineno-18-18 name=__codelineno-18-18 href=#__codelineno-18-18></a>
</span><span id=__span-18-19><a id=__codelineno-18-19 name=__codelineno-18-19 href=#__codelineno-18-19></a>    <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span>  <span class=c1># (batch_size, block_size)の形状で返す</span>
</span><span id=__span-18-20><a id=__codelineno-18-20 name=__codelineno-18-20 href=#__codelineno-18-20></a>
</span><span id=__span-18-21><a id=__codelineno-18-21 name=__codelineno-18-21 href=#__codelineno-18-21></a><span class=n>xb</span><span class=p>,</span> <span class=n>yb</span> <span class=o>=</span> <span class=n>get_batch</span><span class=p>(</span><span class=s2>&quot;train&quot;</span><span class=p>)</span>  <span class=c1># 訓練データからバッチを取得</span>
</span><span id=__span-18-22><a id=__codelineno-18-22 name=__codelineno-18-22 href=#__codelineno-18-22></a>
</span><span id=__span-18-23><a id=__codelineno-18-23 name=__codelineno-18-23 href=#__codelineno-18-23></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;inputs&quot;</span><span class=p>)</span>
</span><span id=__span-18-24><a id=__codelineno-18-24 name=__codelineno-18-24 href=#__codelineno-18-24></a><span class=nb>print</span><span class=p>(</span><span class=n>xb</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>              <span class=c1># 入力テンソルの形状を表示</span>
</span><span id=__span-18-25><a id=__codelineno-18-25 name=__codelineno-18-25 href=#__codelineno-18-25></a><span class=nb>print</span><span class=p>(</span><span class=n>xb</span><span class=p>)</span>                    <span class=c1># 入力テンソルの内容を表示</span>
</span><span id=__span-18-26><a id=__codelineno-18-26 name=__codelineno-18-26 href=#__codelineno-18-26></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;targets&quot;</span><span class=p>)</span>
</span><span id=__span-18-27><a id=__codelineno-18-27 name=__codelineno-18-27 href=#__codelineno-18-27></a><span class=nb>print</span><span class=p>(</span><span class=n>yb</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>              <span class=c1># ターゲットテンソルの形状を表示</span>
</span><span id=__span-18-28><a id=__codelineno-18-28 name=__codelineno-18-28 href=#__codelineno-18-28></a><span class=nb>print</span><span class=p>(</span><span class=n>yb</span><span class=p>)</span>                    <span class=c1># ターゲットテンソルの内容を表示</span>
</span><span id=__span-18-29><a id=__codelineno-18-29 name=__codelineno-18-29 href=#__codelineno-18-29></a>
</span><span id=__span-18-30><a id=__codelineno-18-30 name=__codelineno-18-30 href=#__codelineno-18-30></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;--------&quot;</span><span class=p>)</span>
</span><span id=__span-18-31><a id=__codelineno-18-31 name=__codelineno-18-31 href=#__codelineno-18-31></a>
</span><span id=__span-18-32><a id=__codelineno-18-32 name=__codelineno-18-32 href=#__codelineno-18-32></a><span class=c1># 各バッチ・各時刻ごとに、与えられたコンテキストとターゲットを表示</span>
</span><span id=__span-18-33><a id=__codelineno-18-33 name=__codelineno-18-33 href=#__codelineno-18-33></a><span class=k>for</span> <span class=n>b</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>batch_size</span><span class=p>):</span> <span class=c1># バッチ次元</span>
</span><span id=__span-18-34><a id=__codelineno-18-34 name=__codelineno-18-34 href=#__codelineno-18-34></a>    <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>block_size</span><span class=p>):</span> <span class=c1># 時系列次元</span>
</span><span id=__span-18-35><a id=__codelineno-18-35 name=__codelineno-18-35 href=#__codelineno-18-35></a>        <span class=n>context</span> <span class=o>=</span> <span class=n>xb</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=p>:</span><span class=n>t</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span>   <span class=c1># t時点までのコンテキスト</span>
</span><span id=__span-18-36><a id=__codelineno-18-36 name=__codelineno-18-36 href=#__codelineno-18-36></a>        <span class=n>target</span> <span class=o>=</span> <span class=n>yb</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=n>t</span><span class=p>]</span>       <span class=c1># 予測すべきターゲット</span>
</span><span id=__span-18-37><a id=__codelineno-18-37 name=__codelineno-18-37 href=#__codelineno-18-37></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;when input is </span><span class=si>{</span><span class=n>context</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span><span class=si>}</span><span class=s2> the target: </span><span class=si>{</span><span class=n>target</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>inputs
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>torch.Size([4, 8])
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>tensor([[24, 43, 58,  5, 57,  1, 46, 43],
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a>        [44, 53, 56,  1, 58, 46, 39, 58],
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a>        [52, 58,  1, 58, 46, 39, 58,  1],
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>        [25, 17, 27, 10,  0, 21,  1, 54]])
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>targets
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a>torch.Size([4, 8])
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a>tensor([[43, 58,  5, 57,  1, 46, 43, 39],
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a>        [53, 56,  1, 58, 46, 39, 58,  1],
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a>        [58,  1, 58, 46, 39, 58,  1, 46],
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a>        [17, 27, 10,  0, 21,  1, 54, 39]])
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a>--------
</span><span id=__span-19-14><a id=__codelineno-19-14 name=__codelineno-19-14 href=#__codelineno-19-14></a>when input is [24] the target: 43
</span><span id=__span-19-15><a id=__codelineno-19-15 name=__codelineno-19-15 href=#__codelineno-19-15></a>when input is [24, 43] the target: 58
</span><span id=__span-19-16><a id=__codelineno-19-16 name=__codelineno-19-16 href=#__codelineno-19-16></a>when input is [24, 43, 58] the target: 5
</span><span id=__span-19-17><a id=__codelineno-19-17 name=__codelineno-19-17 href=#__codelineno-19-17></a>when input is [24, 43, 58, 5] the target: 57
</span><span id=__span-19-18><a id=__codelineno-19-18 name=__codelineno-19-18 href=#__codelineno-19-18></a>when input is [24, 43, 58, 5, 57] the target: 1
</span><span id=__span-19-19><a id=__codelineno-19-19 name=__codelineno-19-19 href=#__codelineno-19-19></a>when input is [24, 43, 58, 5, 57, 1] the target: 46
</span><span id=__span-19-20><a id=__codelineno-19-20 name=__codelineno-19-20 href=#__codelineno-19-20></a>when input is [24, 43, 58, 5, 57, 1, 46] the target: 43
</span><span id=__span-19-21><a id=__codelineno-19-21 name=__codelineno-19-21 href=#__codelineno-19-21></a>when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39
</span><span id=__span-19-22><a id=__codelineno-19-22 name=__codelineno-19-22 href=#__codelineno-19-22></a>when input is [44] the target: 53
</span><span id=__span-19-23><a id=__codelineno-19-23 name=__codelineno-19-23 href=#__codelineno-19-23></a>when input is [44, 53] the target: 56
</span><span id=__span-19-24><a id=__codelineno-19-24 name=__codelineno-19-24 href=#__codelineno-19-24></a>when input is [44, 53, 56] the target: 1
</span><span id=__span-19-25><a id=__codelineno-19-25 name=__codelineno-19-25 href=#__codelineno-19-25></a>when input is [44, 53, 56, 1] the target: 58
</span><span id=__span-19-26><a id=__codelineno-19-26 name=__codelineno-19-26 href=#__codelineno-19-26></a>when input is [44, 53, 56, 1, 58] the target: 46
</span><span id=__span-19-27><a id=__codelineno-19-27 name=__codelineno-19-27 href=#__codelineno-19-27></a>when input is [44, 53, 56, 1, 58, 46] the target: 39
</span><span id=__span-19-28><a id=__codelineno-19-28 name=__codelineno-19-28 href=#__codelineno-19-28></a>when input is [44, 53, 56, 1, 58, 46, 39] the target: 58
</span><span id=__span-19-29><a id=__codelineno-19-29 name=__codelineno-19-29 href=#__codelineno-19-29></a>when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1
</span><span id=__span-19-30><a id=__codelineno-19-30 name=__codelineno-19-30 href=#__codelineno-19-30></a>when input is [52] the target: 58
</span><span id=__span-19-31><a id=__codelineno-19-31 name=__codelineno-19-31 href=#__codelineno-19-31></a>when input is [52, 58] the target: 1
</span><span id=__span-19-32><a id=__codelineno-19-32 name=__codelineno-19-32 href=#__codelineno-19-32></a>when input is [52, 58, 1] the target: 58
</span><span id=__span-19-33><a id=__codelineno-19-33 name=__codelineno-19-33 href=#__codelineno-19-33></a>when input is [52, 58, 1, 58] the target: 46
</span><span id=__span-19-34><a id=__codelineno-19-34 name=__codelineno-19-34 href=#__codelineno-19-34></a>when input is [52, 58, 1, 58, 46] the target: 39
</span><span id=__span-19-35><a id=__codelineno-19-35 name=__codelineno-19-35 href=#__codelineno-19-35></a>when input is [52, 58, 1, 58, 46, 39] the target: 58
</span><span id=__span-19-36><a id=__codelineno-19-36 name=__codelineno-19-36 href=#__codelineno-19-36></a>when input is [52, 58, 1, 58, 46, 39, 58] the target: 1
</span><span id=__span-19-37><a id=__codelineno-19-37 name=__codelineno-19-37 href=#__codelineno-19-37></a>when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46
</span><span id=__span-19-38><a id=__codelineno-19-38 name=__codelineno-19-38 href=#__codelineno-19-38></a>when input is [25] the target: 17
</span><span id=__span-19-39><a id=__codelineno-19-39 name=__codelineno-19-39 href=#__codelineno-19-39></a>when input is [25, 17] the target: 27
</span><span id=__span-19-40><a id=__codelineno-19-40 name=__codelineno-19-40 href=#__codelineno-19-40></a>when input is [25, 17, 27] the target: 10
</span><span id=__span-19-41><a id=__codelineno-19-41 name=__codelineno-19-41 href=#__codelineno-19-41></a>when input is [25, 17, 27, 10] the target: 0
</span><span id=__span-19-42><a id=__codelineno-19-42 name=__codelineno-19-42 href=#__codelineno-19-42></a>when input is [25, 17, 27, 10, 0] the target: 21
</span><span id=__span-19-43><a id=__codelineno-19-43 name=__codelineno-19-43 href=#__codelineno-19-43></a>when input is [25, 17, 27, 10, 0, 21] the target: 1
</span><span id=__span-19-44><a id=__codelineno-19-44 name=__codelineno-19-44 href=#__codelineno-19-44></a>when input is [25, 17, 27, 10, 0, 21, 1] the target: 54
</span><span id=__span-19-45><a id=__codelineno-19-45 name=__codelineno-19-45 href=#__codelineno-19-45></a>when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=nb>print</span><span class=p>(</span><span class=n>xb</span><span class=p>)</span> <span class=c1># Transformerへの入力データ</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>tensor([[24, 43, 58,  5, 57,  1, 46, 43],
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>        [44, 53, 56,  1, 58, 46, 39, 58],
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a>        [52, 58,  1, 58, 46, 39, 58,  1],
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a>        [25, 17, 27, 10,  0, 21,  1, 54]])
</span></code></pre></div></p> <div class="admonition tip"> <p class=admonition-title>ランダムサンプリングについて</p> <p>言語モデルの訓練では、データからランダムにblock_size分のシーケンスを取得する。この時、全てのblockが訓練に使われるわけではない。一部のblockは何度も選ばれ、一部は一度も選ばれない可能性がある。 しかし、これは問題ではない。深層学習は統計学習であり、全てのデータを見る必要はない。言語には多くの重複パターンがあるため、ランダムサンプルでも言語の統計的規則を十分学習できる。また、ランダムサンプリングはデータの局所的相関を打破し、効率的な学習を促進する。 十分な訓練ステップを行えば、統計的に大部分のblockは最終的にサンプルされることになる。</p> </div> <h3 id=32>3.2 最もシンプルなモデル: バイグラム言語モデル<a class=headerlink href=#32 title="Permanent link">&para;</a></h3> <p>最初に、最もシンプルなバイグラム言語モデルを実装して基本概念を理解する：</p> <ul> <li><strong>実装</strong>: PyTorchのnn.Moduleでバイグラム言語モデルを実装</li> <li><strong>埋め込み層</strong>: nn.Embeddingを使用して、各トークン（文字）をvocab_size x vocab_sizeの埋め込みベクトルに変換する。入力の各整数が埋め込み層の行を選択する</li> <li><strong>ロジットと損失</strong>: 出力は次の文字の「スコア」（logit）となる。損失は「Negative Log Likelihood Loss」（PyTorchではCrossEntropyLoss）で評価する</li> <li><strong>生成</strong>: 現在のコンテキストに基づいて次のトークンを生成する。softmaxで確率を計算し、torch.multinomialでサンプリングする</li> <li><strong>訓練</strong>: Adamオプティマイザを使用し、損失を最小化するようにモデルパラメータを更新する。バイグラムモデルでは、「入力は完全にランダム」な出力を生成するが、訓練によりいくらか改善される</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=kn>import</span> <span class=n>functional</span> <span class=k>as</span> <span class=n>F</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>1337</span><span class=p>)</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a><span class=k>class</span><span class=w> </span><span class=nc>BigramLanguageModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>):</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-22-9><a id=__codelineno-22-9 name=__codelineno-22-9 href=#__codelineno-22-9></a>        <span class=c1># 各トークンは埋め込み層から次のトークンのロジットを直接読み取る</span>
</span><span id=__span-22-10><a id=__codelineno-22-10 name=__codelineno-22-10 href=#__codelineno-22-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding_table</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>)</span>
</span><span id=__span-22-11><a id=__codelineno-22-11 name=__codelineno-22-11 href=#__codelineno-22-11></a>
</span><span id=__span-22-12><a id=__codelineno-22-12 name=__codelineno-22-12 href=#__codelineno-22-12></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>,</span> <span class=n>targets</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-22-13><a id=__codelineno-22-13 name=__codelineno-22-13 href=#__codelineno-22-13></a>        <span class=c1># idxとtargetsはどちらも整数の(B, T)テンソル</span>
</span><span id=__span-22-14><a id=__codelineno-22-14 name=__codelineno-22-14 href=#__codelineno-22-14></a>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding_table</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span> <span class=c1># (B, T, C)</span>
</span><span id=__span-22-15><a id=__codelineno-22-15 name=__codelineno-22-15 href=#__codelineno-22-15></a>
</span><span id=__span-22-16><a id=__codelineno-22-16 name=__codelineno-22-16 href=#__codelineno-22-16></a>        <span class=k>if</span> <span class=n>targets</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-22-17><a id=__codelineno-22-17 name=__codelineno-22-17 href=#__codelineno-22-17></a>            <span class=n>loss</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-22-18><a id=__codelineno-22-18 name=__codelineno-22-18 href=#__codelineno-22-18></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-22-19><a id=__codelineno-22-19 name=__codelineno-22-19 href=#__codelineno-22-19></a>            <span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-22-20><a id=__codelineno-22-20 name=__codelineno-22-20 href=#__codelineno-22-20></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>T</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span>
</span><span id=__span-22-21><a id=__codelineno-22-21 name=__codelineno-22-21 href=#__codelineno-22-21></a>            <span class=n>targets</span> <span class=o>=</span> <span class=n>targets</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>T</span><span class=p>)</span>
</span><span id=__span-22-22><a id=__codelineno-22-22 name=__codelineno-22-22 href=#__codelineno-22-22></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-22-23><a id=__codelineno-22-23 name=__codelineno-22-23 href=#__codelineno-22-23></a>
</span><span id=__span-22-24><a id=__codelineno-22-24 name=__codelineno-22-24 href=#__codelineno-22-24></a>        <span class=k>return</span> <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span>
</span><span id=__span-22-25><a id=__codelineno-22-25 name=__codelineno-22-25 href=#__codelineno-22-25></a>
</span><span id=__span-22-26><a id=__codelineno-22-26 name=__codelineno-22-26 href=#__codelineno-22-26></a>    <span class=k>def</span><span class=w> </span><span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=p>):</span>
</span><span id=__span-22-27><a id=__codelineno-22-27 name=__codelineno-22-27 href=#__codelineno-22-27></a>        <span class=c1># idxは現在のコンテキストのインデックスの(B, T)配列</span>
</span><span id=__span-22-28><a id=__codelineno-22-28 name=__codelineno-22-28 href=#__codelineno-22-28></a>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_new_tokens</span><span class=p>):</span>
</span><span id=__span-22-29><a id=__codelineno-22-29 name=__codelineno-22-29 href=#__codelineno-22-29></a>            <span class=c1># 予測を取得</span>
</span><span id=__span-22-30><a id=__codelineno-22-30 name=__codelineno-22-30 href=#__codelineno-22-30></a>            <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span>
</span><span id=__span-22-31><a id=__codelineno-22-31 name=__codelineno-22-31 href=#__codelineno-22-31></a>            <span class=c1># 最後の時間ステップにのみ焦点を当てる</span>
</span><span id=__span-22-32><a id=__codelineno-22-32 name=__codelineno-22-32 href=#__codelineno-22-32></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># (B, C)になる</span>
</span><span id=__span-22-33><a id=__codelineno-22-33 name=__codelineno-22-33 href=#__codelineno-22-33></a>            <span class=c1># softmaxを適用して確率を取得</span>
</span><span id=__span-22-34><a id=__codelineno-22-34 name=__codelineno-22-34 href=#__codelineno-22-34></a>            <span class=n>probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, C)</span>
</span><span id=__span-22-35><a id=__codelineno-22-35 name=__codelineno-22-35 href=#__codelineno-22-35></a>            <span class=c1># 分布からサンプル</span>
</span><span id=__span-22-36><a id=__codelineno-22-36 name=__codelineno-22-36 href=#__codelineno-22-36></a>            <span class=n>idx_next</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>num_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, 1)</span>
</span><span id=__span-22-37><a id=__codelineno-22-37 name=__codelineno-22-37 href=#__codelineno-22-37></a>            <span class=c1># サンプルされたインデックスを実行シーケンスに追加</span>
</span><span id=__span-22-38><a id=__codelineno-22-38 name=__codelineno-22-38 href=#__codelineno-22-38></a>            <span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>idx</span><span class=p>,</span> <span class=n>idx_next</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, T+1)</span>
</span><span id=__span-22-39><a id=__codelineno-22-39 name=__codelineno-22-39 href=#__codelineno-22-39></a>        <span class=k>return</span> <span class=n>idx</span>
</span><span id=__span-22-40><a id=__codelineno-22-40 name=__codelineno-22-40 href=#__codelineno-22-40></a>
</span><span id=__span-22-41><a id=__codelineno-22-41 name=__codelineno-22-41 href=#__codelineno-22-41></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;inputs: </span><span class=si>{</span><span class=n>xb</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span> <span class=c1># 入力テンソルの形状を表示</span>
</span><span id=__span-22-42><a id=__codelineno-22-42 name=__codelineno-22-42 href=#__codelineno-22-42></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;targets: </span><span class=si>{</span><span class=n>yb</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span> <span class=c1># ターゲットテンソルの形状を表示</span>
</span><span id=__span-22-43><a id=__codelineno-22-43 name=__codelineno-22-43 href=#__codelineno-22-43></a><span class=n>model</span> <span class=o>=</span> <span class=n>BigramLanguageModel</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>)</span>
</span><span id=__span-22-44><a id=__codelineno-22-44 name=__codelineno-22-44 href=#__codelineno-22-44></a><span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>xb</span><span class=p>,</span> <span class=n>yb</span><span class=p>)</span>
</span><span id=__span-22-45><a id=__codelineno-22-45 name=__codelineno-22-45 href=#__codelineno-22-45></a><span class=nb>print</span><span class=p>(</span><span class=n>logits</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-22-46><a id=__codelineno-22-46 name=__codelineno-22-46 href=#__codelineno-22-46></a><span class=nb>print</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span><span id=__span-22-47><a id=__codelineno-22-47 name=__codelineno-22-47 href=#__codelineno-22-47></a>
</span><span id=__span-22-48><a id=__codelineno-22-48 name=__codelineno-22-48 href=#__codelineno-22-48></a><span class=nb>print</span><span class=p>(</span><span class=n>decode</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>tolist</span><span class=p>()))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a>inputs: torch.Size([4, 8])
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>targets: torch.Size([4, 8])
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a>torch.Size([32, 65])
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a>tensor(4.8786, grad_fn=&lt;NllLossBackward0&gt;)
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a>SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a>wnYWmnxKWWev-tDqXErVKLgJ
</span></code></pre></div></p> <p>オプティマイザ: AdamW (Adamの改良版) を利用します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=c1># PyTorchオプティマイザの作成</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>)</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=c1># 訓練ループの実行</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>32</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a><span class=k>for</span> <span class=n>steps</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5000</span><span class=p>):</span> <span class=c1># より良い結果を得るにはステップ数を増やす...</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a>    <span class=c1># データのバッチをサンプル</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a>    <span class=n>xb</span><span class=p>,</span> <span class=n>yb</span> <span class=o>=</span> <span class=n>get_batch</span><span class=p>(</span><span class=s2>&quot;train&quot;</span><span class=p>)</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>    <span class=c1># 損失を評価</span>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a>    <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>xb</span><span class=p>,</span> <span class=n>yb</span><span class=p>)</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>(</span><span class=n>set_to_none</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11 href=#__codelineno-25-11></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-25-12><a id=__codelineno-25-12 name=__codelineno-25-12 href=#__codelineno-25-12></a>
</span><span id=__span-25-13><a id=__codelineno-25-13 name=__codelineno-25-13 href=#__codelineno-25-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;loss: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a>loss: 4.801066875457764
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a><span class=nb>print</span><span class=p>(</span><span class=n>decode</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>500</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>tolist</span><span class=p>()))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a>Yc;A-wF-Idfyh$-HSVLzR&#39;QljxYiykGzMGJmKUfN-IJL-mZI-PWT;AnYju&#39;KZRmXc;ha;hEq-epHAA:NJjmyhjd
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a>3Q&amp;vW:PiHA fotx:VFv$VrgCOlvyeE?BK-j,lzoUlx;ALIB;&amp;srWk:PqNgCJW?nOphstDM$zW.:x:a-gfr,LC&#39;KDIEuC -LzRwfqoTF&amp;!wKS.byhixJJi?aUJa,SjNYwJUDnLgBZ!zPYQQ&amp;oiOlv&#39;bFOYGxrDGM?iNubZwJFbqAm,.pSrgi,
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a>W:CVz zlfFC!ufNevU&#39;d f?Y3fAr.uYCJr&amp;!Aqm,p$YCUAbV!PnQhhs;:wiBk!a!!Q!ITh
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a>RwEiMWkzoXn!a!ajn&amp;o;cLgFVTq,Njx.y,cUNfI&#39;qUzdpG;EZvmJMlH;w$ vhzzrgKtdlgM;zPNXrzVvix?LTNXx,ehfVJUZbW -.jxXW:x;i?nQUh&amp;yJh;tQJ$a:Cj$uUEa-PyFERV
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a>oEBCKpF$ehSKgKYIoaiB
</span></code></pre></div></p> <p>損失は下がりましたが、予測の内容は全然ダメですね。 それはもっともシンプルなモデルですから、featuresが独立して、関連性がなかったです。</p> <h2 id=4-self-attention>4. Self-Attentionメカニズムの構築<a class=headerlink href=#4-self-attention title="Permanent link">&para;</a></h2> <h3 id=41-self-attention>4.1 Self-Attention（自己注意機構）の理論<a class=headerlink href=#41-self-attention title="Permanent link">&para;</a></h3> <h4 id=_9>効率的な重み付き集約の数学的トリック<a class=headerlink href=#_9 title="Permanent link">&para;</a></h4> <p>まず、行列乗算を使った重み付き集約の仕組みを理解するために、シンプルなトイ例から始めましょう。この例では、<strong>下三角行列</strong>と<strong>重み正規化</strong>を使って、過去のトークンのみを参照する仕組みを作ります。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a><span class=c1># 行列乗算が「重み付き集約」にどのように使用されるかを示すトイ例</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a><span class=n>a_original</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tril</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a><span class=n>a</span> <span class=o>=</span> <span class=n>a_original</span> <span class=o>/</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>a_original</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a><span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>10</span><span class=p>,(</span><span class=mi>3</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6 href=#__codelineno-29-6></a><span class=n>c</span> <span class=o>=</span> <span class=n>a</span> <span class=o>@</span> <span class=n>b</span>
</span><span id=__span-29-7><a id=__codelineno-29-7 name=__codelineno-29-7 href=#__codelineno-29-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;a_original=&quot;</span><span class=p>)</span>
</span><span id=__span-29-8><a id=__codelineno-29-8 name=__codelineno-29-8 href=#__codelineno-29-8></a><span class=nb>print</span><span class=p>(</span><span class=n>a_original</span><span class=p>)</span>
</span><span id=__span-29-9><a id=__codelineno-29-9 name=__codelineno-29-9 href=#__codelineno-29-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;a=</span><span class=si>{</span><span class=n>a</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-29-10><a id=__codelineno-29-10 name=__codelineno-29-10 href=#__codelineno-29-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;b=</span><span class=si>{</span><span class=n>b</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-29-11><a id=__codelineno-29-11 name=__codelineno-29-11 href=#__codelineno-29-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;c=</span><span class=si>{</span><span class=n>c</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a>a_original=
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a>tensor([[1., 0., 0.],
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a>        [1., 1., 0.],
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a>        [1., 1., 1.]])
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a>a=tensor([[1.0000, 0.0000, 0.0000],
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6 href=#__codelineno-30-6></a>        [0.5000, 0.5000, 0.0000],
</span><span id=__span-30-7><a id=__codelineno-30-7 name=__codelineno-30-7 href=#__codelineno-30-7></a>        [0.3333, 0.3333, 0.3333]])
</span><span id=__span-30-8><a id=__codelineno-30-8 name=__codelineno-30-8 href=#__codelineno-30-8></a>b=tensor([[2., 7.],
</span><span id=__span-30-9><a id=__codelineno-30-9 name=__codelineno-30-9 href=#__codelineno-30-9></a>        [6., 4.],
</span><span id=__span-30-10><a id=__codelineno-30-10 name=__codelineno-30-10 href=#__codelineno-30-10></a>        [6., 5.]])
</span><span id=__span-30-11><a id=__codelineno-30-11 name=__codelineno-30-11 href=#__codelineno-30-11></a>c=tensor([[2.0000, 7.0000],
</span><span id=__span-30-12><a id=__codelineno-30-12 name=__codelineno-30-12 href=#__codelineno-30-12></a>        [4.0000, 5.5000],
</span><span id=__span-30-13><a id=__codelineno-30-13 name=__codelineno-30-13 href=#__codelineno-30-13></a>        [4.6667, 5.3333]])
</span></code></pre></div></p> <p>それでは、実際のテンソルを使ってこの概念を確認してみましょう。以下では、<strong>バッチ処理</strong>を含む3次元テンソル（バッチ、時間、チャンネル）で重み付き集約がどのように動作するかを見ていきます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a><span class=c1># 以下のトイ例を考えてみましょう：</span>
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2 href=#__codelineno-31-2></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>1337</span><span class=p>)</span>
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3 href=#__codelineno-31-3></a><span class=n>B</span><span class=p>,</span><span class=n>T</span><span class=p>,</span><span class=n>C</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span><span class=mi>8</span><span class=p>,</span><span class=mi>2</span> <span class=c1># バッチ、時間、チャンネル</span>
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4 href=#__codelineno-31-4></a><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>B</span><span class=p>,</span><span class=n>T</span><span class=p>,</span><span class=n>C</span><span class=p>)</span>
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5 href=#__codelineno-31-5></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6 href=#__codelineno-31-6></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span><span id=__span-31-7><a id=__codelineno-31-7 name=__codelineno-31-7 href=#__codelineno-31-7></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a>torch.Size([4, 8, 2])
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a>tensor([[ 0.1808, -0.0700],
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a>        [-0.3596, -0.9152],
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a>        [ 0.6258,  0.0255],
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a>        [ 0.9545,  0.0643],
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6 href=#__codelineno-32-6></a>        [ 0.3612,  1.1679],
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7 href=#__codelineno-32-7></a>        [-1.3499, -0.5102],
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8 href=#__codelineno-32-8></a>        [ 0.2360, -0.2398],
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9 href=#__codelineno-32-9></a>        [-0.9211,  1.5433]])
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10 href=#__codelineno-32-10></a>tensor([[ 0.1808, -0.0700],
</span><span id=__span-32-11><a id=__codelineno-32-11 name=__codelineno-32-11 href=#__codelineno-32-11></a>        [-0.3596, -0.9152]])
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a><span class=c1># x[b,t] = mean_{i&lt;=t} x[b,i] を実現したい</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2 href=#__codelineno-33-2></a><span class=n>xbow</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>B</span><span class=p>,</span><span class=n>T</span><span class=p>,</span><span class=n>C</span><span class=p>))</span>
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3 href=#__codelineno-33-3></a><span class=k>for</span> <span class=n>b</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>B</span><span class=p>):</span>
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4 href=#__codelineno-33-4></a>    <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>T</span><span class=p>):</span>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5 href=#__codelineno-33-5></a>        <span class=n>xprev</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=p>:</span><span class=n>t</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=c1># (t,C)</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6 href=#__codelineno-33-6></a>        <span class=n>xbow</span><span class=p>[</span><span class=n>b</span><span class=p>,</span><span class=n>t</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>xprev</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span><span id=__span-33-7><a id=__codelineno-33-7 name=__codelineno-33-7 href=#__codelineno-33-7></a>
</span><span id=__span-33-8><a id=__codelineno-33-8 name=__codelineno-33-8 href=#__codelineno-33-8></a><span class=nb>print</span><span class=p>(</span><span class=n>xbow</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-33-9><a id=__codelineno-33-9 name=__codelineno-33-9 href=#__codelineno-33-9></a><span class=nb>print</span><span class=p>(</span><span class=n>xbow</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a>torch.Size([4, 8, 2])
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a>tensor([[ 0.1808, -0.0700],
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a>        [-0.0894, -0.4926],
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a>        [ 0.1490, -0.3199],
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>        [ 0.3504, -0.2238],
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a>        [ 0.3525,  0.0545],
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a>        [ 0.0688, -0.0396],
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a>        [ 0.0927, -0.0682],
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>        [-0.0341,  0.1332]])
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a><span class=c1># バージョン2: 重み付き集約に行列乗算を使用</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2 href=#__codelineno-35-2></a><span class=n>wei</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tril</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>T</span><span class=p>,</span><span class=n>T</span><span class=p>))</span>
</span><span id=__span-35-3><a id=__codelineno-35-3 name=__codelineno-35-3 href=#__codelineno-35-3></a><span class=n>wei</span> <span class=o>=</span> <span class=n>wei</span> <span class=o>/</span> <span class=n>wei</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-35-4><a id=__codelineno-35-4 name=__codelineno-35-4 href=#__codelineno-35-4></a><span class=n>xbow2</span> <span class=o>=</span> <span class=n>wei</span> <span class=o>@</span> <span class=n>x</span> <span class=c1># (B,T,T)@(B,T,C)----&gt; (B,T,C)</span>
</span><span id=__span-35-5><a id=__codelineno-35-5 name=__codelineno-35-5 href=#__codelineno-35-5></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>allclose</span><span class=p>(</span><span class=n>xbow</span><span class=p>,</span> <span class=n>xbow2</span><span class=p>))</span>
</span><span id=__span-35-6><a id=__codelineno-35-6 name=__codelineno-35-6 href=#__codelineno-35-6></a>
</span><span id=__span-35-7><a id=__codelineno-35-7 name=__codelineno-35-7 href=#__codelineno-35-7></a><span class=nb>print</span><span class=p>(</span><span class=n>xbow2</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a>True
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a>tensor([[ 0.1808, -0.0700],
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a>        [-0.0894, -0.4926],
</span><span id=__span-36-4><a id=__codelineno-36-4 name=__codelineno-36-4 href=#__codelineno-36-4></a>        [ 0.1490, -0.3199],
</span><span id=__span-36-5><a id=__codelineno-36-5 name=__codelineno-36-5 href=#__codelineno-36-5></a>        [ 0.3504, -0.2238],
</span><span id=__span-36-6><a id=__codelineno-36-6 name=__codelineno-36-6 href=#__codelineno-36-6></a>        [ 0.3525,  0.0545],
</span><span id=__span-36-7><a id=__codelineno-36-7 name=__codelineno-36-7 href=#__codelineno-36-7></a>        [ 0.0688, -0.0396],
</span><span id=__span-36-8><a id=__codelineno-36-8 name=__codelineno-36-8 href=#__codelineno-36-8></a>        [ 0.0927, -0.0682],
</span><span id=__span-36-9><a id=__codelineno-36-9 name=__codelineno-36-9 href=#__codelineno-36-9></a>        [-0.0341,  0.1332]])
</span></code></pre></div></p> <p><strong>形状変換の仕組み</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a>wei.shape = [T, T] = [8, 8]
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2 href=#__codelineno-37-2></a>x.shape = [B, T, C] = [4, 8, 2]
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3 href=#__codelineno-37-3></a>broadcastingにより: [8, 8] → [4, 8, 8]
</span><span id=__span-37-4><a id=__codelineno-37-4 name=__codelineno-37-4 href=#__codelineno-37-4></a>最終結果: [4, 8, 8] @ [4, 8, 2] → [4, 8, 2]
</span></code></pre></div></p> <p><strong>matrix multiplicationのルール</strong></p> <ul> <li>最後の2次元のみが行列乗算に参加 </li> <li>前の次元はバッチ処理（for loopに相当）</li> <li>4次元なら2重for loop、5次元なら3重for loopと同等</li> </ul> <p><strong>weiマトリックスの役割</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a>wei = [[1.0, 0.0, 0.0, ...],   # 時刻0: 自分のみ
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a>       [0.5, 0.5, 0.0, ...],   # 時刻1: 0,1の平均  
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a>       [0.33,0.33,0.33,...],   # 時刻2: 0,1,2の平均
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a>       ...]
</span></code></pre></div></p> <p><strong>なぜこんなに巧みなのか？</strong></p> <p>各行が「集約ルール」を定義している： <div class="language-text highlight"><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1 href=#__codelineno-39-1></a>第0行：自分のみを見る → [1, 0, 0, 0]
</span><span id=__span-39-2><a id=__codelineno-39-2 name=__codelineno-39-2 href=#__codelineno-39-2></a>第1行：自分と前の1つを見る → [0.5, 0.5, 0, 0]
</span><span id=__span-39-3><a id=__codelineno-39-3 name=__codelineno-39-3 href=#__codelineno-39-3></a>第2行：自分と前の2つを見る → [1/3, 1/3, 1/3, 0]
</span></code></pre></div> matrix multiplicationがこれらのルールを自動適用する！</p> <p>これがmatrix multiplicationが深層学習でこれほど中核的な理由 - 複雑な集約操作を優雅に表現できる！</p> <p>次に、<strong>Softmax関数</strong>を使った重み付きを実装してみましょう。Softmaxは、マスキングされていない部分の重みを正規化し、より安定した学習を可能にします。この手法は、実際のTransformerモデルで使用されています。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-40-1><a id=__codelineno-40-1 name=__codelineno-40-1 href=#__codelineno-40-1></a><span class=c1># バージョン3: Softmaxを使用</span>
</span><span id=__span-40-2><a id=__codelineno-40-2 name=__codelineno-40-2 href=#__codelineno-40-2></a><span class=n>tril</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tril</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>T</span><span class=p>,</span><span class=n>T</span><span class=p>))</span>
</span><span id=__span-40-3><a id=__codelineno-40-3 name=__codelineno-40-3 href=#__codelineno-40-3></a><span class=n>wei</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>T</span><span class=p>,</span><span class=n>T</span><span class=p>)</span>
</span><span id=__span-40-4><a id=__codelineno-40-4 name=__codelineno-40-4 href=#__codelineno-40-4></a><span class=n>wei</span> <span class=o>=</span> <span class=n>wei</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>tril</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span>
</span><span id=__span-40-5><a id=__codelineno-40-5 name=__codelineno-40-5 href=#__codelineno-40-5></a><span class=n>wei</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>wei</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-40-6><a id=__codelineno-40-6 name=__codelineno-40-6 href=#__codelineno-40-6></a><span class=n>xbow3</span> <span class=o>=</span> <span class=n>wei</span> <span class=o>@</span> <span class=n>x</span>
</span><span id=__span-40-7><a id=__codelineno-40-7 name=__codelineno-40-7 href=#__codelineno-40-7></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>allclose</span><span class=p>(</span><span class=n>xbow</span><span class=p>,</span><span class=n>xbow3</span><span class=p>))</span>
</span><span id=__span-40-8><a id=__codelineno-40-8 name=__codelineno-40-8 href=#__codelineno-40-8></a><span class=nb>print</span><span class=p>(</span><span class=n>xbow3</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-41-1><a id=__codelineno-41-1 name=__codelineno-41-1 href=#__codelineno-41-1></a>True
</span><span id=__span-41-2><a id=__codelineno-41-2 name=__codelineno-41-2 href=#__codelineno-41-2></a>tensor([[ 0.1808, -0.0700],
</span><span id=__span-41-3><a id=__codelineno-41-3 name=__codelineno-41-3 href=#__codelineno-41-3></a>        [-0.0894, -0.4926],
</span><span id=__span-41-4><a id=__codelineno-41-4 name=__codelineno-41-4 href=#__codelineno-41-4></a>        [ 0.1490, -0.3199],
</span><span id=__span-41-5><a id=__codelineno-41-5 name=__codelineno-41-5 href=#__codelineno-41-5></a>        [ 0.3504, -0.2238],
</span><span id=__span-41-6><a id=__codelineno-41-6 name=__codelineno-41-6 href=#__codelineno-41-6></a>        [ 0.3525,  0.0545],
</span><span id=__span-41-7><a id=__codelineno-41-7 name=__codelineno-41-7 href=#__codelineno-41-7></a>        [ 0.0688, -0.0396],
</span><span id=__span-41-8><a id=__codelineno-41-8 name=__codelineno-41-8 href=#__codelineno-41-8></a>        [ 0.0927, -0.0682],
</span><span id=__span-41-9><a id=__codelineno-41-9 name=__codelineno-41-9 href=#__codelineno-41-9></a>        [-0.0341,  0.1332]])
</span></code></pre></div></p> <h4 id=_10>セルフアテンションヘッドの構築<a class=headerlink href=#_10 title="Permanent link">&para;</a></h4> <p>セルフアテンションヘッドは、Transformerモデルの心臓部であり、文脈を理解するために各トークン（単語や文字）が他のすべてのトークンとの関係を計算する仕組みです。このプロセスは、以下のステップで進みます。</p> <p><strong>1. クエリ、キー、バリューの生成</strong></p> <p>まず、入力された各トークンは、自身の情報を基に3つの異なるベクトル<strong>「クエリ（Query）」、「キー（Key）」、「バリュー（Value）」</strong>を生成します。これらはそれぞれ以下の役割を担います。</p> <ul> <li>クエリ（Query）: 「私は何を探しているか？」という問いを表します。</li> <li>キー（Key）: 「私が何を持っているか？」という情報を含みます。</li> <li>バリュー（Value）: 「何を伝えるべき情報か？」という内容そのものです。</li> </ul> <p>このプロセスでは、nn.Linearレイヤーを使って、入力Xからkey_linear、query_linear、value_linearという3つのベクトルが生成されます。</p> <p><strong>2. アフィニティ（関連度）の計算</strong></p> <p>次に、各トークンのクエリと、他のすべてのトークンのキーの内積（ドット積）を計算します。これにより、それぞれのトークンが互いにどれだけ関連しているかを示す<strong>「アフィニティ行列」</strong>が生成されます。</p> <p>この行列は、モデルがどのトークンを「重要」と見なすべきかを判断する際の土台となります。特に、B x T x head_sizeのクエリとB x head_size x Tのキーを乗算することで、B x T x Tという形状のアフィニティ行列weiが生成されます。この計算により、バッチ内のデータごとに異なる関連度が計算され、データに依存した柔軟な相互作用が可能になります。</p> <p><strong>3. スケーリングとマスキング</strong></p> <p>計算されたアフィニティweiは、sqrt(head_size)で割ることでスケーリングされます。これは、softmax関数を適用する際に値が極端に大きくなりすぎるのを防ぎ、学習を安定させるための重要なステップです。</p> <p>また、文章生成などのタスクでは、未来の情報を参照してしまわないように、マスキングが適用されます。下三角行列を使うことで、各トークンが自身より前のトークンにのみ注意を向けるようになり、予測が過去の文脈にのみ基づく<strong>「オートリグレッシブ」</strong>な性質を保ちます。</p> <p><strong>4. ソフトマックスとバリューの集約</strong></p> <p>スケーリングとマスキングの処理を終えたアフィニティweiにsoftmaxを適用し、それぞれの関連度を正規化された確率分布に変換します。これにより、関連度が0から1の範囲に収まり、<strong>「どれだけ注意を向けるか」</strong>という重み付けが明確になります。</p> <p>最後に、この正規化された重みweiと、各トークンのバリューを行列乗算します。この処理によって、関連性の高いトークンのバリューが「集約」され、文脈を考慮した新たなベクトルが出力されます。このベクトルこそが、セルフアテンションヘッドが「このヘッドの目的のために集約された情報」です。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-42-1><a id=__codelineno-42-1 name=__codelineno-42-1 href=#__codelineno-42-1></a><span class=c1># バージョン4: セルフアテンション！</span>
</span><span id=__span-42-2><a id=__codelineno-42-2 name=__codelineno-42-2 href=#__codelineno-42-2></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>1337</span><span class=p>)</span>
</span><span id=__span-42-3><a id=__codelineno-42-3 name=__codelineno-42-3 href=#__codelineno-42-3></a><span class=n>B</span><span class=p>,</span><span class=n>T</span><span class=p>,</span><span class=n>C</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span><span class=mi>8</span><span class=p>,</span><span class=mi>32</span> <span class=c1># バッチ、時間、チャンネル</span>
</span><span id=__span-42-4><a id=__codelineno-42-4 name=__codelineno-42-4 href=#__codelineno-42-4></a><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>B</span><span class=p>,</span><span class=n>T</span><span class=p>,</span><span class=n>C</span><span class=p>)</span>
</span><span id=__span-42-5><a id=__codelineno-42-5 name=__codelineno-42-5 href=#__codelineno-42-5></a>
</span><span id=__span-42-6><a id=__codelineno-42-6 name=__codelineno-42-6 href=#__codelineno-42-6></a><span class=c1># 単一のヘッドでセルフアテンションを実行してみよう</span>
</span><span id=__span-42-7><a id=__codelineno-42-7 name=__codelineno-42-7 href=#__codelineno-42-7></a><span class=n>head_size</span> <span class=o>=</span> <span class=mi>16</span>
</span><span id=__span-42-8><a id=__codelineno-42-8 name=__codelineno-42-8 href=#__codelineno-42-8></a><span class=n>key</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-42-9><a id=__codelineno-42-9 name=__codelineno-42-9 href=#__codelineno-42-9></a><span class=n>query</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-42-10><a id=__codelineno-42-10 name=__codelineno-42-10 href=#__codelineno-42-10></a><span class=n>value</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-42-11><a id=__codelineno-42-11 name=__codelineno-42-11 href=#__codelineno-42-11></a><span class=n>k</span> <span class=o>=</span> <span class=n>key</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, 16)</span>
</span><span id=__span-42-12><a id=__codelineno-42-12 name=__codelineno-42-12 href=#__codelineno-42-12></a><span class=n>q</span> <span class=o>=</span> <span class=n>query</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, 16)</span>
</span><span id=__span-42-13><a id=__codelineno-42-13 name=__codelineno-42-13 href=#__codelineno-42-13></a><span class=n>wei</span> <span class=o>=</span> <span class=n>q</span> <span class=o>@</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, T, 16)@(B, 16, T) ---&gt; (B, T, T)</span>
</span><span id=__span-42-14><a id=__codelineno-42-14 name=__codelineno-42-14 href=#__codelineno-42-14></a>
</span><span id=__span-42-15><a id=__codelineno-42-15 name=__codelineno-42-15 href=#__codelineno-42-15></a><span class=n>tril</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tril</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>T</span><span class=p>))</span>
</span><span id=__span-42-16><a id=__codelineno-42-16 name=__codelineno-42-16 href=#__codelineno-42-16></a><span class=c1># wei = torch.zeros((T,T))</span>
</span><span id=__span-42-17><a id=__codelineno-42-17 name=__codelineno-42-17 href=#__codelineno-42-17></a><span class=n>wei</span> <span class=o>=</span> <span class=n>wei</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>tril</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span>
</span><span id=__span-42-18><a id=__codelineno-42-18 name=__codelineno-42-18 href=#__codelineno-42-18></a><span class=n>wei</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>wei</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># [4, 8, 8]</span>
</span><span id=__span-42-19><a id=__codelineno-42-19 name=__codelineno-42-19 href=#__codelineno-42-19></a>
</span><span id=__span-42-20><a id=__codelineno-42-20 name=__codelineno-42-20 href=#__codelineno-42-20></a><span class=n>v</span> <span class=o>=</span> <span class=n>value</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># [4, 8, 16]</span>
</span><span id=__span-42-21><a id=__codelineno-42-21 name=__codelineno-42-21 href=#__codelineno-42-21></a><span class=n>out</span> <span class=o>=</span> <span class=n>wei</span> <span class=o>@</span> <span class=n>v</span> <span class=c1>#  [4, 8, 8]@ [4, 8, 16] -&gt; [4, 8, 16]</span>
</span><span id=__span-42-22><a id=__codelineno-42-22 name=__codelineno-42-22 href=#__codelineno-42-22></a>
</span><span id=__span-42-23><a id=__codelineno-42-23 name=__codelineno-42-23 href=#__codelineno-42-23></a><span class=n>wei</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-43-1><a id=__codelineno-43-1 name=__codelineno-43-1 href=#__codelineno-43-1></a>tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
</span><span id=__span-43-2><a id=__codelineno-43-2 name=__codelineno-43-2 href=#__codelineno-43-2></a>        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
</span><span id=__span-43-3><a id=__codelineno-43-3 name=__codelineno-43-3 href=#__codelineno-43-3></a>        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
</span><span id=__span-43-4><a id=__codelineno-43-4 name=__codelineno-43-4 href=#__codelineno-43-4></a>        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],
</span><span id=__span-43-5><a id=__codelineno-43-5 name=__codelineno-43-5 href=#__codelineno-43-5></a>        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],
</span><span id=__span-43-6><a id=__codelineno-43-6 name=__codelineno-43-6 href=#__codelineno-43-6></a>        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],
</span><span id=__span-43-7><a id=__codelineno-43-7 name=__codelineno-43-7 href=#__codelineno-43-7></a>        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],
</span><span id=__span-43-8><a id=__codelineno-43-8 name=__codelineno-43-8 href=#__codelineno-43-8></a>        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],
</span><span id=__span-43-9><a id=__codelineno-43-9 name=__codelineno-43-9 href=#__codelineno-43-9></a>       grad_fn=&lt;SelectBackward0&gt;)
</span></code></pre></div></p> <h4 id=_11>アテンションに関する注意点<a class=headerlink href=#_11 title="Permanent link">&para;</a></h4> <ul> <li><strong>通信メカニズム</strong>: アテンションは、指向性グラフ内のノード間の通信メカニズムとして機能する</li> <li><strong>空間の概念がない</strong>: アテンションはデフォルトで空間の概念を持たないため、位置エンコーディングが必要</li> <li><strong>バッチ次元の独立性</strong>: バッチ内の各例は独立して処理される</li> <li><strong>デコーダーブロック</strong>（我々の実装）: 未来のトークンからの通信をマスクする（オートリグレッシブ）</li> <li><strong>エンコーダーブロック</strong>: 全てのノードが完全に通信できる（マスクなし）</li> <li><strong>自己注意（Self-Attention）</strong>: クエリ、キー、バリューが全て同じソースから生成される</li> <li><strong>交差注意（Cross-Attention）</strong>: クエリが自身のソースから、キーとバリューが外部ソースから生成される（例：エンコーダー・デコーダーTransformer）</li> </ul> <h3 id=42-self-attention>4.2 Self-Attentionヘッドの統合<a class=headerlink href=#42-self-attention title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-44-1><a id=__codelineno-44-1 name=__codelineno-44-1 href=#__codelineno-44-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-44-2><a id=__codelineno-44-2 name=__codelineno-44-2 href=#__codelineno-44-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-44-3><a id=__codelineno-44-3 name=__codelineno-44-3 href=#__codelineno-44-3></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=kn>import</span> <span class=n>functional</span> <span class=k>as</span> <span class=n>F</span>
</span><span id=__span-44-4><a id=__codelineno-44-4 name=__codelineno-44-4 href=#__codelineno-44-4></a>
</span><span id=__span-44-5><a id=__codelineno-44-5 name=__codelineno-44-5 href=#__codelineno-44-5></a><span class=c1># ハイパーパラメータの設定</span>
</span><span id=__span-44-6><a id=__codelineno-44-6 name=__codelineno-44-6 href=#__codelineno-44-6></a><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>16</span> <span class=c1># 並列処理する独立シーケンスの数</span>
</span><span id=__span-44-7><a id=__codelineno-44-7 name=__codelineno-44-7 href=#__codelineno-44-7></a><span class=n>block_size</span> <span class=o>=</span> <span class=mi>32</span> <span class=c1># 予測のための最大コンテキスト長</span>
</span><span id=__span-44-8><a id=__codelineno-44-8 name=__codelineno-44-8 href=#__codelineno-44-8></a><span class=n>max_iters</span> <span class=o>=</span> <span class=mi>5000</span>
</span><span id=__span-44-9><a id=__codelineno-44-9 name=__codelineno-44-9 href=#__codelineno-44-9></a><span class=n>eval_interval</span> <span class=o>=</span> <span class=mi>100</span>
</span><span id=__span-44-10><a id=__codelineno-44-10 name=__codelineno-44-10 href=#__codelineno-44-10></a><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>1e-3</span>
</span><span id=__span-44-11><a id=__codelineno-44-11 name=__codelineno-44-11 href=#__codelineno-44-11></a><span class=n>device</span> <span class=o>=</span> <span class=s1>&#39;mps&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span>
</span><span id=__span-44-12><a id=__codelineno-44-12 name=__codelineno-44-12 href=#__codelineno-44-12></a><span class=n>eval_iters</span> <span class=o>=</span> <span class=mi>200</span>
</span><span id=__span-44-13><a id=__codelineno-44-13 name=__codelineno-44-13 href=#__codelineno-44-13></a><span class=n>n_embd</span> <span class=o>=</span> <span class=mi>64</span>
</span><span id=__span-44-14><a id=__codelineno-44-14 name=__codelineno-44-14 href=#__codelineno-44-14></a><span class=n>n_head</span> <span class=o>=</span> <span class=mi>4</span>
</span><span id=__span-44-15><a id=__codelineno-44-15 name=__codelineno-44-15 href=#__codelineno-44-15></a><span class=n>n_layer</span> <span class=o>=</span> <span class=mi>4</span>
</span><span id=__span-44-16><a id=__codelineno-44-16 name=__codelineno-44-16 href=#__codelineno-44-16></a><span class=n>dropout</span> <span class=o>=</span> <span class=mf>0.0</span>
</span><span id=__span-44-17><a id=__codelineno-44-17 name=__codelineno-44-17 href=#__codelineno-44-17></a>
</span><span id=__span-44-18><a id=__codelineno-44-18 name=__codelineno-44-18 href=#__codelineno-44-18></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>1337</span><span class=p>)</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-45-1><a id=__codelineno-45-1 name=__codelineno-45-1 href=#__codelineno-45-1></a><span class=k>def</span><span class=w> </span><span class=nf>get_batch</span><span class=p>(</span><span class=n>split</span><span class=p>):</span>
</span><span id=__span-45-2><a id=__codelineno-45-2 name=__codelineno-45-2 href=#__codelineno-45-2></a>    <span class=c1># データセットの選択：trainまたはvalidation</span>
</span><span id=__span-45-3><a id=__codelineno-45-3 name=__codelineno-45-3 href=#__codelineno-45-3></a>    <span class=n>data</span> <span class=o>=</span> <span class=n>train_data</span> <span class=k>if</span> <span class=n>split</span> <span class=o>==</span> <span class=s1>&#39;train&#39;</span> <span class=k>else</span> <span class=n>val_data</span>
</span><span id=__span-45-4><a id=__codelineno-45-4 name=__codelineno-45-4 href=#__codelineno-45-4></a>
</span><span id=__span-45-5><a id=__codelineno-45-5 name=__codelineno-45-5 href=#__codelineno-45-5></a>    <span class=c1># ランダムな開始位置を生成（batch_size個）</span>
</span><span id=__span-45-6><a id=__codelineno-45-6 name=__codelineno-45-6 href=#__codelineno-45-6></a>    <span class=c1># len(data) - block_sizeにすることで、境界オーバーを防ぐ</span>
</span><span id=__span-45-7><a id=__codelineno-45-7 name=__codelineno-45-7 href=#__codelineno-45-7></a>    <span class=n>ix</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span> <span class=o>-</span> <span class=n>block_size</span><span class=p>,</span> <span class=p>(</span><span class=n>batch_size</span><span class=p>,))</span>  
</span><span id=__span-45-8><a id=__codelineno-45-8 name=__codelineno-45-8 href=#__codelineno-45-8></a>
</span><span id=__span-45-9><a id=__codelineno-45-9 name=__codelineno-45-9 href=#__codelineno-45-9></a>    <span class=c1># 入力シーケンス（x）：各開始位置からblock_size分のデータを取得</span>
</span><span id=__span-45-10><a id=__codelineno-45-10 name=__codelineno-45-10 href=#__codelineno-45-10></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>block_size</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ix</span><span class=p>])</span> 
</span><span id=__span-45-11><a id=__codelineno-45-11 name=__codelineno-45-11 href=#__codelineno-45-11></a>
</span><span id=__span-45-12><a id=__codelineno-45-12 name=__codelineno-45-12 href=#__codelineno-45-12></a>    <span class=c1># ターゲットシーケンス（y）：xより1つずつ後ろにシフトしたデータ</span>
</span><span id=__span-45-13><a id=__codelineno-45-13 name=__codelineno-45-13 href=#__codelineno-45-13></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>block_size</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ix</span><span class=p>])</span>  
</span><span id=__span-45-14><a id=__codelineno-45-14 name=__codelineno-45-14 href=#__codelineno-45-14></a>    <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-45-15><a id=__codelineno-45-15 name=__codelineno-45-15 href=#__codelineno-45-15></a>    <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span>  <span class=c1># (batch_size, block_size)の形状で返す</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-46-1><a id=__codelineno-46-1 name=__codelineno-46-1 href=#__codelineno-46-1></a><span class=k>class</span><span class=w> </span><span class=nc>Head</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-46-2><a id=__codelineno-46-2 name=__codelineno-46-2 href=#__codelineno-46-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;一つの自己注意ヘッド&quot;&quot;&quot;</span>
</span><span id=__span-46-3><a id=__codelineno-46-3 name=__codelineno-46-3 href=#__codelineno-46-3></a>
</span><span id=__span-46-4><a id=__codelineno-46-4 name=__codelineno-46-4 href=#__codelineno-46-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>head_size</span><span class=p>):</span>
</span><span id=__span-46-5><a id=__codelineno-46-5 name=__codelineno-46-5 href=#__codelineno-46-5></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-46-6><a id=__codelineno-46-6 name=__codelineno-46-6 href=#__codelineno-46-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>key</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-46-7><a id=__codelineno-46-7 name=__codelineno-46-7 href=#__codelineno-46-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>value</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-46-8><a id=__codelineno-46-8 name=__codelineno-46-8 href=#__codelineno-46-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>query</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-46-9><a id=__codelineno-46-9 name=__codelineno-46-9 href=#__codelineno-46-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>&#39;tril&#39;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>tril</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>block_size</span><span class=p>,</span> <span class=n>block_size</span><span class=p>)))</span>
</span><span id=__span-46-10><a id=__codelineno-46-10 name=__codelineno-46-10 href=#__codelineno-46-10></a>
</span><span id=__span-46-11><a id=__codelineno-46-11 name=__codelineno-46-11 href=#__codelineno-46-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-46-12><a id=__codelineno-46-12 name=__codelineno-46-12 href=#__codelineno-46-12></a>
</span><span id=__span-46-13><a id=__codelineno-46-13 name=__codelineno-46-13 href=#__codelineno-46-13></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-46-14><a id=__codelineno-46-14 name=__codelineno-46-14 href=#__codelineno-46-14></a>        <span class=c1># サイズ(batch, time-step, channels)の入力</span>
</span><span id=__span-46-15><a id=__codelineno-46-15 name=__codelineno-46-15 href=#__codelineno-46-15></a>        <span class=c1># サイズ(batch, time-step, head size)の出力</span>
</span><span id=__span-46-16><a id=__codelineno-46-16 name=__codelineno-46-16 href=#__codelineno-46-16></a>        <span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-46-17><a id=__codelineno-46-17 name=__codelineno-46-17 href=#__codelineno-46-17></a>        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>key</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, hs)</span>
</span><span id=__span-46-18><a id=__codelineno-46-18 name=__codelineno-46-18 href=#__codelineno-46-18></a>        <span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, hs)</span>
</span><span id=__span-46-19><a id=__codelineno-46-19 name=__codelineno-46-19 href=#__codelineno-46-19></a>        <span class=c1># アテンションスコア（「アフィニティ」）を計算</span>
</span><span id=__span-46-20><a id=__codelineno-46-20 name=__codelineno-46-20 href=#__codelineno-46-20></a>        <span class=n>wei</span> <span class=o>=</span> <span class=n>q</span> <span class=o>@</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>k</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>**-</span><span class=mf>0.5</span> <span class=c1># (B, T, hs) -&gt; (B, T, T)</span>
</span><span id=__span-46-21><a id=__codelineno-46-21 name=__codelineno-46-21 href=#__codelineno-46-21></a>        <span class=n>wei</span> <span class=o>=</span> <span class=n>wei</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tril</span><span class=p>[:</span><span class=n>T</span><span class=p>,</span> <span class=p>:</span><span class=n>T</span><span class=p>]</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span> <span class=c1># (B, T, T)</span>
</span><span id=__span-46-22><a id=__codelineno-46-22 name=__codelineno-46-22 href=#__codelineno-46-22></a>        <span class=n>wei</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>wei</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, T, T)</span>
</span><span id=__span-46-23><a id=__codelineno-46-23 name=__codelineno-46-23 href=#__codelineno-46-23></a>        <span class=n>wei</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>wei</span><span class=p>)</span>
</span><span id=__span-46-24><a id=__codelineno-46-24 name=__codelineno-46-24 href=#__codelineno-46-24></a>        <span class=c1># バリューの重み付き集約を実行</span>
</span><span id=__span-46-25><a id=__codelineno-46-25 name=__codelineno-46-25 href=#__codelineno-46-25></a>        <span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>value</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, hs)</span>
</span><span id=__span-46-26><a id=__codelineno-46-26 name=__codelineno-46-26 href=#__codelineno-46-26></a>        <span class=n>out</span> <span class=o>=</span> <span class=n>wei</span> <span class=o>@</span> <span class=n>v</span> <span class=c1># (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)</span>
</span><span id=__span-46-27><a id=__codelineno-46-27 name=__codelineno-46-27 href=#__codelineno-46-27></a>        <span class=k>return</span> <span class=n>out</span>
</span></code></pre></div> <div class="admonition tip"> <p class=admonition-title>なぜ√d_kで除算するのか？</p> <p>これはスケール内積注意力の重要な技術：</p> <ul> <li>次元d_kが大きい時、内積の分散が大きくなる</li> <li>大きな内積値はsoftmax後に極端な重み分布を生成</li> <li>√d_kで除算することで内積の分散を制御し、勾配をより安定させる 数学的に：ベクトル要素が独立同分布の場合、d_k次元内積の分散は約d_kです。</li> </ul> </div> <h2 id=5-transformer>5. マルチヘッドアテンションとTransformerブロック<a class=headerlink href=#5-transformer title="Permanent link">&para;</a></h2> <h3 id=51-multi-head-attention>5.1 Multi-Head Attention<a class=headerlink href=#51-multi-head-attention title="Permanent link">&para;</a></h3> <p>複数の自己注意ヘッドを並列に実行し、その結果を連結する。 各ヘッドは異なる「通信チャネル」として機能し、異なるタイプの特徴を学習できます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-47-1><a id=__codelineno-47-1 name=__codelineno-47-1 href=#__codelineno-47-1></a><span class=k>class</span><span class=w> </span><span class=nc>MultiHeadAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-47-2><a id=__codelineno-47-2 name=__codelineno-47-2 href=#__codelineno-47-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;複数の自己注意ヘッドを並列実行&quot;&quot;&quot;</span>
</span><span id=__span-47-3><a id=__codelineno-47-3 name=__codelineno-47-3 href=#__codelineno-47-3></a>
</span><span id=__span-47-4><a id=__codelineno-47-4 name=__codelineno-47-4 href=#__codelineno-47-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>head_size</span><span class=p>):</span>
</span><span id=__span-47-5><a id=__codelineno-47-5 name=__codelineno-47-5 href=#__codelineno-47-5></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-47-6><a id=__codelineno-47-6 name=__codelineno-47-6 href=#__codelineno-47-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>heads</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span><span class=n>Head</span><span class=p>(</span><span class=n>head_size</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_heads</span><span class=p>)])</span>
</span><span id=__span-47-7><a id=__codelineno-47-7 name=__codelineno-47-7 href=#__codelineno-47-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>head_size</span> <span class=o>*</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-47-8><a id=__codelineno-47-8 name=__codelineno-47-8 href=#__codelineno-47-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-47-9><a id=__codelineno-47-9 name=__codelineno-47-9 href=#__codelineno-47-9></a>
</span><span id=__span-47-10><a id=__codelineno-47-10 name=__codelineno-47-10 href=#__codelineno-47-10></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-47-11><a id=__codelineno-47-11 name=__codelineno-47-11 href=#__codelineno-47-11></a>        <span class=n>out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>h</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>h</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-47-12><a id=__codelineno-47-12 name=__codelineno-47-12 href=#__codelineno-47-12></a>        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>proj</span><span class=p>(</span><span class=n>out</span><span class=p>))</span>
</span><span id=__span-47-13><a id=__codelineno-47-13 name=__codelineno-47-13 href=#__codelineno-47-13></a>        <span class=k>return</span> <span class=n>out</span>
</span></code></pre></div> <h3 id=52-feed-forward-network-mlp>5.2 Feed-Forward Network (MLP)<a class=headerlink href=#52-feed-forward-network-mlp title="Permanent link">&para;</a></h3> <p>マルチヘッド自己注意の後に配置されるシンプルな多層パーセプトロン（MLP）。</p> <ul> <li>nn.Linear、ReLU非線形性で構成される</li> <li>トークンは、通信で得た情報を個別に「考える」ための時間と計算能力を得る</li> <li>トークンごとに独立して適用される</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-48-1><a id=__codelineno-48-1 name=__codelineno-48-1 href=#__codelineno-48-1></a><span class=k>class</span><span class=w> </span><span class=nc>FeedFoward</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-48-2><a id=__codelineno-48-2 name=__codelineno-48-2 href=#__codelineno-48-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;非線形性を伴うシンプルな線形層&quot;&quot;&quot;</span>
</span><span id=__span-48-3><a id=__codelineno-48-3 name=__codelineno-48-3 href=#__codelineno-48-3></a>
</span><span id=__span-48-4><a id=__codelineno-48-4 name=__codelineno-48-4 href=#__codelineno-48-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>):</span>
</span><span id=__span-48-5><a id=__codelineno-48-5 name=__codelineno-48-5 href=#__codelineno-48-5></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-48-6><a id=__codelineno-48-6 name=__codelineno-48-6 href=#__codelineno-48-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-48-7><a id=__codelineno-48-7 name=__codelineno-48-7 href=#__codelineno-48-7></a>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>),</span>
</span><span id=__span-48-8><a id=__codelineno-48-8 name=__codelineno-48-8 href=#__codelineno-48-8></a>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-48-9><a id=__codelineno-48-9 name=__codelineno-48-9 href=#__codelineno-48-9></a>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>),</span>
</span><span id=__span-48-10><a id=__codelineno-48-10 name=__codelineno-48-10 href=#__codelineno-48-10></a>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-48-11><a id=__codelineno-48-11 name=__codelineno-48-11 href=#__codelineno-48-11></a>        <span class=p>)</span>
</span><span id=__span-48-12><a id=__codelineno-48-12 name=__codelineno-48-12 href=#__codelineno-48-12></a>
</span><span id=__span-48-13><a id=__codelineno-48-13 name=__codelineno-48-13 href=#__codelineno-48-13></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-48-14><a id=__codelineno-48-14 name=__codelineno-48-14 href=#__codelineno-48-14></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>net</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></code></pre></div> <h3 id=53-transformer>5.3 Transformerブロックの構築と最適化<a class=headerlink href=#53-transformer title="Permanent link">&para;</a></h3> <p>Transformerブロック:Multi-Head Self-AttentionとFeed-Forward Networkを組み合わせたもの。</p> <p>通信（Self-Attention）と計算（Feed-Forward）を交互に行います。</p> <p>複数のブロックをシーケンシャルに適用することで、より深いネットワークを構築します。</p> <p><strong>残差接続（Residual Connections / Skip Connections）</strong>: x = x + self.attention(x)のように、変換されたデータに入力データを直接加算します。</p> <p>勾配がネットワークの深い層まで妨げられずに流れる「スーパーハイウェイ」を提供し、最適化を劇的に改善します。</p> <p>ブロック内の各部分の後に適用されます。</p> <p>出力層への「プロジェクション」（nn.Linear）を導入します。</p> <p><strong>レイヤー正規化（Layer Normalization）</strong>: batch_normに似ていますが、バッチ次元ではなく特徴次元（行）に沿って正規化を行います。</p> <p><strong>ドロップアウト（Dropout）</strong>: 訓練中にランダムに一部のニューロンを無効にする（ゼロに設定する）正則化技術です。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-49-1><a id=__codelineno-49-1 name=__codelineno-49-1 href=#__codelineno-49-1></a><span class=k>class</span><span class=w> </span><span class=nc>Block</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-49-2><a id=__codelineno-49-2 name=__codelineno-49-2 href=#__codelineno-49-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Transformerブロック: 通信の後に計算を行う&quot;&quot;&quot;</span>
</span><span id=__span-49-3><a id=__codelineno-49-3 name=__codelineno-49-3 href=#__codelineno-49-3></a>
</span><span id=__span-49-4><a id=__codelineno-49-4 name=__codelineno-49-4 href=#__codelineno-49-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>):</span>
</span><span id=__span-49-5><a id=__codelineno-49-5 name=__codelineno-49-5 href=#__codelineno-49-5></a>        <span class=c1># n_embd: 埋め込み次元, n_head: 使用したいヘッド数</span>
</span><span id=__span-49-6><a id=__codelineno-49-6 name=__codelineno-49-6 href=#__codelineno-49-6></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-49-7><a id=__codelineno-49-7 name=__codelineno-49-7 href=#__codelineno-49-7></a>        <span class=n>head_size</span> <span class=o>=</span> <span class=n>n_embd</span> <span class=o>//</span> <span class=n>n_head</span>
</span><span id=__span-49-8><a id=__codelineno-49-8 name=__codelineno-49-8 href=#__codelineno-49-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>sa</span> <span class=o>=</span> <span class=n>MultiHeadAttention</span><span class=p>(</span><span class=n>n_head</span><span class=p>,</span> <span class=n>head_size</span><span class=p>)</span>
</span><span id=__span-49-9><a id=__codelineno-49-9 name=__codelineno-49-9 href=#__codelineno-49-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ffwd</span> <span class=o>=</span> <span class=n>FeedFoward</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-49-10><a id=__codelineno-49-10 name=__codelineno-49-10 href=#__codelineno-49-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ln1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-49-11><a id=__codelineno-49-11 name=__codelineno-49-11 href=#__codelineno-49-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ln2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-49-12><a id=__codelineno-49-12 name=__codelineno-49-12 href=#__codelineno-49-12></a>
</span><span id=__span-49-13><a id=__codelineno-49-13 name=__codelineno-49-13 href=#__codelineno-49-13></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-49-14><a id=__codelineno-49-14 name=__codelineno-49-14 href=#__codelineno-49-14></a>        <span class=c1># 残差接続</span>
</span><span id=__span-49-15><a id=__codelineno-49-15 name=__codelineno-49-15 href=#__codelineno-49-15></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>sa</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-49-16><a id=__codelineno-49-16 name=__codelineno-49-16 href=#__codelineno-49-16></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>ffwd</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-49-17><a id=__codelineno-49-17 name=__codelineno-49-17 href=#__codelineno-49-17></a>        <span class=k>return</span> <span class=n>x</span>
</span></code></pre></div> <p><strong>Pre-Norm vs Post-Norm アーキテクチャの比較</strong></p> <p><strong>原始Transformer (Post-Norm, 2017)</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-50-1><a id=__codelineno-50-1 name=__codelineno-50-1 href=#__codelineno-50-1></a><span class=c1># Attention is All You Need の設計</span>
</span><span id=__span-50-2><a id=__codelineno-50-2 name=__codelineno-50-2 href=#__codelineno-50-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>embedding</span> <span class=o>+</span> <span class=n>positional_encoding</span>
</span><span id=__span-50-3><a id=__codelineno-50-3 name=__codelineno-50-3 href=#__codelineno-50-3></a><span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln1</span><span class=p>(</span><span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>sa</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>        <span class=c1># LayerNormが残差接続の後</span>
</span><span id=__span-50-4><a id=__codelineno-50-4 name=__codelineno-50-4 href=#__codelineno-50-4></a><span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln2</span><span class=p>(</span><span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>ffwd</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>      <span class=c1># LayerNormが残差接続の後</span>
</span></code></pre></div></p> <p><strong>現代GPT (Pre-Norm)</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-51-1><a id=__codelineno-51-1 name=__codelineno-51-1 href=#__codelineno-51-1></a><span class=c1># GPTシリーズの設計</span>
</span><span id=__span-51-2><a id=__codelineno-51-2 name=__codelineno-51-2 href=#__codelineno-51-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>embedding</span> <span class=o>+</span> <span class=n>positional_encoding</span>  
</span><span id=__span-51-3><a id=__codelineno-51-3 name=__codelineno-51-3 href=#__codelineno-51-3></a><span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>sa</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>        <span class=c1># LayerNormがモジュールの前</span>
</span><span id=__span-51-4><a id=__codelineno-51-4 name=__codelineno-51-4 href=#__codelineno-51-4></a><span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>ffwd</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>      <span class=c1># LayerNormがモジュールの前</span>
</span></code></pre></div></p> <p><strong>なぜ変化したのか？</strong></p> <p><strong>Post-Normの問題点:</strong> - 深層ネットワークで勾配消失が起こりやすい - 勾配がLayerNormを通過する際に弱くなる - 学習率のウォームアップが必要</p> <p><strong>Pre-Normの利点:</strong> - 直接的な勾配パス: x = x + module(ln(x)) で恒等写像が保証される - 深層ネットワークの安定訓練: 12層以上でも安定 - 学習の高速化: より大きな学習率を使用可能 - 勾配爆発の抑制: 数値的により安定</p> <p><strong>実用的な違い</strong> - 原始Transformer: 機械翻訳など（比較的浅層） - GPT: 言語生成タスク（深層ネットワーク必須）</p> <p><strong>現在の主流</strong></p> <p>現代の大規模言語モデル（GPT、BERT変種など）は、深層ネットワークの訓練安定性のためPre-Normアーキテクチャを採用している。</p> <h3 id=54-positional-encoding>5.4 位置エンコーディング（Positional Encoding）の重要性<a class=headerlink href=#54-positional-encoding title="Permanent link">&para;</a></h3> <p>Transformerアーキテクチャでは、<strong>位置エンコーディング</strong>が極めて重要な役割を果たします。</p> <h4 id=_12>なぜ位置情報が必要なのか？<a class=headerlink href=#_12 title="Permanent link">&para;</a></h4> <p><strong>1. Self-Attentionの性質</strong></p> <p>Self-Attentionは全てのトークン間の関係を並列計算しますが、この処理には<strong>順序の概念</strong>がありません。言い換えると、「私は学校に行く」と「学校に私は行く」を同じものとして扱ってしまう可能性があります。</p> <p><strong>2. バッグオブワード問題</strong></p> <p>位置情報がない場合、モデルは単語の「袋（bag）」として文章を理解し、文法や語順による意味の違いを捉えることができません。</p> <p><strong>3. 文脈の理解</strong></p> <p>言語において、単語の位置は意味に大きく影響します。例えば： - 「田中さんは山田さんを紹介した」 - 「山田さんは田中さんを紹介した」</p> <p>これらは語順によって全く意味が異なります。</p> <h4 id=_13>位置エンコーディングの仕組み<a class=headerlink href=#_13 title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-52-1><a id=__codelineno-52-1 name=__codelineno-52-1 href=#__codelineno-52-1></a><span class=c1># 位置エンコーディングの実装例</span>
</span><span id=__span-52-2><a id=__codelineno-52-2 name=__codelineno-52-2 href=#__codelineno-52-2></a><span class=n>pos_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>position_embedding_table</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>))</span> <span class=c1># (T, C)</span>
</span><span id=__span-52-3><a id=__codelineno-52-3 name=__codelineno-52-3 href=#__codelineno-52-3></a><span class=n>x</span> <span class=o>=</span> <span class=n>tok_emb</span> <span class=o>+</span> <span class=n>pos_emb</span> <span class=c1># トークン埋め込みと位置埋め込みの加算</span>
</span></code></pre></div> <p>この加算により、各トークンは「何の単語か」と「どの位置にあるか」の両方の情報を持つことになります。</p> <div class="admonition tip"> <p class=admonition-title>学習可能な位置エンコーディング vs 固定位置エンコーディング</p> <ul> <li><strong>学習可能</strong>（我々の実装）: nn.Embeddingで位置ごとに異なるベクトルを学習</li> <li><strong>固定式</strong>（原論文）: sin/cos関数を使用した数学的パターン</li> </ul> <p>学習可能な方式は、特定のデータセットに最適化される利点がありますが、最大系列長が固定されるという制約があります。</p> </div> <h2 id=6-gpt>6. 完全なGPTモデルの構築<a class=headerlink href=#6-gpt title="Permanent link">&para;</a></h2> <h3 id=61-gpt>6.1 GPTモデルの実装<a class=headerlink href=#61-gpt title="Permanent link">&para;</a></h3> <p>以下では、これまで学習したすべてのコンポーネントを統合してGPTモデルを実装します。</p> <p><strong>主要コンポーネント</strong>:</p> <ul> <li>トークン埋め込み（Token Embedding）</li> <li>位置埋め込み（Position Embedding） </li> <li>Multi-Head Self-Attention</li> <li>Feed-Forward Networks</li> <li>Layer Normalization</li> <li>残差接続（Residual Connections）</li> <li>適切な重み初期化</li> </ul> <p>以下では、実際のGPTモデルの実装を通してこれらを統合していきます：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-53-1><a id=__codelineno-53-1 name=__codelineno-53-1 href=#__codelineno-53-1></a><span class=k>class</span><span class=w> </span><span class=nc>GPTLanguageModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-53-2><a id=__codelineno-53-2 name=__codelineno-53-2 href=#__codelineno-53-2></a>
</span><span id=__span-53-3><a id=__codelineno-53-3 name=__codelineno-53-3 href=#__codelineno-53-3></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-53-4><a id=__codelineno-53-4 name=__codelineno-53-4 href=#__codelineno-53-4></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-53-5><a id=__codelineno-53-5 name=__codelineno-53-5 href=#__codelineno-53-5></a>        <span class=c1># 各トークンは、埋め込み層から次のトークンのロジットを直接読み取る</span>
</span><span id=__span-53-6><a id=__codelineno-53-6 name=__codelineno-53-6 href=#__codelineno-53-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding_table</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-53-7><a id=__codelineno-53-7 name=__codelineno-53-7 href=#__codelineno-53-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>position_embbedding_table</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>block_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-53-8><a id=__codelineno-53-8 name=__codelineno-53-8 href=#__codelineno-53-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>blocks</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span><span class=n>Block</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_layer</span><span class=p>)])</span>
</span><span id=__span-53-9><a id=__codelineno-53-9 name=__codelineno-53-9 href=#__codelineno-53-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span> <span class=c1># 最終レイヤー正規化</span>
</span><span id=__span-53-10><a id=__codelineno-53-10 name=__codelineno-53-10 href=#__codelineno-53-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>)</span>
</span><span id=__span-53-11><a id=__codelineno-53-11 name=__codelineno-53-11 href=#__codelineno-53-11></a>
</span><span id=__span-53-12><a id=__codelineno-53-12 name=__codelineno-53-12 href=#__codelineno-53-12></a>        <span class=c1># 重み初期化は訓練の成功に極めて重要</span>
</span><span id=__span-53-13><a id=__codelineno-53-13 name=__codelineno-53-13 href=#__codelineno-53-13></a>        <span class=bp>self</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_init_weights</span><span class=p>)</span>
</span><span id=__span-53-14><a id=__codelineno-53-14 name=__codelineno-53-14 href=#__codelineno-53-14></a>
</span><span id=__span-53-15><a id=__codelineno-53-15 name=__codelineno-53-15 href=#__codelineno-53-15></a>    <span class=k>def</span><span class=w> </span><span class=nf>_init_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>module</span><span class=p>):</span>
</span><span id=__span-53-16><a id=__codelineno-53-16 name=__codelineno-53-16 href=#__codelineno-53-16></a>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span><span id=__span-53-17><a id=__codelineno-53-17 name=__codelineno-53-17 href=#__codelineno-53-17></a>            <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-53-18><a id=__codelineno-53-18 name=__codelineno-53-18 href=#__codelineno-53-18></a>            <span class=k>if</span> <span class=n>module</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-53-19><a id=__codelineno-53-19 name=__codelineno-53-19 href=#__codelineno-53-19></a>                <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span><span id=__span-53-20><a id=__codelineno-53-20 name=__codelineno-53-20 href=#__codelineno-53-20></a>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>):</span>
</span><span id=__span-53-21><a id=__codelineno-53-21 name=__codelineno-53-21 href=#__codelineno-53-21></a>            <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-53-22><a id=__codelineno-53-22 name=__codelineno-53-22 href=#__codelineno-53-22></a>
</span><span id=__span-53-23><a id=__codelineno-53-23 name=__codelineno-53-23 href=#__codelineno-53-23></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>,</span> <span class=n>targets</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-53-24><a id=__codelineno-53-24 name=__codelineno-53-24 href=#__codelineno-53-24></a>        <span class=n>B</span><span class=p>,</span> <span class=n>T</span> <span class=o>=</span> <span class=n>idx</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-53-25><a id=__codelineno-53-25 name=__codelineno-53-25 href=#__codelineno-53-25></a>
</span><span id=__span-53-26><a id=__codelineno-53-26 name=__codelineno-53-26 href=#__codelineno-53-26></a>        <span class=c1># idxとtargetsはどちらも整数の(B, T)テンソル</span>
</span><span id=__span-53-27><a id=__codelineno-53-27 name=__codelineno-53-27 href=#__codelineno-53-27></a>        <span class=n>tok_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding_table</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span> <span class=c1># (B, T, C)</span>
</span><span id=__span-53-28><a id=__codelineno-53-28 name=__codelineno-53-28 href=#__codelineno-53-28></a>        <span class=n>pos_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>position_embbedding_table</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>))</span> <span class=c1># (T, C)</span>
</span><span id=__span-53-29><a id=__codelineno-53-29 name=__codelineno-53-29 href=#__codelineno-53-29></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>tok_emb</span> <span class=o>+</span> <span class=n>pos_emb</span> <span class=c1># (B, T, C)</span>
</span><span id=__span-53-30><a id=__codelineno-53-30 name=__codelineno-53-30 href=#__codelineno-53-30></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>blocks</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, C)</span>
</span><span id=__span-53-31><a id=__codelineno-53-31 name=__codelineno-53-31 href=#__codelineno-53-31></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># (B, T, C)</span>
</span><span id=__span-53-32><a id=__codelineno-53-32 name=__codelineno-53-32 href=#__codelineno-53-32></a>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B, T, vocab_size)</span>
</span><span id=__span-53-33><a id=__codelineno-53-33 name=__codelineno-53-33 href=#__codelineno-53-33></a>
</span><span id=__span-53-34><a id=__codelineno-53-34 name=__codelineno-53-34 href=#__codelineno-53-34></a>        <span class=k>if</span> <span class=n>targets</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-53-35><a id=__codelineno-53-35 name=__codelineno-53-35 href=#__codelineno-53-35></a>            <span class=n>loss</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-53-36><a id=__codelineno-53-36 name=__codelineno-53-36 href=#__codelineno-53-36></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-53-37><a id=__codelineno-53-37 name=__codelineno-53-37 href=#__codelineno-53-37></a>            <span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-53-38><a id=__codelineno-53-38 name=__codelineno-53-38 href=#__codelineno-53-38></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>T</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span>
</span><span id=__span-53-39><a id=__codelineno-53-39 name=__codelineno-53-39 href=#__codelineno-53-39></a>            <span class=n>targets</span> <span class=o>=</span> <span class=n>targets</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>T</span><span class=p>)</span>
</span><span id=__span-53-40><a id=__codelineno-53-40 name=__codelineno-53-40 href=#__codelineno-53-40></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-53-41><a id=__codelineno-53-41 name=__codelineno-53-41 href=#__codelineno-53-41></a>
</span><span id=__span-53-42><a id=__codelineno-53-42 name=__codelineno-53-42 href=#__codelineno-53-42></a>        <span class=k>return</span> <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span>
</span><span id=__span-53-43><a id=__codelineno-53-43 name=__codelineno-53-43 href=#__codelineno-53-43></a>
</span><span id=__span-53-44><a id=__codelineno-53-44 name=__codelineno-53-44 href=#__codelineno-53-44></a>    <span class=k>def</span><span class=w> </span><span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=p>):</span>
</span><span id=__span-53-45><a id=__codelineno-53-45 name=__codelineno-53-45 href=#__codelineno-53-45></a>        <span class=c1># idxは現在のコンテキストのインデックスの(B, T)配列</span>
</span><span id=__span-53-46><a id=__codelineno-53-46 name=__codelineno-53-46 href=#__codelineno-53-46></a>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_new_tokens</span><span class=p>):</span>
</span><span id=__span-53-47><a id=__codelineno-53-47 name=__codelineno-53-47 href=#__codelineno-53-47></a>            <span class=c1># idxを最後のblock_sizeトークンにクロップ</span>
</span><span id=__span-53-48><a id=__codelineno-53-48 name=__codelineno-53-48 href=#__codelineno-53-48></a>            <span class=n>idx_cond</span> <span class=o>=</span> <span class=n>idx</span><span class=p>[:,</span> <span class=o>-</span><span class=n>block_size</span><span class=p>:]</span>
</span><span id=__span-53-49><a id=__codelineno-53-49 name=__codelineno-53-49 href=#__codelineno-53-49></a>            <span class=c1># 予測を取得</span>
</span><span id=__span-53-50><a id=__codelineno-53-50 name=__codelineno-53-50 href=#__codelineno-53-50></a>            <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=p>(</span><span class=n>idx_cond</span><span class=p>)</span>
</span><span id=__span-53-51><a id=__codelineno-53-51 name=__codelineno-53-51 href=#__codelineno-53-51></a>            <span class=c1># 最後の時間ステップにのみ焦点を当てる</span>
</span><span id=__span-53-52><a id=__codelineno-53-52 name=__codelineno-53-52 href=#__codelineno-53-52></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># (B, C)になる</span>
</span><span id=__span-53-53><a id=__codelineno-53-53 name=__codelineno-53-53 href=#__codelineno-53-53></a>            <span class=c1># softmaxを適用して確率を取得</span>
</span><span id=__span-53-54><a id=__codelineno-53-54 name=__codelineno-53-54 href=#__codelineno-53-54></a>            <span class=n>probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, C)</span>
</span><span id=__span-53-55><a id=__codelineno-53-55 name=__codelineno-53-55 href=#__codelineno-53-55></a>            <span class=c1># 分布からサンプル</span>
</span><span id=__span-53-56><a id=__codelineno-53-56 name=__codelineno-53-56 href=#__codelineno-53-56></a>            <span class=n>idx_next</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>num_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, 1)</span>
</span><span id=__span-53-57><a id=__codelineno-53-57 name=__codelineno-53-57 href=#__codelineno-53-57></a>            <span class=c1># サンプルされたインデックスを実行シーケンスに追加</span>
</span><span id=__span-53-58><a id=__codelineno-53-58 name=__codelineno-53-58 href=#__codelineno-53-58></a>            <span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>idx</span><span class=p>,</span> <span class=n>idx_next</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, T+1)</span>
</span><span id=__span-53-59><a id=__codelineno-53-59 name=__codelineno-53-59 href=#__codelineno-53-59></a>        <span class=k>return</span> <span class=n>idx</span>
</span></code></pre></div> <h3 id=62>6.2 トレーニングループの構築<a class=headerlink href=#62 title="Permanent link">&para;</a></h3> <p>GPTモデルが完成したので、実際にトレーニングを行うためのループを構築していきます。効果的な訓練には以下の要素が必要です：</p> <ul> <li><strong>損失評価関数</strong>: 訓練データと検証データでの性能測定</li> <li><strong>オプティマイザ設定</strong>: AdamWオプティマイザによる勾配更新</li> <li><strong>訓練ループ</strong>: バッチごとの順伝播・逆伝播・重み更新</li> </ul> <p>まず、モデルをインスタンス化し、パラメータ数を確認します： <div class="language-text highlight"><pre><span></span><code><span id=__span-54-1><a id=__codelineno-54-1 name=__codelineno-54-1 href=#__codelineno-54-1></a>```python
</span><span id=__span-54-2><a id=__codelineno-54-2 name=__codelineno-54-2 href=#__codelineno-54-2></a>model = GPTLanguageModel()
</span><span id=__span-54-3><a id=__codelineno-54-3 name=__codelineno-54-3 href=#__codelineno-54-3></a>m = model.to(device)
</span><span id=__span-54-4><a id=__codelineno-54-4 name=__codelineno-54-4 href=#__codelineno-54-4></a># モデル内のパラメータ数を出力
</span><span id=__span-54-5><a id=__codelineno-54-5 name=__codelineno-54-5 href=#__codelineno-54-5></a>print(sum(p.numel() for p in m.parameters())/1e6, &#39;M parameters&#39;)
</span></code></pre></div></p> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-55-1><a id=__codelineno-55-1 name=__codelineno-55-1 href=#__codelineno-55-1></a>0.209729 M parameters
</span></code></pre></div></p> <h4 id=_14>パラメータ数の詳細内訳<a class=headerlink href=#_14 title="Permanent link">&para;</a></h4> <p>モデルサイズをより詳しく理解するために、各コンポーネントのパラメータ数を計算してみます：</p> <p><strong>パラメータ数の内訳</strong>（設定例：vocab_size=65, n_embd=64, n_head=4, n_layer=4）</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-56-1><a id=__codelineno-56-1 name=__codelineno-56-1 href=#__codelineno-56-1></a>Token Embedding:        65 × 64 = 4,160    パラメータ
</span><span id=__span-56-2><a id=__codelineno-56-2 name=__codelineno-56-2 href=#__codelineno-56-2></a>Position Embedding:     32 × 64 = 2,048    パラメータ
</span><span id=__span-56-3><a id=__codelineno-56-3 name=__codelineno-56-3 href=#__codelineno-56-3></a>各Transformer Block:             ~49,400   パラメータ
</span><span id=__span-56-4><a id=__codelineno-56-4 name=__codelineno-56-4 href=#__codelineno-56-4></a>4つのBlock合計:       49,400 × 4 = 197,600 パラメータ
</span><span id=__span-56-5><a id=__codelineno-56-5 name=__codelineno-56-5 href=#__codelineno-56-5></a>最終出力層(lm_head):    64 × 65 = 4,160    パラメータ
</span><span id=__span-56-6><a id=__codelineno-56-6 name=__codelineno-56-6 href=#__codelineno-56-6></a>Layer Normalization:           少量        パラメータ
</span><span id=__span-56-7><a id=__codelineno-56-7 name=__codelineno-56-7 href=#__codelineno-56-7></a>────────────────────────────────────────────────────
</span><span id=__span-56-8><a id=__codelineno-56-8 name=__codelineno-56-8 href=#__codelineno-56-8></a>総計:                          ~0.21M     パラメータ
</span></code></pre></div> <p><strong>Transformer Block内の詳細</strong>： <div class="language-text highlight"><pre><span></span><code><span id=__span-57-1><a id=__codelineno-57-1 name=__codelineno-57-1 href=#__codelineno-57-1></a>Multi-Head Attention:
</span><span id=__span-57-2><a id=__codelineno-57-2 name=__codelineno-57-2 href=#__codelineno-57-2></a>- Query/Key/Value線形層: 64×64×3 = 12,288
</span><span id=__span-57-3><a id=__codelineno-57-3 name=__codelineno-57-3 href=#__codelineno-57-3></a>- 出力プロジェクション: 64×64 = 4,096
</span><span id=__span-57-4><a id=__codelineno-57-4 name=__codelineno-57-4 href=#__codelineno-57-4></a>Feed-Forward Network:
</span><span id=__span-57-5><a id=__codelineno-57-5 name=__codelineno-57-5 href=#__codelineno-57-5></a>- 第1層: 64×256 = 16,384
</span><span id=__span-57-6><a id=__codelineno-57-6 name=__codelineno-57-6 href=#__codelineno-57-6></a>- 第2層: 256×64 = 16,384
</span><span id=__span-57-7><a id=__codelineno-57-7 name=__codelineno-57-7 href=#__codelineno-57-7></a>Layer Normalization ×2: 64×2 = 128
</span><span id=__span-57-8><a id=__codelineno-57-8 name=__codelineno-57-8 href=#__codelineno-57-8></a>────────────────────────────────────
</span><span id=__span-57-9><a id=__codelineno-57-9 name=__codelineno-57-9 href=#__codelineno-57-9></a>Block合計:              約49,400
</span></code></pre></div></p> <p>この計算により、モデルのサイズが把握でき、メモリとGPU使用量の目安がわかります。</p> <h4 id=_15>損失評価関数の実装<a class=headerlink href=#_15 title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-58-1><a id=__codelineno-58-1 name=__codelineno-58-1 href=#__codelineno-58-1></a><span class=nd>@torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>()</span>
</span><span id=__span-58-2><a id=__codelineno-58-2 name=__codelineno-58-2 href=#__codelineno-58-2></a><span class=k>def</span><span class=w> </span><span class=nf>estimate_loss</span><span class=p>():</span>
</span><span id=__span-58-3><a id=__codelineno-58-3 name=__codelineno-58-3 href=#__codelineno-58-3></a>    <span class=n>out</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-58-4><a id=__codelineno-58-4 name=__codelineno-58-4 href=#__codelineno-58-4></a>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-58-5><a id=__codelineno-58-5 name=__codelineno-58-5 href=#__codelineno-58-5></a>    <span class=k>for</span> <span class=n>split</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>,</span> <span class=s1>&#39;val&#39;</span><span class=p>]:</span>
</span><span id=__span-58-6><a id=__codelineno-58-6 name=__codelineno-58-6 href=#__codelineno-58-6></a>        <span class=n>losses</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>eval_iters</span><span class=p>)</span>
</span><span id=__span-58-7><a id=__codelineno-58-7 name=__codelineno-58-7 href=#__codelineno-58-7></a>        <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>eval_iters</span><span class=p>):</span>
</span><span id=__span-58-8><a id=__codelineno-58-8 name=__codelineno-58-8 href=#__codelineno-58-8></a>            <span class=n>X</span><span class=p>,</span> <span class=n>Y</span> <span class=o>=</span> <span class=n>get_batch</span><span class=p>(</span><span class=n>split</span><span class=p>)</span>
</span><span id=__span-58-9><a id=__codelineno-58-9 name=__codelineno-58-9 href=#__codelineno-58-9></a>            <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>
</span><span id=__span-58-10><a id=__codelineno-58-10 name=__codelineno-58-10 href=#__codelineno-58-10></a>            <span class=n>losses</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-58-11><a id=__codelineno-58-11 name=__codelineno-58-11 href=#__codelineno-58-11></a>        <span class=n>out</span><span class=p>[</span><span class=n>split</span><span class=p>]</span> <span class=o>=</span> <span class=n>losses</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-58-12><a id=__codelineno-58-12 name=__codelineno-58-12 href=#__codelineno-58-12></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-58-13><a id=__codelineno-58-13 name=__codelineno-58-13 href=#__codelineno-58-13></a>    <span class=k>return</span> <span class=n>out</span>
</span></code></pre></div> <h4 id=_16>メインの訓練ループ<a class=headerlink href=#_16 title="Permanent link">&para;</a></h4> <p>訓練データと検証データで定期的に損失を評価しながら、AdamWオプティマイザでモデルを訓練します：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-59-1><a id=__codelineno-59-1 name=__codelineno-59-1 href=#__codelineno-59-1></a><span class=c1># PyTorchオプティマイザの作成</span>
</span><span id=__span-59-2><a id=__codelineno-59-2 name=__codelineno-59-2 href=#__codelineno-59-2></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>
</span><span id=__span-59-3><a id=__codelineno-59-3 name=__codelineno-59-3 href=#__codelineno-59-3></a>
</span><span id=__span-59-4><a id=__codelineno-59-4 name=__codelineno-59-4 href=#__codelineno-59-4></a><span class=k>for</span> <span class=nb>iter</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_iters</span><span class=p>):</span>
</span><span id=__span-59-5><a id=__codelineno-59-5 name=__codelineno-59-5 href=#__codelineno-59-5></a>    <span class=c1># 定期的に訓練セットと検証セットで損失を評価</span>
</span><span id=__span-59-6><a id=__codelineno-59-6 name=__codelineno-59-6 href=#__codelineno-59-6></a>    <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=n>eval_interval</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>or</span> <span class=nb>iter</span> <span class=o>==</span> <span class=n>max_iters</span> <span class=o>-</span><span class=mi>1</span><span class=p>:</span>
</span><span id=__span-59-7><a id=__codelineno-59-7 name=__codelineno-59-7 href=#__codelineno-59-7></a>        <span class=n>losses</span> <span class=o>=</span> <span class=n>estimate_loss</span><span class=p>()</span>
</span><span id=__span-59-8><a id=__codelineno-59-8 name=__codelineno-59-8 href=#__codelineno-59-8></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;step </span><span class=si>{</span><span class=nb>iter</span><span class=si>}</span><span class=s2>: train loss </span><span class=si>{</span><span class=n>losses</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>, val loss </span><span class=si>{</span><span class=n>losses</span><span class=p>[</span><span class=s1>&#39;val&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-59-9><a id=__codelineno-59-9 name=__codelineno-59-9 href=#__codelineno-59-9></a>
</span><span id=__span-59-10><a id=__codelineno-59-10 name=__codelineno-59-10 href=#__codelineno-59-10></a>    <span class=c1># データのバッチをサンプル</span>
</span><span id=__span-59-11><a id=__codelineno-59-11 name=__codelineno-59-11 href=#__codelineno-59-11></a>    <span class=n>xb</span><span class=p>,</span> <span class=n>yb</span> <span class=o>=</span> <span class=n>get_batch</span><span class=p>(</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span><span id=__span-59-12><a id=__codelineno-59-12 name=__codelineno-59-12 href=#__codelineno-59-12></a>
</span><span id=__span-59-13><a id=__codelineno-59-13 name=__codelineno-59-13 href=#__codelineno-59-13></a>    <span class=c1># 損失を評価</span>
</span><span id=__span-59-14><a id=__codelineno-59-14 name=__codelineno-59-14 href=#__codelineno-59-14></a>    <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>xb</span><span class=p>,</span> <span class=n>yb</span><span class=p>)</span>
</span><span id=__span-59-15><a id=__codelineno-59-15 name=__codelineno-59-15 href=#__codelineno-59-15></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>(</span><span class=n>set_to_none</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-59-16><a id=__codelineno-59-16 name=__codelineno-59-16 href=#__codelineno-59-16></a>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-59-17><a id=__codelineno-59-17 name=__codelineno-59-17 href=#__codelineno-59-17></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-60-1><a id=__codelineno-60-1 name=__codelineno-60-1 href=#__codelineno-60-1></a>step 0: train loss 4.1959, val loss 4.1962
</span><span id=__span-60-2><a id=__codelineno-60-2 name=__codelineno-60-2 href=#__codelineno-60-2></a>step 100: train loss 2.6228, val loss 2.6158
</span><span id=__span-60-3><a id=__codelineno-60-3 name=__codelineno-60-3 href=#__codelineno-60-3></a>step 200: train loss 2.4580, val loss 2.4510
</span><span id=__span-60-4><a id=__codelineno-60-4 name=__codelineno-60-4 href=#__codelineno-60-4></a>step 300: train loss 2.3817, val loss 2.3929
</span><span id=__span-60-5><a id=__codelineno-60-5 name=__codelineno-60-5 href=#__codelineno-60-5></a>step 400: train loss 2.3220, val loss 2.3230
</span><span id=__span-60-6><a id=__codelineno-60-6 name=__codelineno-60-6 href=#__codelineno-60-6></a>step 500: train loss 2.2391, val loss 2.2578
</span><span id=__span-60-7><a id=__codelineno-60-7 name=__codelineno-60-7 href=#__codelineno-60-7></a>step 600: train loss 2.1846, val loss 2.2275
</span><span id=__span-60-8><a id=__codelineno-60-8 name=__codelineno-60-8 href=#__codelineno-60-8></a>step 700: train loss 2.1361, val loss 2.1595
</span><span id=__span-60-9><a id=__codelineno-60-9 name=__codelineno-60-9 href=#__codelineno-60-9></a>step 800: train loss 2.1026, val loss 2.1439
</span><span id=__span-60-10><a id=__codelineno-60-10 name=__codelineno-60-10 href=#__codelineno-60-10></a>step 900: train loss 2.0587, val loss 2.1057
</span><span id=__span-60-11><a id=__codelineno-60-11 name=__codelineno-60-11 href=#__codelineno-60-11></a>step 1000: train loss 2.0449, val loss 2.0912
</span><span id=__span-60-12><a id=__codelineno-60-12 name=__codelineno-60-12 href=#__codelineno-60-12></a>step 1100: train loss 2.0026, val loss 2.0696
</span><span id=__span-60-13><a id=__codelineno-60-13 name=__codelineno-60-13 href=#__codelineno-60-13></a>step 1200: train loss 1.9823, val loss 2.0701
</span><span id=__span-60-14><a id=__codelineno-60-14 name=__codelineno-60-14 href=#__codelineno-60-14></a>step 1300: train loss 1.9682, val loss 2.0451
</span><span id=__span-60-15><a id=__codelineno-60-15 name=__codelineno-60-15 href=#__codelineno-60-15></a>step 1400: train loss 1.9421, val loss 2.0375
</span><span id=__span-60-16><a id=__codelineno-60-16 name=__codelineno-60-16 href=#__codelineno-60-16></a>step 1500: train loss 1.9029, val loss 1.9990
</span><span id=__span-60-17><a id=__codelineno-60-17 name=__codelineno-60-17 href=#__codelineno-60-17></a>step 1600: train loss 1.8860, val loss 1.9939
</span><span id=__span-60-18><a id=__codelineno-60-18 name=__codelineno-60-18 href=#__codelineno-60-18></a>step 1700: train loss 1.8778, val loss 1.9785
</span><span id=__span-60-19><a id=__codelineno-60-19 name=__codelineno-60-19 href=#__codelineno-60-19></a>step 1800: train loss 1.8865, val loss 1.9925
</span><span id=__span-60-20><a id=__codelineno-60-20 name=__codelineno-60-20 href=#__codelineno-60-20></a>step 1900: train loss 1.8428, val loss 1.9692
</span><span id=__span-60-21><a id=__codelineno-60-21 name=__codelineno-60-21 href=#__codelineno-60-21></a>step 2000: train loss 1.8349, val loss 1.9544
</span><span id=__span-60-22><a id=__codelineno-60-22 name=__codelineno-60-22 href=#__codelineno-60-22></a>step 2100: train loss 1.8397, val loss 1.9828
</span><span id=__span-60-23><a id=__codelineno-60-23 name=__codelineno-60-23 href=#__codelineno-60-23></a>step 2200: train loss 1.8097, val loss 1.9398
</span><span id=__span-60-24><a id=__codelineno-60-24 name=__codelineno-60-24 href=#__codelineno-60-24></a>step 2300: train loss 1.8034, val loss 1.9342
</span><span id=__span-60-25><a id=__codelineno-60-25 name=__codelineno-60-25 href=#__codelineno-60-25></a>step 2400: train loss 1.7814, val loss 1.9171
</span><span id=__span-60-26><a id=__codelineno-60-26 name=__codelineno-60-26 href=#__codelineno-60-26></a>step 2500: train loss 1.7723, val loss 1.9080
</span><span id=__span-60-27><a id=__codelineno-60-27 name=__codelineno-60-27 href=#__codelineno-60-27></a>step 2600: train loss 1.7570, val loss 1.8970
</span><span id=__span-60-28><a id=__codelineno-60-28 name=__codelineno-60-28 href=#__codelineno-60-28></a>step 2700: train loss 1.7583, val loss 1.9077
</span><span id=__span-60-29><a id=__codelineno-60-29 name=__codelineno-60-29 href=#__codelineno-60-29></a>step 2800: train loss 1.7523, val loss 1.8983
</span><span id=__span-60-30><a id=__codelineno-60-30 name=__codelineno-60-30 href=#__codelineno-60-30></a>step 2900: train loss 1.7405, val loss 1.8941
</span><span id=__span-60-31><a id=__codelineno-60-31 name=__codelineno-60-31 href=#__codelineno-60-31></a>step 3000: train loss 1.7512, val loss 1.8875
</span><span id=__span-60-32><a id=__codelineno-60-32 name=__codelineno-60-32 href=#__codelineno-60-32></a>step 3100: train loss 1.7413, val loss 1.8903
</span><span id=__span-60-33><a id=__codelineno-60-33 name=__codelineno-60-33 href=#__codelineno-60-33></a>step 3200: train loss 1.7300, val loss 1.8864
</span><span id=__span-60-34><a id=__codelineno-60-34 name=__codelineno-60-34 href=#__codelineno-60-34></a>step 3300: train loss 1.7250, val loss 1.8710
</span><span id=__span-60-35><a id=__codelineno-60-35 name=__codelineno-60-35 href=#__codelineno-60-35></a>step 3400: train loss 1.7151, val loss 1.8758
</span><span id=__span-60-36><a id=__codelineno-60-36 name=__codelineno-60-36 href=#__codelineno-60-36></a>step 3500: train loss 1.7164, val loss 1.8638
</span><span id=__span-60-37><a id=__codelineno-60-37 name=__codelineno-60-37 href=#__codelineno-60-37></a>step 3600: train loss 1.7095, val loss 1.8521
</span><span id=__span-60-38><a id=__codelineno-60-38 name=__codelineno-60-38 href=#__codelineno-60-38></a>step 3700: train loss 1.6988, val loss 1.8557
</span><span id=__span-60-39><a id=__codelineno-60-39 name=__codelineno-60-39 href=#__codelineno-60-39></a>step 3800: train loss 1.7032, val loss 1.8610
</span><span id=__span-60-40><a id=__codelineno-60-40 name=__codelineno-60-40 href=#__codelineno-60-40></a>step 3900: train loss 1.6901, val loss 1.8394
</span><span id=__span-60-41><a id=__codelineno-60-41 name=__codelineno-60-41 href=#__codelineno-60-41></a>step 4000: train loss 1.6839, val loss 1.8307
</span><span id=__span-60-42><a id=__codelineno-60-42 name=__codelineno-60-42 href=#__codelineno-60-42></a>step 4100: train loss 1.6743, val loss 1.8447
</span><span id=__span-60-43><a id=__codelineno-60-43 name=__codelineno-60-43 href=#__codelineno-60-43></a>step 4200: train loss 1.6673, val loss 1.8499
</span><span id=__span-60-44><a id=__codelineno-60-44 name=__codelineno-60-44 href=#__codelineno-60-44></a>step 4300: train loss 1.6743, val loss 1.8297
</span><span id=__span-60-45><a id=__codelineno-60-45 name=__codelineno-60-45 href=#__codelineno-60-45></a>step 4400: train loss 1.6674, val loss 1.8384
</span><span id=__span-60-46><a id=__codelineno-60-46 name=__codelineno-60-46 href=#__codelineno-60-46></a>step 4500: train loss 1.6638, val loss 1.8206
</span><span id=__span-60-47><a id=__codelineno-60-47 name=__codelineno-60-47 href=#__codelineno-60-47></a>step 4600: train loss 1.6467, val loss 1.8364
</span><span id=__span-60-48><a id=__codelineno-60-48 name=__codelineno-60-48 href=#__codelineno-60-48></a>step 4700: train loss 1.6564, val loss 1.8121
</span><span id=__span-60-49><a id=__codelineno-60-49 name=__codelineno-60-49 href=#__codelineno-60-49></a>step 4800: train loss 1.6547, val loss 1.8267
</span><span id=__span-60-50><a id=__codelineno-60-50 name=__codelineno-60-50 href=#__codelineno-60-50></a>step 4900: train loss 1.6436, val loss 1.8231
</span><span id=__span-60-51><a id=__codelineno-60-51 name=__codelineno-60-51 href=#__codelineno-60-51></a>step 4999: train loss 1.6491, val loss 1.8256
</span></code></pre></div></p> <h4 id=_17>訓練済みモデルでのテキスト生成<a class=headerlink href=#_17 title="Permanent link">&para;</a></h4> <p>訓練が完了したので、モデルを使って新しいテキストを生成してみましょう：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-61-1><a id=__codelineno-61-1 name=__codelineno-61-1 href=#__codelineno-61-1></a><span class=c1># モデルから生成</span>
</span><span id=__span-61-2><a id=__codelineno-61-2 name=__codelineno-61-2 href=#__codelineno-61-2></a><span class=n>context</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-61-3><a id=__codelineno-61-3 name=__codelineno-61-3 href=#__codelineno-61-3></a><span class=nb>print</span><span class=p>(</span><span class=n>decode</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>context</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>1000</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>tolist</span><span class=p>()))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-62-1><a id=__codelineno-62-1 name=__codelineno-62-1 href=#__codelineno-62-1></a>God, O, that of you: life, whereep, them with
</span><span id=__span-62-2><a id=__codelineno-62-2 name=__codelineno-62-2 href=#__codelineno-62-2></a>force this cordon&#39;d his encleours.
</span><span id=__span-62-3><a id=__codelineno-62-3 name=__codelineno-62-3 href=#__codelineno-62-3></a>Thou thy enleiter judget lut womal
</span><span id=__span-62-4><a id=__codelineno-62-4 name=__codelineno-62-4 href=#__codelineno-62-4></a>To him; haver core&#39; venray,
</span><span id=__span-62-5><a id=__codelineno-62-5 name=__codelineno-62-5 href=#__codelineno-62-5></a>Bon the wrights a cause in thisfiend prepossity treak his sound,
</span><span id=__span-62-6><a id=__codelineno-62-6 name=__codelineno-62-6 href=#__codelineno-62-6></a>And boy pring lack marrougs maste I hand&#39;d naccuse,
</span><span id=__span-62-7><a id=__codelineno-62-7 name=__codelineno-62-7 href=#__codelineno-62-7></a>That that keep reasw the underer you: it
</span><span id=__span-62-8><a id=__codelineno-62-8 name=__codelineno-62-8 href=#__codelineno-62-8></a>That fight thee
</span><span id=__span-62-9><a id=__codelineno-62-9 name=__codelineno-62-9 href=#__codelineno-62-9></a>fall Julatest: God! hatt &#39;t a bed&#39;s mear acannot.
</span><span id=__span-62-10><a id=__codelineno-62-10 name=__codelineno-62-10 href=#__codelineno-62-10></a>Nos weld?
</span><span id=__span-62-11><a id=__codelineno-62-11 name=__codelineno-62-11 href=#__codelineno-62-11></a>
</span><span id=__span-62-12><a id=__codelineno-62-12 name=__codelineno-62-12 href=#__codelineno-62-12></a>DUKE VINCESD IVERS:
</span><span id=__span-62-13><a id=__codelineno-62-13 name=__codelineno-62-13 href=#__codelineno-62-13></a>Mere folies a gentrefarefien a fawaither wither in bawdel,--sain,
</span><span id=__span-62-14><a id=__codelineno-62-14 name=__codelineno-62-14 href=#__codelineno-62-14></a>In centerfore to hope curce mame court us:
</span><span id=__span-62-15><a id=__codelineno-62-15 name=__codelineno-62-15 href=#__codelineno-62-15></a>sell not forf.
</span><span id=__span-62-16><a id=__codelineno-62-16 name=__codelineno-62-16 href=#__codelineno-62-16></a>
</span><span id=__span-62-17><a id=__codelineno-62-17 name=__codelineno-62-17 href=#__codelineno-62-17></a>PRINCES:
</span><span id=__span-62-18><a id=__codelineno-62-18 name=__codelineno-62-18 href=#__codelineno-62-18></a>Nob tull teare them one
</span><span id=__span-62-19><a id=__codelineno-62-19 name=__codelineno-62-19 href=#__codelineno-62-19></a>Ongive me
</span><span id=__span-62-20><a id=__codelineno-62-20 name=__codelineno-62-20 href=#__codelineno-62-20></a>Where pat here appeased Edperate,
</span><span id=__span-62-21><a id=__codelineno-62-21 name=__codelineno-62-21 href=#__codelineno-62-21></a>But thou mean; nastesders home on wletgeedate to frise tense,
</span><span id=__span-62-22><a id=__codelineno-62-22 name=__codelineno-62-22 href=#__codelineno-62-22></a>Come a in on this friend 
</span><span id=__span-62-23><a id=__codelineno-62-23 name=__codelineno-62-23 href=#__codelineno-62-23></a>With polows
</span><span id=__span-62-24><a id=__codelineno-62-24 name=__codelineno-62-24 href=#__codelineno-62-24></a>Julate both our tran in there
</span><span id=__span-62-25><a id=__codelineno-62-25 name=__codelineno-62-25 href=#__codelineno-62-25></a>mour worthern: it he sout at I cried!
</span><span id=__span-62-26><a id=__codelineno-62-26 name=__codelineno-62-26 href=#__codelineno-62-26></a>By gent him to the god poors, time same a dal Bowery.
</span><span id=__span-62-27><a id=__codelineno-62-27 name=__codelineno-62-27 href=#__codelineno-62-27></a>
</span><span id=__span-62-28><a id=__codelineno-62-28 name=__codelineno-62-28 href=#__codelineno-62-28></a>CLAUDIO:
</span><span id=__span-62-29><a id=__codelineno-62-29 name=__codelineno-62-29 href=#__codelineno-62-29></a>O, bearech it the is wis to Lorde,
</span><span id=__span-62-30><a id=__codelineno-62-30 name=__codelineno-62-30 href=#__codelineno-62-30></a>What, he bare he of the bund-heddeige,
</span><span id=__span-62-31><a id=__codelineno-62-31 name=__codelineno-62-31 href=#__codelineno-62-31></a>That laie agg to that you usworld that shall ound to wack.
</span><span id=__span-62-32><a id=__codelineno-62-32 name=__codelineno-62-32 href=#__codelineno-62-32></a>
</span><span id=__span-62-33><a id=__codelineno-62-33 name=__codelineno-62-33 href=#__codelineno-62-33></a>That hopose.
</span><span id=__span-62-34><a id=__codelineno-62-34 name=__codelineno-62-34 href=#__codelineno-62-34></a>
</span><span id=__span-62-35><a id=__codelineno-62-35 name=__codelineno-62-35 href=#__codelineno-62-35></a>WARWICKBERS:
</span><span id=__span-62-36><a id=__codelineno-62-36 name=__codelineno-62-36 href=#__codelineno-62-36></a>O, for
</span></code></pre></div></p> <h2 id=7>7. 最終実装とテキスト生成<a class=headerlink href=#7 title="Permanent link">&para;</a></h2> <h3 id=71-gpt>7.1 統合されたGPTモデルの実装<a class=headerlink href=#71-gpt title="Permanent link">&para;</a></h3> <p>ここまでで学習したすべてのコンポーネントを統合し、<strong>完全なGPTモデル</strong>を構築します。以下のコードには、これまで段階的に説明してきた全ての要素が含まれています：</p> <ul> <li>文字レベルトークン化システム</li> <li>マルチヘッド自己注意メカニズム</li> <li>フィードフォワードネットワーク</li> <li>位置エンコーディング</li> <li>残差接続とLayer Normalization</li> <li>適切な重み初期化</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-63-1><a id=__codelineno-63-1 name=__codelineno-63-1 href=#__codelineno-63-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-63-2><a id=__codelineno-63-2 name=__codelineno-63-2 href=#__codelineno-63-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-63-3><a id=__codelineno-63-3 name=__codelineno-63-3 href=#__codelineno-63-3></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=kn>import</span> <span class=n>functional</span> <span class=k>as</span> <span class=n>F</span>
</span><span id=__span-63-4><a id=__codelineno-63-4 name=__codelineno-63-4 href=#__codelineno-63-4></a>
</span><span id=__span-63-5><a id=__codelineno-63-5 name=__codelineno-63-5 href=#__codelineno-63-5></a><span class=c1># ハイパーパラメータ</span>
</span><span id=__span-63-6><a id=__codelineno-63-6 name=__codelineno-63-6 href=#__codelineno-63-6></a><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>64</span> <span class=c1># 並列処理する独立シーケンスの数</span>
</span><span id=__span-63-7><a id=__codelineno-63-7 name=__codelineno-63-7 href=#__codelineno-63-7></a><span class=n>block_size</span> <span class=o>=</span> <span class=mi>256</span> <span class=c1># 予測のための最大コンテキスト長</span>
</span><span id=__span-63-8><a id=__codelineno-63-8 name=__codelineno-63-8 href=#__codelineno-63-8></a><span class=n>max_iters</span> <span class=o>=</span> <span class=mi>5000</span>
</span><span id=__span-63-9><a id=__codelineno-63-9 name=__codelineno-63-9 href=#__codelineno-63-9></a><span class=n>eval_interval</span> <span class=o>=</span> <span class=mi>500</span>
</span><span id=__span-63-10><a id=__codelineno-63-10 name=__codelineno-63-10 href=#__codelineno-63-10></a><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>3e-4</span>
</span><span id=__span-63-11><a id=__codelineno-63-11 name=__codelineno-63-11 href=#__codelineno-63-11></a><span class=n>device</span> <span class=o>=</span> <span class=s1>&#39;mps&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span>
</span><span id=__span-63-12><a id=__codelineno-63-12 name=__codelineno-63-12 href=#__codelineno-63-12></a><span class=n>eval_iters</span> <span class=o>=</span> <span class=mi>200</span>
</span><span id=__span-63-13><a id=__codelineno-63-13 name=__codelineno-63-13 href=#__codelineno-63-13></a><span class=n>n_embd</span> <span class=o>=</span> <span class=mi>384</span>
</span><span id=__span-63-14><a id=__codelineno-63-14 name=__codelineno-63-14 href=#__codelineno-63-14></a><span class=n>n_head</span> <span class=o>=</span> <span class=mi>6</span>
</span><span id=__span-63-15><a id=__codelineno-63-15 name=__codelineno-63-15 href=#__codelineno-63-15></a><span class=n>n_layer</span> <span class=o>=</span> <span class=mi>6</span>
</span><span id=__span-63-16><a id=__codelineno-63-16 name=__codelineno-63-16 href=#__codelineno-63-16></a><span class=n>dropout</span> <span class=o>=</span> <span class=mf>0.2</span>
</span><span id=__span-63-17><a id=__codelineno-63-17 name=__codelineno-63-17 href=#__codelineno-63-17></a><span class=c1># ------------</span>
</span><span id=__span-63-18><a id=__codelineno-63-18 name=__codelineno-63-18 href=#__codelineno-63-18></a>
</span><span id=__span-63-19><a id=__codelineno-63-19 name=__codelineno-63-19 href=#__codelineno-63-19></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>1337</span><span class=p>)</span>
</span><span id=__span-63-20><a id=__codelineno-63-20 name=__codelineno-63-20 href=#__codelineno-63-20></a>
</span><span id=__span-63-21><a id=__codelineno-63-21 name=__codelineno-63-21 href=#__codelineno-63-21></a><span class=err>!</span><span class=n>wget</span> <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>raw</span><span class=o>.</span><span class=n>githubusercontent</span><span class=o>.</span><span class=n>com</span><span class=o>/</span><span class=n>karpathy</span><span class=o>/</span><span class=n>char</span><span class=o>-</span><span class=n>rnn</span><span class=o>/</span><span class=n>master</span><span class=o>/</span><span class=n>data</span><span class=o>/</span><span class=n>tinyshakespeare</span><span class=o>/</span><span class=nb>input</span><span class=o>.</span><span class=n>txt</span>
</span><span id=__span-63-22><a id=__codelineno-63-22 name=__codelineno-63-22 href=#__codelineno-63-22></a><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;input.txt&#39;</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-63-23><a id=__codelineno-63-23 name=__codelineno-63-23 href=#__codelineno-63-23></a>    <span class=n>text</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span><span id=__span-63-24><a id=__codelineno-63-24 name=__codelineno-63-24 href=#__codelineno-63-24></a>
</span><span id=__span-63-25><a id=__codelineno-63-25 name=__codelineno-63-25 href=#__codelineno-63-25></a><span class=c1># このテキストに出現する全てのユニーク文字</span>
</span><span id=__span-63-26><a id=__codelineno-63-26 name=__codelineno-63-26 href=#__codelineno-63-26></a><span class=n>chars</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>text</span><span class=p>)))</span>
</span><span id=__span-63-27><a id=__codelineno-63-27 name=__codelineno-63-27 href=#__codelineno-63-27></a><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>chars</span><span class=p>)</span>
</span><span id=__span-63-28><a id=__codelineno-63-28 name=__codelineno-63-28 href=#__codelineno-63-28></a><span class=c1># 文字から整数へのマッピングを作成</span>
</span><span id=__span-63-29><a id=__codelineno-63-29 name=__codelineno-63-29 href=#__codelineno-63-29></a><span class=n>stoi</span> <span class=o>=</span> <span class=p>{</span> <span class=n>ch</span><span class=p>:</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span><span class=n>ch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>chars</span><span class=p>)</span> <span class=p>}</span>
</span><span id=__span-63-30><a id=__codelineno-63-30 name=__codelineno-63-30 href=#__codelineno-63-30></a><span class=n>itos</span> <span class=o>=</span> <span class=p>{</span> <span class=n>i</span><span class=p>:</span><span class=n>ch</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span><span class=n>ch</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>chars</span><span class=p>)</span> <span class=p>}</span>
</span><span id=__span-63-31><a id=__codelineno-63-31 name=__codelineno-63-31 href=#__codelineno-63-31></a><span class=n>encode</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>s</span><span class=p>:</span> <span class=p>[</span><span class=n>stoi</span><span class=p>[</span><span class=n>c</span><span class=p>]</span> <span class=k>for</span> <span class=n>c</span> <span class=ow>in</span> <span class=n>s</span><span class=p>]</span> <span class=c1># エンコーダー: 文字列を取得し、整数のリストを出力</span>
</span><span id=__span-63-32><a id=__codelineno-63-32 name=__codelineno-63-32 href=#__codelineno-63-32></a><span class=n>decode</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>l</span><span class=p>:</span> <span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=n>itos</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>l</span><span class=p>])</span> <span class=c1># デコーダー: 整数のリストを取得し、文字列を出力</span>
</span><span id=__span-63-33><a id=__codelineno-63-33 name=__codelineno-63-33 href=#__codelineno-63-33></a>
</span><span id=__span-63-34><a id=__codelineno-63-34 name=__codelineno-63-34 href=#__codelineno-63-34></a><span class=c1># 訓練・テスト分割</span>
</span><span id=__span-63-35><a id=__codelineno-63-35 name=__codelineno-63-35 href=#__codelineno-63-35></a><span class=n>data</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>encode</span><span class=p>(</span><span class=n>text</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span><span id=__span-63-36><a id=__codelineno-63-36 name=__codelineno-63-36 href=#__codelineno-63-36></a><span class=n>n</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=mf>0.9</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>))</span> <span class=c1># 最初の90%が訓練、残りが検証</span>
</span><span id=__span-63-37><a id=__codelineno-63-37 name=__codelineno-63-37 href=#__codelineno-63-37></a><span class=n>train_data</span> <span class=o>=</span> <span class=n>data</span><span class=p>[:</span><span class=n>n</span><span class=p>]</span>
</span><span id=__span-63-38><a id=__codelineno-63-38 name=__codelineno-63-38 href=#__codelineno-63-38></a><span class=n>val_data</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>n</span><span class=p>:]</span>
</span><span id=__span-63-39><a id=__codelineno-63-39 name=__codelineno-63-39 href=#__codelineno-63-39></a>
</span><span id=__span-63-40><a id=__codelineno-63-40 name=__codelineno-63-40 href=#__codelineno-63-40></a><span class=c1># データローディング</span>
</span><span id=__span-63-41><a id=__codelineno-63-41 name=__codelineno-63-41 href=#__codelineno-63-41></a><span class=k>def</span><span class=w> </span><span class=nf>get_batch</span><span class=p>(</span><span class=n>split</span><span class=p>):</span>
</span><span id=__span-63-42><a id=__codelineno-63-42 name=__codelineno-63-42 href=#__codelineno-63-42></a>    <span class=c1># 入力xとターゲットyの小さなデータバッチを生成</span>
</span><span id=__span-63-43><a id=__codelineno-63-43 name=__codelineno-63-43 href=#__codelineno-63-43></a>    <span class=n>data</span> <span class=o>=</span> <span class=n>train_data</span> <span class=k>if</span> <span class=n>split</span> <span class=o>==</span> <span class=s1>&#39;train&#39;</span> <span class=k>else</span> <span class=n>val_data</span>
</span><span id=__span-63-44><a id=__codelineno-63-44 name=__codelineno-63-44 href=#__codelineno-63-44></a>    <span class=n>ix</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span> <span class=o>-</span> <span class=n>block_size</span><span class=p>,</span> <span class=p>(</span><span class=n>batch_size</span><span class=p>,))</span>
</span><span id=__span-63-45><a id=__codelineno-63-45 name=__codelineno-63-45 href=#__codelineno-63-45></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>block_size</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ix</span><span class=p>])</span>
</span><span id=__span-63-46><a id=__codelineno-63-46 name=__codelineno-63-46 href=#__codelineno-63-46></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>block_size</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ix</span><span class=p>])</span>
</span><span id=__span-63-47><a id=__codelineno-63-47 name=__codelineno-63-47 href=#__codelineno-63-47></a>    <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-63-48><a id=__codelineno-63-48 name=__codelineno-63-48 href=#__codelineno-63-48></a>    <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span>
</span><span id=__span-63-49><a id=__codelineno-63-49 name=__codelineno-63-49 href=#__codelineno-63-49></a>
</span><span id=__span-63-50><a id=__codelineno-63-50 name=__codelineno-63-50 href=#__codelineno-63-50></a><span class=nd>@torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>()</span>
</span><span id=__span-63-51><a id=__codelineno-63-51 name=__codelineno-63-51 href=#__codelineno-63-51></a><span class=k>def</span><span class=w> </span><span class=nf>estimate_loss</span><span class=p>():</span>
</span><span id=__span-63-52><a id=__codelineno-63-52 name=__codelineno-63-52 href=#__codelineno-63-52></a>    <span class=n>out</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-63-53><a id=__codelineno-63-53 name=__codelineno-63-53 href=#__codelineno-63-53></a>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-63-54><a id=__codelineno-63-54 name=__codelineno-63-54 href=#__codelineno-63-54></a>    <span class=k>for</span> <span class=n>split</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>,</span> <span class=s1>&#39;val&#39;</span><span class=p>]:</span>
</span><span id=__span-63-55><a id=__codelineno-63-55 name=__codelineno-63-55 href=#__codelineno-63-55></a>        <span class=n>losses</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>eval_iters</span><span class=p>)</span>
</span><span id=__span-63-56><a id=__codelineno-63-56 name=__codelineno-63-56 href=#__codelineno-63-56></a>        <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>eval_iters</span><span class=p>):</span>
</span><span id=__span-63-57><a id=__codelineno-63-57 name=__codelineno-63-57 href=#__codelineno-63-57></a>            <span class=n>X</span><span class=p>,</span> <span class=n>Y</span> <span class=o>=</span> <span class=n>get_batch</span><span class=p>(</span><span class=n>split</span><span class=p>)</span>
</span><span id=__span-63-58><a id=__codelineno-63-58 name=__codelineno-63-58 href=#__codelineno-63-58></a>            <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>
</span><span id=__span-63-59><a id=__codelineno-63-59 name=__codelineno-63-59 href=#__codelineno-63-59></a>            <span class=n>losses</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-63-60><a id=__codelineno-63-60 name=__codelineno-63-60 href=#__codelineno-63-60></a>        <span class=n>out</span><span class=p>[</span><span class=n>split</span><span class=p>]</span> <span class=o>=</span> <span class=n>losses</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-63-61><a id=__codelineno-63-61 name=__codelineno-63-61 href=#__codelineno-63-61></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-63-62><a id=__codelineno-63-62 name=__codelineno-63-62 href=#__codelineno-63-62></a>    <span class=k>return</span> <span class=n>out</span>
</span><span id=__span-63-63><a id=__codelineno-63-63 name=__codelineno-63-63 href=#__codelineno-63-63></a>
</span><span id=__span-63-64><a id=__codelineno-63-64 name=__codelineno-63-64 href=#__codelineno-63-64></a><span class=k>class</span><span class=w> </span><span class=nc>Head</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-63-65><a id=__codelineno-63-65 name=__codelineno-63-65 href=#__codelineno-63-65></a><span class=w>    </span><span class=sd>&quot;&quot;&quot; 一つの自己注意ヘッド &quot;&quot;&quot;</span>
</span><span id=__span-63-66><a id=__codelineno-63-66 name=__codelineno-63-66 href=#__codelineno-63-66></a>
</span><span id=__span-63-67><a id=__codelineno-63-67 name=__codelineno-63-67 href=#__codelineno-63-67></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>head_size</span><span class=p>):</span>
</span><span id=__span-63-68><a id=__codelineno-63-68 name=__codelineno-63-68 href=#__codelineno-63-68></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-63-69><a id=__codelineno-63-69 name=__codelineno-63-69 href=#__codelineno-63-69></a>        <span class=bp>self</span><span class=o>.</span><span class=n>key</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-63-70><a id=__codelineno-63-70 name=__codelineno-63-70 href=#__codelineno-63-70></a>        <span class=bp>self</span><span class=o>.</span><span class=n>query</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-63-71><a id=__codelineno-63-71 name=__codelineno-63-71 href=#__codelineno-63-71></a>        <span class=bp>self</span><span class=o>.</span><span class=n>value</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>head_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-63-72><a id=__codelineno-63-72 name=__codelineno-63-72 href=#__codelineno-63-72></a>        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>&#39;tril&#39;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>tril</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>block_size</span><span class=p>,</span> <span class=n>block_size</span><span class=p>)))</span>
</span><span id=__span-63-73><a id=__codelineno-63-73 name=__codelineno-63-73 href=#__codelineno-63-73></a>
</span><span id=__span-63-74><a id=__codelineno-63-74 name=__codelineno-63-74 href=#__codelineno-63-74></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-63-75><a id=__codelineno-63-75 name=__codelineno-63-75 href=#__codelineno-63-75></a>
</span><span id=__span-63-76><a id=__codelineno-63-76 name=__codelineno-63-76 href=#__codelineno-63-76></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-63-77><a id=__codelineno-63-77 name=__codelineno-63-77 href=#__codelineno-63-77></a>        <span class=c1># サイズ(batch, time-step, channels)の入力</span>
</span><span id=__span-63-78><a id=__codelineno-63-78 name=__codelineno-63-78 href=#__codelineno-63-78></a>        <span class=c1># サイズ(batch, time-step, head size)の出力</span>
</span><span id=__span-63-79><a id=__codelineno-63-79 name=__codelineno-63-79 href=#__codelineno-63-79></a>        <span class=n>B</span><span class=p>,</span><span class=n>T</span><span class=p>,</span><span class=n>C</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-63-80><a id=__codelineno-63-80 name=__codelineno-63-80 href=#__codelineno-63-80></a>        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>key</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>   <span class=c1># (B,T,hs)</span>
</span><span id=__span-63-81><a id=__codelineno-63-81 name=__codelineno-63-81 href=#__codelineno-63-81></a>        <span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B,T,hs)</span>
</span><span id=__span-63-82><a id=__codelineno-63-82 name=__codelineno-63-82 href=#__codelineno-63-82></a>        <span class=c1># アテンションスコア（「アフィニティ」）を計算</span>
</span><span id=__span-63-83><a id=__codelineno-63-83 name=__codelineno-63-83 href=#__codelineno-63-83></a>        <span class=n>wei</span> <span class=o>=</span> <span class=n>q</span> <span class=o>@</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>k</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>**-</span><span class=mf>0.5</span> <span class=c1># (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)</span>
</span><span id=__span-63-84><a id=__codelineno-63-84 name=__codelineno-63-84 href=#__codelineno-63-84></a>        <span class=n>wei</span> <span class=o>=</span> <span class=n>wei</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tril</span><span class=p>[:</span><span class=n>T</span><span class=p>,</span> <span class=p>:</span><span class=n>T</span><span class=p>]</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span> <span class=c1># (B, T, T)</span>
</span><span id=__span-63-85><a id=__codelineno-63-85 name=__codelineno-63-85 href=#__codelineno-63-85></a>        <span class=n>wei</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>wei</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, T, T)</span>
</span><span id=__span-63-86><a id=__codelineno-63-86 name=__codelineno-63-86 href=#__codelineno-63-86></a>        <span class=n>wei</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>wei</span><span class=p>)</span>
</span><span id=__span-63-87><a id=__codelineno-63-87 name=__codelineno-63-87 href=#__codelineno-63-87></a>        <span class=c1># バリューの重み付き集約を実行</span>
</span><span id=__span-63-88><a id=__codelineno-63-88 name=__codelineno-63-88 href=#__codelineno-63-88></a>        <span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>value</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B,T,hs)</span>
</span><span id=__span-63-89><a id=__codelineno-63-89 name=__codelineno-63-89 href=#__codelineno-63-89></a>        <span class=n>out</span> <span class=o>=</span> <span class=n>wei</span> <span class=o>@</span> <span class=n>v</span> <span class=c1># (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)</span>
</span><span id=__span-63-90><a id=__codelineno-63-90 name=__codelineno-63-90 href=#__codelineno-63-90></a>        <span class=k>return</span> <span class=n>out</span>
</span><span id=__span-63-91><a id=__codelineno-63-91 name=__codelineno-63-91 href=#__codelineno-63-91></a>
</span><span id=__span-63-92><a id=__codelineno-63-92 name=__codelineno-63-92 href=#__codelineno-63-92></a><span class=k>class</span><span class=w> </span><span class=nc>MultiHeadAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-63-93><a id=__codelineno-63-93 name=__codelineno-63-93 href=#__codelineno-63-93></a><span class=w>    </span><span class=sd>&quot;&quot;&quot; 複数の自己注意ヘッドを並列実行 &quot;&quot;&quot;</span>
</span><span id=__span-63-94><a id=__codelineno-63-94 name=__codelineno-63-94 href=#__codelineno-63-94></a>
</span><span id=__span-63-95><a id=__codelineno-63-95 name=__codelineno-63-95 href=#__codelineno-63-95></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>head_size</span><span class=p>):</span>
</span><span id=__span-63-96><a id=__codelineno-63-96 name=__codelineno-63-96 href=#__codelineno-63-96></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-63-97><a id=__codelineno-63-97 name=__codelineno-63-97 href=#__codelineno-63-97></a>        <span class=bp>self</span><span class=o>.</span><span class=n>heads</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span><span class=n>Head</span><span class=p>(</span><span class=n>head_size</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_heads</span><span class=p>)])</span>
</span><span id=__span-63-98><a id=__codelineno-63-98 name=__codelineno-63-98 href=#__codelineno-63-98></a>        <span class=bp>self</span><span class=o>.</span><span class=n>proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>head_size</span> <span class=o>*</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-63-99><a id=__codelineno-63-99 name=__codelineno-63-99 href=#__codelineno-63-99></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-63-100><a id=__codelineno-63-100 name=__codelineno-63-100 href=#__codelineno-63-100></a>
</span><span id=__span-63-101><a id=__codelineno-63-101 name=__codelineno-63-101 href=#__codelineno-63-101></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-63-102><a id=__codelineno-63-102 name=__codelineno-63-102 href=#__codelineno-63-102></a>        <span class=n>out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>h</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>h</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-63-103><a id=__codelineno-63-103 name=__codelineno-63-103 href=#__codelineno-63-103></a>        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>proj</span><span class=p>(</span><span class=n>out</span><span class=p>))</span>
</span><span id=__span-63-104><a id=__codelineno-63-104 name=__codelineno-63-104 href=#__codelineno-63-104></a>        <span class=k>return</span> <span class=n>out</span>
</span><span id=__span-63-105><a id=__codelineno-63-105 name=__codelineno-63-105 href=#__codelineno-63-105></a>
</span><span id=__span-63-106><a id=__codelineno-63-106 name=__codelineno-63-106 href=#__codelineno-63-106></a><span class=k>class</span><span class=w> </span><span class=nc>FeedFoward</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-63-107><a id=__codelineno-63-107 name=__codelineno-63-107 href=#__codelineno-63-107></a><span class=w>    </span><span class=sd>&quot;&quot;&quot; 非線形性を伴うシンプルな線形層 &quot;&quot;&quot;</span>
</span><span id=__span-63-108><a id=__codelineno-63-108 name=__codelineno-63-108 href=#__codelineno-63-108></a>
</span><span id=__span-63-109><a id=__codelineno-63-109 name=__codelineno-63-109 href=#__codelineno-63-109></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>):</span>
</span><span id=__span-63-110><a id=__codelineno-63-110 name=__codelineno-63-110 href=#__codelineno-63-110></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-63-111><a id=__codelineno-63-111 name=__codelineno-63-111 href=#__codelineno-63-111></a>        <span class=bp>self</span><span class=o>.</span><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span><span id=__span-63-112><a id=__codelineno-63-112 name=__codelineno-63-112 href=#__codelineno-63-112></a>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>),</span>
</span><span id=__span-63-113><a id=__codelineno-63-113 name=__codelineno-63-113 href=#__codelineno-63-113></a>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span><span id=__span-63-114><a id=__codelineno-63-114 name=__codelineno-63-114 href=#__codelineno-63-114></a>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>),</span>
</span><span id=__span-63-115><a id=__codelineno-63-115 name=__codelineno-63-115 href=#__codelineno-63-115></a>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>),</span>
</span><span id=__span-63-116><a id=__codelineno-63-116 name=__codelineno-63-116 href=#__codelineno-63-116></a>        <span class=p>)</span>
</span><span id=__span-63-117><a id=__codelineno-63-117 name=__codelineno-63-117 href=#__codelineno-63-117></a>
</span><span id=__span-63-118><a id=__codelineno-63-118 name=__codelineno-63-118 href=#__codelineno-63-118></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-63-119><a id=__codelineno-63-119 name=__codelineno-63-119 href=#__codelineno-63-119></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>net</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-63-120><a id=__codelineno-63-120 name=__codelineno-63-120 href=#__codelineno-63-120></a>
</span><span id=__span-63-121><a id=__codelineno-63-121 name=__codelineno-63-121 href=#__codelineno-63-121></a><span class=k>class</span><span class=w> </span><span class=nc>Block</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-63-122><a id=__codelineno-63-122 name=__codelineno-63-122 href=#__codelineno-63-122></a><span class=w>    </span><span class=sd>&quot;&quot;&quot; Transformerブロック: 通信の後に計算を行う &quot;&quot;&quot;</span>
</span><span id=__span-63-123><a id=__codelineno-63-123 name=__codelineno-63-123 href=#__codelineno-63-123></a>
</span><span id=__span-63-124><a id=__codelineno-63-124 name=__codelineno-63-124 href=#__codelineno-63-124></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>):</span>
</span><span id=__span-63-125><a id=__codelineno-63-125 name=__codelineno-63-125 href=#__codelineno-63-125></a>        <span class=c1># n_embd: 埋め込み次元, n_head: 使用したいヘッド数</span>
</span><span id=__span-63-126><a id=__codelineno-63-126 name=__codelineno-63-126 href=#__codelineno-63-126></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-63-127><a id=__codelineno-63-127 name=__codelineno-63-127 href=#__codelineno-63-127></a>        <span class=n>head_size</span> <span class=o>=</span> <span class=n>n_embd</span> <span class=o>//</span> <span class=n>n_head</span>
</span><span id=__span-63-128><a id=__codelineno-63-128 name=__codelineno-63-128 href=#__codelineno-63-128></a>        <span class=bp>self</span><span class=o>.</span><span class=n>sa</span> <span class=o>=</span> <span class=n>MultiHeadAttention</span><span class=p>(</span><span class=n>n_head</span><span class=p>,</span> <span class=n>head_size</span><span class=p>)</span>
</span><span id=__span-63-129><a id=__codelineno-63-129 name=__codelineno-63-129 href=#__codelineno-63-129></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ffwd</span> <span class=o>=</span> <span class=n>FeedFoward</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-63-130><a id=__codelineno-63-130 name=__codelineno-63-130 href=#__codelineno-63-130></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ln1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-63-131><a id=__codelineno-63-131 name=__codelineno-63-131 href=#__codelineno-63-131></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ln2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-63-132><a id=__codelineno-63-132 name=__codelineno-63-132 href=#__codelineno-63-132></a>
</span><span id=__span-63-133><a id=__codelineno-63-133 name=__codelineno-63-133 href=#__codelineno-63-133></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-63-134><a id=__codelineno-63-134 name=__codelineno-63-134 href=#__codelineno-63-134></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>sa</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-63-135><a id=__codelineno-63-135 name=__codelineno-63-135 href=#__codelineno-63-135></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>ffwd</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-63-136><a id=__codelineno-63-136 name=__codelineno-63-136 href=#__codelineno-63-136></a>        <span class=k>return</span> <span class=n>x</span>
</span><span id=__span-63-137><a id=__codelineno-63-137 name=__codelineno-63-137 href=#__codelineno-63-137></a>
</span><span id=__span-63-138><a id=__codelineno-63-138 name=__codelineno-63-138 href=#__codelineno-63-138></a><span class=k>class</span><span class=w> </span><span class=nc>GPTLanguageModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-63-139><a id=__codelineno-63-139 name=__codelineno-63-139 href=#__codelineno-63-139></a>
</span><span id=__span-63-140><a id=__codelineno-63-140 name=__codelineno-63-140 href=#__codelineno-63-140></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-63-141><a id=__codelineno-63-141 name=__codelineno-63-141 href=#__codelineno-63-141></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-63-142><a id=__codelineno-63-142 name=__codelineno-63-142 href=#__codelineno-63-142></a>        <span class=c1># 各トークンは、埋め込み層から次のトークンのロジットを直接読み取る</span>
</span><span id=__span-63-143><a id=__codelineno-63-143 name=__codelineno-63-143 href=#__codelineno-63-143></a>        <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding_table</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-63-144><a id=__codelineno-63-144 name=__codelineno-63-144 href=#__codelineno-63-144></a>        <span class=bp>self</span><span class=o>.</span><span class=n>position_embedding_table</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>block_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span><span id=__span-63-145><a id=__codelineno-63-145 name=__codelineno-63-145 href=#__codelineno-63-145></a>        <span class=bp>self</span><span class=o>.</span><span class=n>blocks</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span><span class=n>Block</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=o>=</span><span class=n>n_head</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_layer</span><span class=p>)])</span>
</span><span id=__span-63-146><a id=__codelineno-63-146 name=__codelineno-63-146 href=#__codelineno-63-146></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span> <span class=c1># 最終レイヤー正規化</span>
</span><span id=__span-63-147><a id=__codelineno-63-147 name=__codelineno-63-147 href=#__codelineno-63-147></a>        <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>)</span>
</span><span id=__span-63-148><a id=__codelineno-63-148 name=__codelineno-63-148 href=#__codelineno-63-148></a>
</span><span id=__span-63-149><a id=__codelineno-63-149 name=__codelineno-63-149 href=#__codelineno-63-149></a>        <span class=c1># より良い初期化、元のGPTビデオでは扱わなかったが重要、フォローアップビデオで扱う予定</span>
</span><span id=__span-63-150><a id=__codelineno-63-150 name=__codelineno-63-150 href=#__codelineno-63-150></a>        <span class=bp>self</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_init_weights</span><span class=p>)</span>
</span><span id=__span-63-151><a id=__codelineno-63-151 name=__codelineno-63-151 href=#__codelineno-63-151></a>
</span><span id=__span-63-152><a id=__codelineno-63-152 name=__codelineno-63-152 href=#__codelineno-63-152></a>    <span class=k>def</span><span class=w> </span><span class=nf>_init_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>module</span><span class=p>):</span>
</span><span id=__span-63-153><a id=__codelineno-63-153 name=__codelineno-63-153 href=#__codelineno-63-153></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-63-154><a id=__codelineno-63-154 name=__codelineno-63-154 href=#__codelineno-63-154></a><span class=sd>        GPT式重み初期化：標準偏差0.02の正規分布を使用</span>
</span><span id=__span-63-155><a id=__codelineno-63-155 name=__codelineno-63-155 href=#__codelineno-63-155></a><span class=sd>        この値はTransformerアーキテクチャに最適化された経験的結果</span>
</span><span id=__span-63-156><a id=__codelineno-63-156 name=__codelineno-63-156 href=#__codelineno-63-156></a><span class=sd>        &quot;&quot;&quot;</span>
</span><span id=__span-63-157><a id=__codelineno-63-157 name=__codelineno-63-157 href=#__codelineno-63-157></a>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span><span id=__span-63-158><a id=__codelineno-63-158 name=__codelineno-63-158 href=#__codelineno-63-158></a>            <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-63-159><a id=__codelineno-63-159 name=__codelineno-63-159 href=#__codelineno-63-159></a>            <span class=k>if</span> <span class=n>module</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-63-160><a id=__codelineno-63-160 name=__codelineno-63-160 href=#__codelineno-63-160></a>                <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span><span id=__span-63-161><a id=__codelineno-63-161 name=__codelineno-63-161 href=#__codelineno-63-161></a>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>):</span>
</span><span id=__span-63-162><a id=__codelineno-63-162 name=__codelineno-63-162 href=#__codelineno-63-162></a>            <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-63-163><a id=__codelineno-63-163 name=__codelineno-63-163 href=#__codelineno-63-163></a>
</span><span id=__span-63-164><a id=__codelineno-63-164 name=__codelineno-63-164 href=#__codelineno-63-164></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>,</span> <span class=n>targets</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-63-165><a id=__codelineno-63-165 name=__codelineno-63-165 href=#__codelineno-63-165></a>        <span class=n>B</span><span class=p>,</span> <span class=n>T</span> <span class=o>=</span> <span class=n>idx</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-63-166><a id=__codelineno-63-166 name=__codelineno-63-166 href=#__codelineno-63-166></a>
</span><span id=__span-63-167><a id=__codelineno-63-167 name=__codelineno-63-167 href=#__codelineno-63-167></a>        <span class=c1># idxとtargetsはどちらも整数の(B,T)テンソル</span>
</span><span id=__span-63-168><a id=__codelineno-63-168 name=__codelineno-63-168 href=#__codelineno-63-168></a>        <span class=n>tok_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding_table</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span> <span class=c1># (B,T,C)</span>
</span><span id=__span-63-169><a id=__codelineno-63-169 name=__codelineno-63-169 href=#__codelineno-63-169></a>        <span class=n>pos_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>position_embedding_table</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>))</span> <span class=c1># (T,C)</span>
</span><span id=__span-63-170><a id=__codelineno-63-170 name=__codelineno-63-170 href=#__codelineno-63-170></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>tok_emb</span> <span class=o>+</span> <span class=n>pos_emb</span> <span class=c1># (B,T,C)</span>
</span><span id=__span-63-171><a id=__codelineno-63-171 name=__codelineno-63-171 href=#__codelineno-63-171></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>blocks</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B,T,C)</span>
</span><span id=__span-63-172><a id=__codelineno-63-172 name=__codelineno-63-172 href=#__codelineno-63-172></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B,T,C)</span>
</span><span id=__span-63-173><a id=__codelineno-63-173 name=__codelineno-63-173 href=#__codelineno-63-173></a>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lm_head</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># (B,T,vocab_size)</span>
</span><span id=__span-63-174><a id=__codelineno-63-174 name=__codelineno-63-174 href=#__codelineno-63-174></a>
</span><span id=__span-63-175><a id=__codelineno-63-175 name=__codelineno-63-175 href=#__codelineno-63-175></a>        <span class=k>if</span> <span class=n>targets</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-63-176><a id=__codelineno-63-176 name=__codelineno-63-176 href=#__codelineno-63-176></a>            <span class=n>loss</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-63-177><a id=__codelineno-63-177 name=__codelineno-63-177 href=#__codelineno-63-177></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-63-178><a id=__codelineno-63-178 name=__codelineno-63-178 href=#__codelineno-63-178></a>            <span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-63-179><a id=__codelineno-63-179 name=__codelineno-63-179 href=#__codelineno-63-179></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>T</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span>
</span><span id=__span-63-180><a id=__codelineno-63-180 name=__codelineno-63-180 href=#__codelineno-63-180></a>            <span class=n>targets</span> <span class=o>=</span> <span class=n>targets</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=o>*</span><span class=n>T</span><span class=p>)</span>
</span><span id=__span-63-181><a id=__codelineno-63-181 name=__codelineno-63-181 href=#__codelineno-63-181></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span><span id=__span-63-182><a id=__codelineno-63-182 name=__codelineno-63-182 href=#__codelineno-63-182></a>
</span><span id=__span-63-183><a id=__codelineno-63-183 name=__codelineno-63-183 href=#__codelineno-63-183></a>        <span class=k>return</span> <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span>
</span><span id=__span-63-184><a id=__codelineno-63-184 name=__codelineno-63-184 href=#__codelineno-63-184></a>
</span><span id=__span-63-185><a id=__codelineno-63-185 name=__codelineno-63-185 href=#__codelineno-63-185></a>    <span class=k>def</span><span class=w> </span><span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=p>):</span>
</span><span id=__span-63-186><a id=__codelineno-63-186 name=__codelineno-63-186 href=#__codelineno-63-186></a>        <span class=c1># idxは現在のコンテキストのインデックスの(B, T)配列</span>
</span><span id=__span-63-187><a id=__codelineno-63-187 name=__codelineno-63-187 href=#__codelineno-63-187></a>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_new_tokens</span><span class=p>):</span>
</span><span id=__span-63-188><a id=__codelineno-63-188 name=__codelineno-63-188 href=#__codelineno-63-188></a>            <span class=c1># idxを最後のblock_sizeトークンにクロップ</span>
</span><span id=__span-63-189><a id=__codelineno-63-189 name=__codelineno-63-189 href=#__codelineno-63-189></a>            <span class=n>idx_cond</span> <span class=o>=</span> <span class=n>idx</span><span class=p>[:,</span> <span class=o>-</span><span class=n>block_size</span><span class=p>:]</span>
</span><span id=__span-63-190><a id=__codelineno-63-190 name=__codelineno-63-190 href=#__codelineno-63-190></a>            <span class=c1># 予測を取得</span>
</span><span id=__span-63-191><a id=__codelineno-63-191 name=__codelineno-63-191 href=#__codelineno-63-191></a>            <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=p>(</span><span class=n>idx_cond</span><span class=p>)</span>
</span><span id=__span-63-192><a id=__codelineno-63-192 name=__codelineno-63-192 href=#__codelineno-63-192></a>            <span class=c1># 最後の時間ステップにのみ焦点を当てる</span>
</span><span id=__span-63-193><a id=__codelineno-63-193 name=__codelineno-63-193 href=#__codelineno-63-193></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># (B, C)になる</span>
</span><span id=__span-63-194><a id=__codelineno-63-194 name=__codelineno-63-194 href=#__codelineno-63-194></a>            <span class=c1># softmaxを適用して確率を取得</span>
</span><span id=__span-63-195><a id=__codelineno-63-195 name=__codelineno-63-195 href=#__codelineno-63-195></a>            <span class=n>probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, C)</span>
</span><span id=__span-63-196><a id=__codelineno-63-196 name=__codelineno-63-196 href=#__codelineno-63-196></a>            <span class=c1># 分布からサンプル</span>
</span><span id=__span-63-197><a id=__codelineno-63-197 name=__codelineno-63-197 href=#__codelineno-63-197></a>            <span class=n>idx_next</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>num_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, 1)</span>
</span><span id=__span-63-198><a id=__codelineno-63-198 name=__codelineno-63-198 href=#__codelineno-63-198></a>            <span class=c1># サンプルされたインデックスを実行シーケンスに追加</span>
</span><span id=__span-63-199><a id=__codelineno-63-199 name=__codelineno-63-199 href=#__codelineno-63-199></a>            <span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>idx</span><span class=p>,</span> <span class=n>idx_next</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># (B, T+1)</span>
</span><span id=__span-63-200><a id=__codelineno-63-200 name=__codelineno-63-200 href=#__codelineno-63-200></a>        <span class=k>return</span> <span class=n>idx</span>
</span><span id=__span-63-201><a id=__codelineno-63-201 name=__codelineno-63-201 href=#__codelineno-63-201></a><span class=n>model</span> <span class=o>=</span> <span class=n>GPTLanguageModel</span><span class=p>()</span>
</span><span id=__span-63-202><a id=__codelineno-63-202 name=__codelineno-63-202 href=#__codelineno-63-202></a><span class=n>m</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-63-203><a id=__codelineno-63-203 name=__codelineno-63-203 href=#__codelineno-63-203></a><span class=c1># モデル内のパラメータ数を出力</span>
</span><span id=__span-63-204><a id=__codelineno-63-204 name=__codelineno-63-204 href=#__codelineno-63-204></a><span class=nb>print</span><span class=p>(</span><span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>m</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>/</span><span class=mf>1e6</span><span class=p>,</span> <span class=s1>&#39;M parameters&#39;</span><span class=p>)</span>
</span><span id=__span-63-205><a id=__codelineno-63-205 name=__codelineno-63-205 href=#__codelineno-63-205></a>
</span><span id=__span-63-206><a id=__codelineno-63-206 name=__codelineno-63-206 href=#__codelineno-63-206></a><span class=c1># PyTorchオプティマイザの作成</span>
</span><span id=__span-63-207><a id=__codelineno-63-207 name=__codelineno-63-207 href=#__codelineno-63-207></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>
</span><span id=__span-63-208><a id=__codelineno-63-208 name=__codelineno-63-208 href=#__codelineno-63-208></a>
</span><span id=__span-63-209><a id=__codelineno-63-209 name=__codelineno-63-209 href=#__codelineno-63-209></a><span class=k>for</span> <span class=nb>iter</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_iters</span><span class=p>):</span>
</span><span id=__span-63-210><a id=__codelineno-63-210 name=__codelineno-63-210 href=#__codelineno-63-210></a>
</span><span id=__span-63-211><a id=__codelineno-63-211 name=__codelineno-63-211 href=#__codelineno-63-211></a>    <span class=c1># 定期的に訓練セットと検証セットで損失を評価</span>
</span><span id=__span-63-212><a id=__codelineno-63-212 name=__codelineno-63-212 href=#__codelineno-63-212></a>    <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=n>eval_interval</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>or</span> <span class=nb>iter</span> <span class=o>==</span> <span class=n>max_iters</span> <span class=o>-</span> <span class=mi>1</span><span class=p>:</span>
</span><span id=__span-63-213><a id=__codelineno-63-213 name=__codelineno-63-213 href=#__codelineno-63-213></a>        <span class=n>losses</span> <span class=o>=</span> <span class=n>estimate_loss</span><span class=p>()</span>
</span><span id=__span-63-214><a id=__codelineno-63-214 name=__codelineno-63-214 href=#__codelineno-63-214></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;step </span><span class=si>{</span><span class=nb>iter</span><span class=si>}</span><span class=s2>: train loss </span><span class=si>{</span><span class=n>losses</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>, val loss </span><span class=si>{</span><span class=n>losses</span><span class=p>[</span><span class=s1>&#39;val&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-63-215><a id=__codelineno-63-215 name=__codelineno-63-215 href=#__codelineno-63-215></a>
</span><span id=__span-63-216><a id=__codelineno-63-216 name=__codelineno-63-216 href=#__codelineno-63-216></a>    <span class=c1># データのバッチをサンプル</span>
</span><span id=__span-63-217><a id=__codelineno-63-217 name=__codelineno-63-217 href=#__codelineno-63-217></a>    <span class=n>xb</span><span class=p>,</span> <span class=n>yb</span> <span class=o>=</span> <span class=n>get_batch</span><span class=p>(</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span><span id=__span-63-218><a id=__codelineno-63-218 name=__codelineno-63-218 href=#__codelineno-63-218></a>
</span><span id=__span-63-219><a id=__codelineno-63-219 name=__codelineno-63-219 href=#__codelineno-63-219></a>    <span class=c1># 損失を評価</span>
</span><span id=__span-63-220><a id=__codelineno-63-220 name=__codelineno-63-220 href=#__codelineno-63-220></a>    <span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>xb</span><span class=p>,</span> <span class=n>yb</span><span class=p>)</span>
</span><span id=__span-63-221><a id=__codelineno-63-221 name=__codelineno-63-221 href=#__codelineno-63-221></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>(</span><span class=n>set_to_none</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-63-222><a id=__codelineno-63-222 name=__codelineno-63-222 href=#__codelineno-63-222></a>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-63-223><a id=__codelineno-63-223 name=__codelineno-63-223 href=#__codelineno-63-223></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-63-224><a id=__codelineno-63-224 name=__codelineno-63-224 href=#__codelineno-63-224></a>
</span><span id=__span-63-225><a id=__codelineno-63-225 name=__codelineno-63-225 href=#__codelineno-63-225></a><span class=c1># モデルから生成</span>
</span><span id=__span-63-226><a id=__codelineno-63-226 name=__codelineno-63-226 href=#__codelineno-63-226></a><span class=n>context</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-63-227><a id=__codelineno-63-227 name=__codelineno-63-227 href=#__codelineno-63-227></a><span class=nb>print</span><span class=p>(</span><span class=n>decode</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>context</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>500</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>tolist</span><span class=p>()))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-64-1><a id=__codelineno-64-1 name=__codelineno-64-1 href=#__codelineno-64-1></a>--2025-08-28 21:14:55--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt
</span><span id=__span-64-2><a id=__codelineno-64-2 name=__codelineno-64-2 href=#__codelineno-64-2></a>raw.githubusercontent.com (raw.githubusercontent.com) をDNSに問い合わせています... 2606:50c0:8001::154, 2606:50c0:8000::154, 2606:50c0:8003::154, ...
</span><span id=__span-64-3><a id=__codelineno-64-3 name=__codelineno-64-3 href=#__codelineno-64-3></a>raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443 に接続しています... 接続しました。
</span><span id=__span-64-4><a id=__codelineno-64-4 name=__codelineno-64-4 href=#__codelineno-64-4></a>HTTP による接続要求を送信しました、応答を待っています... 200 OK
</span><span id=__span-64-5><a id=__codelineno-64-5 name=__codelineno-64-5 href=#__codelineno-64-5></a>長さ: 1115394 (1.1M) [text/plain]
</span><span id=__span-64-6><a id=__codelineno-64-6 name=__codelineno-64-6 href=#__codelineno-64-6></a>`input.txt&#39; に保存中
</span><span id=__span-64-7><a id=__codelineno-64-7 name=__codelineno-64-7 href=#__codelineno-64-7></a>
</span><span id=__span-64-8><a id=__codelineno-64-8 name=__codelineno-64-8 href=#__codelineno-64-8></a>input.txt           100%[===================&gt;]   1.06M  --.-KB/s 時間 0.1s       
</span><span id=__span-64-9><a id=__codelineno-64-9 name=__codelineno-64-9 href=#__codelineno-64-9></a>
</span><span id=__span-64-10><a id=__codelineno-64-10 name=__codelineno-64-10 href=#__codelineno-64-10></a>2025-08-28 21:14:56 (7.62 MB/s) - `input.txt&#39; へ保存完了 [1115394/1115394]
</span><span id=__span-64-11><a id=__codelineno-64-11 name=__codelineno-64-11 href=#__codelineno-64-11></a>
</span><span id=__span-64-12><a id=__codelineno-64-12 name=__codelineno-64-12 href=#__codelineno-64-12></a>10.788929 M parameters
</span><span id=__span-64-13><a id=__codelineno-64-13 name=__codelineno-64-13 href=#__codelineno-64-13></a>step 0: train loss 4.2221, val loss 4.2306
</span><span id=__span-64-14><a id=__codelineno-64-14 name=__codelineno-64-14 href=#__codelineno-64-14></a>step 500: train loss 1.7444, val loss 1.9058
</span><span id=__span-64-15><a id=__codelineno-64-15 name=__codelineno-64-15 href=#__codelineno-64-15></a>step 1000: train loss 1.3914, val loss 1.5998
</span><span id=__span-64-16><a id=__codelineno-64-16 name=__codelineno-64-16 href=#__codelineno-64-16></a>step 1500: train loss 1.2659, val loss 1.5262
</span><span id=__span-64-17><a id=__codelineno-64-17 name=__codelineno-64-17 href=#__codelineno-64-17></a>step 2000: train loss 1.1856, val loss 1.5041
</span><span id=__span-64-18><a id=__codelineno-64-18 name=__codelineno-64-18 href=#__codelineno-64-18></a>step 2500: train loss 1.1206, val loss 1.4968
</span><span id=__span-64-19><a id=__codelineno-64-19 name=__codelineno-64-19 href=#__codelineno-64-19></a>step 3000: train loss 1.0732, val loss 1.4862
</span><span id=__span-64-20><a id=__codelineno-64-20 name=__codelineno-64-20 href=#__codelineno-64-20></a>step 3500: train loss 1.0168, val loss 1.5054
</span><span id=__span-64-21><a id=__codelineno-64-21 name=__codelineno-64-21 href=#__codelineno-64-21></a>step 4000: train loss 0.9598, val loss 1.5148
</span><span id=__span-64-22><a id=__codelineno-64-22 name=__codelineno-64-22 href=#__codelineno-64-22></a>step 4500: train loss 0.9094, val loss 1.5358
</span><span id=__span-64-23><a id=__codelineno-64-23 name=__codelineno-64-23 href=#__codelineno-64-23></a>step 4999: train loss 0.8632, val loss 1.5685
</span><span id=__span-64-24><a id=__codelineno-64-24 name=__codelineno-64-24 href=#__codelineno-64-24></a>
</span><span id=__span-64-25><a id=__codelineno-64-25 name=__codelineno-64-25 href=#__codelineno-64-25></a>a man one of a most wit that; a thousands
</span><span id=__span-64-26><a id=__codelineno-64-26 name=__codelineno-64-26 href=#__codelineno-64-26></a>with a most opiny. And a jest but
</span><span id=__span-64-27><a id=__codelineno-64-27 name=__codelineno-64-27 href=#__codelineno-64-27></a>to the fish self-bond, a disesimple; a monster.
</span><span id=__span-64-28><a id=__codelineno-64-28 name=__codelineno-64-28 href=#__codelineno-64-28></a>
</span><span id=__span-64-29><a id=__codelineno-64-29 name=__codelineno-64-29 href=#__codelineno-64-29></a>Shepherd:
</span><span id=__span-64-30><a id=__codelineno-64-30 name=__codelineno-64-30 href=#__codelineno-64-30></a>Lets for him, he desires and man of dain impojects. I reason
</span><span id=__span-64-31><a id=__codelineno-64-31 name=__codelineno-64-31 href=#__codelineno-64-31></a>to them, fell fear out of the sight: the Good take it advantage
</span><span id=__span-64-32><a id=__codelineno-64-32 name=__codelineno-64-32 href=#__codelineno-64-32></a>to your agnoly then bitine home. Stand, for for
</span><span id=__span-64-33><a id=__codelineno-64-33 name=__codelineno-64-33 href=#__codelineno-64-33></a>mine with Bianca. Powpan, the drink that you onceed his
</span><span id=__span-64-34><a id=__codelineno-64-34 name=__codelineno-64-34 href=#__codelineno-64-34></a>stair and the mair people with him: he&#39;s a song of this cause
</span><span id=__span-64-35><a id=__codelineno-64-35 name=__codelineno-64-35 href=#__codelineno-64-35></a>to live Escalus; he lies and kneel I
</span><span id=__span-64-36><a id=__codelineno-64-36 name=__codelineno-64-36 href=#__codelineno-64-36></a>require out absen; and ever
</span><span id=__span-64-37><a id=__codelineno-64-37 name=__codelineno-64-37 href=#__codelineno-64-37></a>be a judg
</span></code></pre></div></p> <h3 id=72>7.2 テキスト生成アルゴリズムの詳細解説<a class=headerlink href=#72 title="Permanent link">&para;</a></h3> <p>GPTがどのようにテキストを生成するのか、ステップごとに詳しく見ていきましょう。</p> <h4 id=gpt>なぜGPTはテキストを生成できるのか？<a class=headerlink href=#gpt title="Permanent link">&para;</a></h4> <p>GPTは<strong>「次に来る単語（文字）を予測する」</strong>ように訓練されています。この予測能力を使って、以下のように文章を生成します：</p> <p><strong>具体例で理解する生成プロセス</strong>： <div class="language-text highlight"><pre><span></span><code><span id=__span-65-1><a id=__codelineno-65-1 name=__codelineno-65-1 href=#__codelineno-65-1></a>Step 1: 入力「Hello, my name is」→ GPTが予測「John」
</span><span id=__span-65-2><a id=__codelineno-65-2 name=__codelineno-65-2 href=#__codelineno-65-2></a>Step 2: 入力「Hello, my name is John」→ GPTが予測「.」  
</span><span id=__span-65-3><a id=__codelineno-65-3 name=__codelineno-65-3 href=#__codelineno-65-3></a>Step 3: 入力「Hello, my name is John.」→ GPTが予測「I」
</span><span id=__span-65-4><a id=__codelineno-65-4 name=__codelineno-65-4 href=#__codelineno-65-4></a>Step 4: 入力「Hello, my name is John. I」→ GPTが予測「am」
</span><span id=__span-65-5><a id=__codelineno-65-5 name=__codelineno-65-5 href=#__codelineno-65-5></a>...このプロセスを繰り返す
</span></code></pre></div></p> <p>これを<strong>オートリグレッシブ生成</strong>と呼びます。「自分の出力を次の入力に使う」という意味です。</p> <h4 id=gpt5>GPT生成メソッドの5つのステップ<a class=headerlink href=#gpt5 title="Permanent link">&para;</a></h4> <p>それでは、実際のコードを見ながら、GPTがどのように1つずつ文字を生成するかを詳しく解説します。</p> <p><strong>Step 1: 入力の長さを制限する</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-66-1><a id=__codelineno-66-1 name=__codelineno-66-1 href=#__codelineno-66-1></a><span class=n>idx_cond</span> <span class=o>=</span> <span class=n>idx</span><span class=p>[:,</span> <span class=o>-</span><span class=n>block_size</span><span class=p>:]</span>  <span class=c1># 最新のblock_size個のトークンのみ使用</span>
</span></code></pre></div></p> <p><strong>なぜ長さを制限するの？</strong></p> <ul> <li><strong>メモリの節約</strong>: 長い文章全体を覚える必要がない</li> <li><strong>処理速度</strong>: 短い文章の方が計算が速い</li> <li><strong>学習時と同じ条件</strong>: 訓練時も同じ長さで学習したから</li> </ul> <p><strong>例</strong>: 本が長くても、最新の8ページだけ読んで次を予測する感じです <div class="language-text highlight"><pre><span></span><code><span id=__span-67-1><a id=__codelineno-67-1 name=__codelineno-67-1 href=#__codelineno-67-1></a>元の文章: [1,2,3,4,5,6,7,8,9,10,11] （11文字）
</span><span id=__span-67-2><a id=__codelineno-67-2 name=__codelineno-67-2 href=#__codelineno-67-2></a>↓ block_size=8の場合
</span><span id=__span-67-3><a id=__codelineno-67-3 name=__codelineno-67-3 href=#__codelineno-67-3></a>使用する部分: [4,5,6,7,8,9,10,11] （最新8文字のみ）
</span></code></pre></div></p> <p><strong>Step 2: モデルに予測させる</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-68-1><a id=__codelineno-68-1 name=__codelineno-68-1 href=#__codelineno-68-1></a><span class=n>logits</span><span class=p>,</span> <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=p>(</span><span class=n>idx_cond</span><span class=p>)</span>  <span class=c1># GPTモデルで予測</span>
</span><span id=__span-68-2><a id=__codelineno-68-2 name=__codelineno-68-2 href=#__codelineno-68-2></a><span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span>      <span class=c1># 最後の位置の予測のみ取得</span>
</span></code></pre></div></p> <p><strong>GPTの予測の仕組み</strong>: - GPTは入力文字列の「各位置」で次の文字を予測します - でも生成時は、「最後の位置の予測」だけが必要です</p> <p><strong>例</strong>: 「こんにち」という入力の場合 <div class="language-text highlight"><pre><span></span><code><span id=__span-69-1><a id=__codelineno-69-1 name=__codelineno-69-1 href=#__codelineno-69-1></a>位置1: 「こ」→ 次は「ん」を予測
</span><span id=__span-69-2><a id=__codelineno-69-2 name=__codelineno-69-2 href=#__codelineno-69-2></a>位置2: 「ん」→ 次は「に」を予測  
</span><span id=__span-69-3><a id=__codelineno-69-3 name=__codelineno-69-3 href=#__codelineno-69-3></a>位置3: 「に」→ 次は「ち」を予測
</span><span id=__span-69-4><a id=__codelineno-69-4 name=__codelineno-69-4 href=#__codelineno-69-4></a>位置4: 「ち」→ 次は「は」を予測 ← これだけが重要！
</span></code></pre></div></p> <p><strong>Step 3: 生スコアを確率に変換</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-70-1><a id=__codelineno-70-1 name=__codelineno-70-1 href=#__codelineno-70-1></a><span class=n>probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># 確率に変換</span>
</span></code></pre></div></p> <p><strong>なぜ確率に変換？</strong> GPTの出力は「生スコア」（ロジット）です。これを0〜1の確率に変換します。</p> <p><strong>例</strong>: 次の文字の予測スコア <div class="language-text highlight"><pre><span></span><code><span id=__span-71-1><a id=__codelineno-71-1 name=__codelineno-71-1 href=#__codelineno-71-1></a>生スコア: 「は」:8.2, 「わ」:2.1, 「ば」:1.5, 「が」:0.8
</span><span id=__span-71-2><a id=__codelineno-71-2 name=__codelineno-71-2 href=#__codelineno-71-2></a>↓ softmaxで変換
</span><span id=__span-71-3><a id=__codelineno-71-3 name=__codelineno-71-3 href=#__codelineno-71-3></a>確率: 「は」:89%, 「わ」:7%, 「ば」:3%, 「が」:1%
</span></code></pre></div></p> <p><strong>Step 4: 確率に基づいて1つの文字を選ぶ</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-72-1><a id=__codelineno-72-1 name=__codelineno-72-1 href=#__codelineno-72-1></a><span class=n>idx_next</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>num_samples</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># 確率的に選択</span>
</span></code></pre></div></p> <p><strong>なぜ最も確率の高い文字を選ばない？</strong> - <strong>創造性</strong>: 毎回同じ文章にならない - <strong>自然さ</strong>: 人間も完全に予測可能ではない - <strong>多様性</strong>: 面白い文章が生成される</p> <p><strong>例</strong>: 89%で「は」、7%で「わ」を選ぶ。たまに「わ」が選ばれるから面白い！</p> <p><strong>Step 5: 新しい文字を文章に追加</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-73-1><a id=__codelineno-73-1 name=__codelineno-73-1 href=#__codelineno-73-1></a><span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>idx</span><span class=p>,</span> <span class=n>idx_next</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># 新しい文字を追加</span>
</span></code></pre></div></p> <p><strong>完了！次のループに進む</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-74-1><a id=__codelineno-74-1 name=__codelineno-74-1 href=#__codelineno-74-1></a>元の文章: 「こんにち」
</span><span id=__span-74-2><a id=__codelineno-74-2 name=__codelineno-74-2 href=#__codelineno-74-2></a>↓ 新しい文字「は」を追加  
</span><span id=__span-74-3><a id=__codelineno-74-3 name=__codelineno-74-3 href=#__codelineno-74-3></a>新しい文章: 「こんにちは」
</span><span id=__span-74-4><a id=__codelineno-74-4 name=__codelineno-74-4 href=#__codelineno-74-4></a>↓ これが次のループの入力になる
</span></code></pre></div></p> <h4 id=_18>全体の流れをまとめて理解<a class=headerlink href=#_18 title="Permanent link">&para;</a></h4> <p><strong>1回のループで起こること</strong>: <div class="language-text highlight"><pre><span></span><code><span id=__span-75-1><a id=__codelineno-75-1 name=__codelineno-75-1 href=#__codelineno-75-1></a>入力: 「こんにち」
</span><span id=__span-75-2><a id=__codelineno-75-2 name=__codelineno-75-2 href=#__codelineno-75-2></a>Step 1: 最新8文字に制限 → 「こんにち」（8文字以下なのでそのまま）  
</span><span id=__span-75-3><a id=__codelineno-75-3 name=__codelineno-75-3 href=#__codelineno-75-3></a>Step 2: GPTで予測 → 各文字の確率を計算
</span><span id=__span-75-4><a id=__codelineno-75-4 name=__codelineno-75-4 href=#__codelineno-75-4></a>Step 3: 確率変換 → は:89%, わ:7%, ば:3%, が:1%
</span><span id=__span-75-5><a id=__codelineno-75-5 name=__codelineno-75-5 href=#__codelineno-75-5></a>Step 4: 確率的選択 → 「は」を選択
</span><span id=__span-75-6><a id=__codelineno-75-6 name=__codelineno-75-6 href=#__codelineno-75-6></a>Step 5: 文章更新 → 「こんにちは」
</span><span id=__span-75-7><a id=__codelineno-75-7 name=__codelineno-75-7 href=#__codelineno-75-7></a>
</span><span id=__span-75-8><a id=__codelineno-75-8 name=__codelineno-75-8 href=#__codelineno-75-8></a>次のループ:
</span><span id=__span-75-9><a id=__codelineno-75-9 name=__codelineno-75-9 href=#__codelineno-75-9></a>入力: 「こんにちは」  
</span><span id=__span-75-10><a id=__codelineno-75-10 name=__codelineno-75-10 href=#__codelineno-75-10></a>→ 同じ処理を繰り返して次の文字を生成...
</span></code></pre></div></p> <p>これを指定回数（例：500回）繰り返すことで、長い文章を生成できます！</p> <h4 id=_19>より良いテキストを生成するには？<a class=headerlink href=#_19 title="Permanent link">&para;</a></h4> <p><strong>1. 温度（Temperature）の調整</strong> - 今回は未実装ですが重要 <div class="language-python highlight"><pre><span></span><code><span id=__span-76-1><a id=__codelineno-76-1 name=__codelineno-76-1 href=#__codelineno-76-1></a><span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span> <span class=o>/</span> <span class=n>temperature</span>  <span class=c1># temperatureで調整</span>
</span><span id=__span-76-2><a id=__codelineno-76-2 name=__codelineno-76-2 href=#__codelineno-76-2></a><span class=n>probs</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></code></pre></div> - <strong>温度が低い（例：0.3）</strong>: 安全で予測しやすい文章 - <strong>温度が高い（例：1.5）</strong>: 創造的で予測しにくい文章</p> <p><strong>2. より長いコンテキスト</strong> - <code>block_size</code>を大きくすると、より長い文脈を覚えられる - より一貫性のある文章が生成される</p> <p><strong>3. より大きなモデル</strong> - パラメータ数が多いほど、より賢い文章を生成 - 実際のChatGPTは数十億〜数千億パラメータ</p> <p><strong>4. より多くの訓練データ</strong> - 多様な文章で学習するほど、多様な表現ができる</p> <div class="admonition tip"> <p class=admonition-title>実際の応用では</p> <p>ChatGPTなどでは、KV-Cacheという高速化技術や、より洗練されたサンプリング手法（Top-p sampling等）が使用されています。</p> </div> <h2 id=8>8. 参考資料<a class=headerlink href=#8 title="Permanent link">&para;</a></h2> <p><strong>使用したデータソース</strong>: - <a href=https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt>Tiny Shakespeare Dataset</a></p> <p><strong>参考文献</strong>: - Vaswani, A., et al. "Attention is all you need." Advances in neural information processing systems 30 (2017) - Radford, A., et al. "Language models are unsupervised multitask learners." OpenAI blog 1.8 (2019): 9</p> <p><strong>関連リンク</strong>: - <a href=https://www.youtube.com/@AndrejKarpathy>Andrej Karpathy's YouTube Channel</a> - <a href=https://pytorch.org/docs/stable/index.html>PyTorch Documentation</a> - <a href=https://huggingface.co/docs/transformers/index>Hugging Face Transformers</a></p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title=最終更新日> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年9月28日 19:08:34 JST">2025年9月28日 19:08:34</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> ページトップへ戻る </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 - 2025 vinsmoke-three </div> </div> <div class=md-social> <a href=https://github.com/vinsmoke-three target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": {"BERT": "bert", "CNN": "convolutional-neural-network", "FashionMNIST": "fashion-mnist", "GPT": "gpt", "LLM": "large-language-model", "ML\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3": "ml-pipeline", "NLP": "nlp", "PyTorch": "pytorch", "Python": "python", "TensorBoard": "tensorboard", "TinyVGG": "tinyvgg", "Transformer": "transformer", "\u30ab\u30b9\u30bf\u30e0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8": "custom-datasets", "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3": "computer-vision", "\u30b9\u30af\u30ea\u30d7\u30c8\u30e2\u30fc\u30c9": "script-mode", "\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb": "tutorial", "\u30c6\u30f3\u30bd\u30eb": "tensor", "\u30c7\u30fc\u30bf\u62e1\u5f35": "data-augmentation", "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af": "neural-network", "\u30e2\u30b8\u30e5\u30fc\u30eb\u5316": "modularization", "\u30ef\u30fc\u30af\u30d5\u30ed\u30fc": "workflow", "\u4e0a\u7d1a\u8005\u5411\u3051": "advanced", "\u4e2d\u7d1a\u8005\u5411\u3051": "intermediate", "\u518d\u5229\u7528": "reusability", "\u5206\u985e": "classification", "\u521d\u5fc3\u8005\u5411\u3051": "beginner", "\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb": "large-language-model", "\u5b9f\u8df5": "practical", "\u5b9f\u9a13\u8ffd\u8de1": "experiment-tracking", "\u6a5f\u68b0\u5b66\u7fd2": "machine-learning", "\u6df1\u5c64\u5b66\u7fd2": "deep-learning", "\u753b\u50cf\u5206\u985e": "image-classification", "\u7dda\u5f62\u56de\u5e30": "linear-regression", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406": "natural-language-processing", "\u8ee2\u79fb\u5b66\u7fd2": "transfer-learning"}, "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}, "version": null}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/meta.js></script> <script src=../../javascripts/structured-data.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>