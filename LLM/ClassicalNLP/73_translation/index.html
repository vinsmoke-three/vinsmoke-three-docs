<!doctype html><html lang=ja class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=Helsinki-NLPのOpus-100データセットを使用して英日翻訳モデルをファインチューニングする方法を、TrainerAPIとカスタム学習ループの両方で詳しく解説します。><meta name=author content=vinsmoke-three><link href=https://vinsmoke-three.com/LLM/ClassicalNLP/73_translation/ rel=canonical><link href=../72_masked_language_modeling/ rel=prev><link href=../74_summarization/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.20"><title>Hugging Face Transformersを使った機械翻訳モデルのファインチューニング実践ガイド - vinsmoke-three - 機械学習・深層学習ドキュメント</title><link rel=stylesheet href=../../../assets/stylesheets/main.e53b48f4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-BXKYE0NT9N"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-BXKYE0NT9N",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-BXKYE0NT9N",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> コンテンツにスキップ </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=ヘッダー> <a href=../../.. title="vinsmoke-three - 機械学習・深層学習ドキュメント" class="md-header__button md-logo" aria-label="vinsmoke-three - 機械学習・深層学習ドキュメント" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 14.27 10.64 13A11.24 11.24 0 0 0 5 10.18v6.95c2.61.34 5 1.34 7 2.82 2-1.48 4.39-2.48 7-2.82v-6.95c-2.16.39-4.09 1.39-5.64 2.82M19 8.15c.65-.1 1.32-.15 2-.15v11c-3.5 0-6.64 1.35-9 3.54C9.64 20.35 6.5 19 3 19V8c.68 0 1.35.05 2 .15 2.69.41 5.1 1.63 7 3.39 1.9-1.76 4.31-2.98 7-3.39M12 6c.27 0 .5-.1.71-.29.19-.21.29-.44.29-.71s-.1-.5-.29-.71C12.5 4.11 12.27 4 12 4s-.5.11-.71.29c-.18.21-.29.45-.29.71s.11.5.29.71c.21.19.45.29.71.29m2.12 1.12a2.997 2.997 0 1 1-4.24-4.24 2.997 2.997 0 1 1 4.24 4.24"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> vinsmoke-three - 機械学習・深層学習ドキュメント </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Hugging Face Transformersを使った機械翻訳モデルのファインチューニング実践ガイド </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=検索 placeholder=検索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=検索> <a href=javascript:void(0) class="md-search__icon md-icon" title=共有 aria-label=共有 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=クリア aria-label=クリア tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 検索を初期化 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=タブ data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../PyTorch/00_setup/ class=md-tabs__link> PyTorch </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../00_illustrated_transformer/ class=md-tabs__link> LLM </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=ナビゲーション data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="vinsmoke-three - 機械学習・深層学習ドキュメント" class="md-nav__button md-logo" aria-label="vinsmoke-three - 機械学習・深層学習ドキュメント" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 14.27 10.64 13A11.24 11.24 0 0 0 5 10.18v6.95c2.61.34 5 1.34 7 2.82 2-1.48 4.39-2.48 7-2.82v-6.95c-2.16.39-4.09 1.39-5.64 2.82M19 8.15c.65-.1 1.32-.15 2-.15v11c-3.5 0-6.64 1.35-9 3.54C9.64 20.35 6.5 19 3 19V8c.68 0 1.35.05 2 .15 2.69.41 5.1 1.63 7 3.39 1.9-1.76 4.31-2.98 7-3.39M12 6c.27 0 .5-.1.71-.29.19-.21.29-.44.29-.71s-.1-.5-.29-.71C12.5 4.11 12.27 4 12 4s-.5.11-.71.29c-.18.21-.29.45-.29.71s.11.5.29.71c.21.19.45.29.71.29m2.12 1.12a2.997 2.997 0 1 1-4.24-4.24 2.997 2.997 0 1 1 4.24 4.24"/></svg> </a> vinsmoke-three - 機械学習・深層学習ドキュメント </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> PyTorch </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> PyTorch </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../PyTorch/00_setup/ class=md-nav__link> <span class=md-ellipsis> 0. setup </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/01_pytorch_fundamentals/ class=md-nav__link> <span class=md-ellipsis> 1. PyTorch fundamentals </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/02_pytorch_workflow/ class=md-nav__link> <span class=md-ellipsis> 2. PyTorch workflow </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/03_pytorch_classification/ class=md-nav__link> <span class=md-ellipsis> 3. PyTorch classification </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/04_pytorch_computer_vision/ class=md-nav__link> <span class=md-ellipsis> 4. PyTorch computer vision </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/05_pytorch_custom_datasets/ class=md-nav__link> <span class=md-ellipsis> 5. PyTorch custom datasets </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/06_pytorch_modular/ class=md-nav__link> <span class=md-ellipsis> 6. PyTorch modular </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/07_pytorch_transfer_learning/ class=md-nav__link> <span class=md-ellipsis> 7. PyTorch transfer learning </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/08_pytorch_experiment_tracking/ class=md-nav__link> <span class=md-ellipsis> 8. PyTorch experiment tracking </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/09_pytorch_paper_replicating/ class=md-nav__link> <span class=md-ellipsis> 9. PyTorch paper replicating </span> </a> </li> <li class=md-nav__item> <a href=../../../PyTorch/10_pytorch_model_deployment/ class=md-nav__link> <span class=md-ellipsis> 10. PyTorch model deployment </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> LLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../00_illustrated_transformer/ class=md-nav__link> <span class=md-ellipsis> 0. The illustrated transformer </span> </a> </li> <li class=md-nav__item> <a href=../../01_transformer_models/ class=md-nav__link> <span class=md-ellipsis> 1. Transformer models </span> </a> </li> <li class=md-nav__item> <a href=../../02_using_transformers/ class=md-nav__link> <span class=md-ellipsis> 2. Using transformers </span> </a> </li> <li class=md-nav__item> <a href=../../03_fine_tuning_a_pretrained_model/ class=md-nav__link> <span class=md-ellipsis> 3. Fine-tuning a pretrained model </span> </a> </li> <li class=md-nav__item> <a href=../../04_the_huggingface_tokenizers_library/ class=md-nav__link> <span class=md-ellipsis> 4. Tokenizers library </span> </a> </li> <li class=md-nav__item> <a href=../../05_Let%27s_build_GPT_from_scratch/ class=md-nav__link> <span class=md-ellipsis> 5. Let't build GPT from scratch </span> </a> </li> <li class=md-nav__item> <a href=../../06_the_huggingface_datasets_library/ class=md-nav__link> <span class=md-ellipsis> 6. Datasets library </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8 checked> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> 7. Classical NLP Tasks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=true> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> 7. Classical NLP Tasks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../71_token_classification/ class=md-nav__link> <span class=md-ellipsis> Token Classification </span> </a> </li> <li class=md-nav__item> <a href=../72_masked_language_modeling/ class=md-nav__link> <span class=md-ellipsis> Masked Language Modeling </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Translation </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Translation </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目次> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目次 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 概要 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 前提知識 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> データの準備 </span> </a> </li> <li class=md-nav__item> <a href=#trainer-api class=md-nav__link> <span class=md-ellipsis> Trainer API を使用したモデルのファインチューニング </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> カスタム訓練ループ </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 参考資料 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../74_summarization/ class=md-nav__link> <span class=md-ellipsis> Summarization </span> </a> </li> <li class=md-nav__item> <a href=../75_question_answering/ class=md-nav__link> <span class=md-ellipsis> Question Answering </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目次> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目次 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 概要 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 前提知識 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> データの準備 </span> </a> </li> <li class=md-nav__item> <a href=#trainer-api class=md-nav__link> <span class=md-ellipsis> Trainer API を使用したモデルのファインチューニング </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> カスタム訓練ループ </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 参考資料 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>機械翻訳モデルのファインチューニング<a class=headerlink href=#_1 title="Permanent link">&para;</a></h1> <h2 id=_2>概要<a class=headerlink href=#_2 title="Permanent link">&para;</a></h2> <p>この記事では、<strong>sequence-to-sequence（系列対系列）</strong> タスクの一つである機械翻訳について学習します。機械翻訳は、ある言語の文章を別の言語に変換する問題で、要約問題と同様のアプローチが適用できます。</p> <p>本記事で学習する内容は、以下のような他の系列対系列問題にも応用可能です：</p> <ul> <li><strong>スタイル変換</strong>: あるスタイルで書かれたテキストを別のスタイルに変換するモデル（例：フォーマルな文章をカジュアルに、シェイクスピア英語を現代英語に）</li> <li><strong>生成的質問応答</strong>: 文脈を与えられた質問に対する回答を生成するモデル</li> </ul> <div class="admonition info"> <p class=admonition-title>参考資料</p> <p>本ドキュメントは <a href=https://huggingface.co/learn/llm-course/chapter7/4>Hugging Face LLM Course</a> を参考に、日本語で学習内容をまとめた個人的な学習ノートです。詳細な内容や最新情報については、原文も併せてご参照ください。</p> </div> <h2 id=_3>前提知識<a class=headerlink href=#_3 title="Permanent link">&para;</a></h2> <p>この記事を理解するために必要な知識：</p> <ul> <li>Python の基本的な文法</li> <li>Transformers ライブラリの基本的な使い方</li> <li>機械学習の基礎概念（学習、評価、ファインチューニング）</li> <li>PyTorch の基本的な操作</li> </ul> <h2 id=_4>データの準備<a class=headerlink href=#_4 title="Permanent link">&para;</a></h2> <p>機械翻訳モデルをファインチューニングまたはゼロから学習するには、タスクに適したデータセットが必要です。この記事では <a href=https://huggingface.co/datasets/Helsinki-NLP/opus-100>opus-100 dataset</a> を使用しますが、翻訳したい言語ペアの文章があれば、コードを簡単に適応させることができます。</p> <h3 id=opus-100>opus-100 データセット<a class=headerlink href=#opus-100 title="Permanent link">&para;</a></h3> <p>いつものように、<code>load_dataset()</code> 関数を使用してデータセットをダウンロードします。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>from</span><span class=w> </span><span class=nn>datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_dataset</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=c1># 英日翻訳用データセットを読み込み</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=n>split_datasets</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&quot;Helsinki-NLP/opus-100&quot;</span><span class=p>,</span> <span class=s2>&quot;en-ja&quot;</span><span class=p>)</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=n>split_datasets</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>DatasetDict({
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>    test: Dataset({
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>        features: [&#39;translation&#39;],
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>        num_rows: 2000
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>    })
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>    train: Dataset({
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>        features: [&#39;translation&#39;],
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>        num_rows: 1000000
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>    })
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>    validation: Dataset({
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>        features: [&#39;translation&#39;],
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>        num_rows: 2000
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>    })
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>})
</span></code></pre></div></p> <p>データセットの要素を一つ見てみましょう。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># データセットのサンプルを確認</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>split_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>][</span><span class=s2>&quot;translation&quot;</span><span class=p>]</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>{&#39;en&#39;: &quot;I&#39;m being held in a basement. I&#39;ve been abducted with two other girls.&quot;,
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a> &#39;ja&#39;: &#39;いま地下に居ます 他の2人と一緒に誘拐されたんです！&#39;}
</span></code></pre></div></p> <p>リクエストした言語ペアの2つの文章を含む辞書が得られます。</p> <p>事前訓練済みモデルを使って翻訳を試してみましょう。このモデルは、より大きなフランス語と英語の文章コーパスで事前訓練されており、簡単な翻訳を提供します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>pipeline</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=c1># 英日翻訳用の事前訓練済みモデルを読み込み</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=n>model_checkpoint</span> <span class=o>=</span> <span class=s2>&quot;Helsinki-NLP/opus-mt-en-jap&quot;</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=n>translator</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span><span class=s2>&quot;translation&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>model_checkpoint</span><span class=p>)</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=n>translator</span><span class=p>(</span><span class=s2>&quot;I&#39;m being held in a basement. I&#39;ve been abducted with two other girls.&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a>Device set to use mps:0
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>[{&#39;translation_text&#39;: &#39;あたし は 不平 を 負う 者 と な り , ほか の ふたり の 女 と 婚約 し た こと が ある が ,&#39;}]
</span></code></pre></div></p> <h3 id=_5>データの前処理<a class=headerlink href=#_5 title="Permanent link">&para;</a></h3> <p>お馴染みの手順ですが、すべてのテキストをトークンIDのセットに変換して、モデルが理解できるようにする必要があります。このタスクでは、入力とターゲットの両方をトークン化する必要があります。最初のタスクは、<code>tokenizer</code> オブジェクトを作成することです。前述のとおり、Marian英日事前訓練済みモデルを使用します。別の言語ペアでこのコードを試す場合は、モデルチェックポイントを適応させてください。<a href=https://huggingface.co/Helsinki-NLP>Helsinki-NLP</a> 組織では、複数言語で1000以上のモデルを提供しています。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>AutoTokenizer</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># 英日翻訳モデルのTokenizerを初期化</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>model_checkpoint</span> <span class=o>=</span> <span class=s2>&quot;Helsinki-NLP/opus-mt-en-jap&quot;</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_checkpoint</span><span class=p>,</span> <span class=n>return_tensors</span> <span class=o>=</span> <span class=s2>&quot;pt&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>データの準備は非常に簡単です。覚えておくべきことが一つあります：tokenizerが出力言語（ここでは日本語）でターゲットを処理することを確実にする必要があります。これは、tokenizerの <code>__call__</code> メソッドの <code>text_targets</code> 引数にターゲットを渡すことで行えます。</p> <p>この仕組みを確認するために、訓練セットから各言語のサンプルを1つずつ処理してみましょう。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># 英語と日本語の文章を取得</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=n>en_sentence</span> <span class=o>=</span> <span class=n>split_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>][</span><span class=s2>&quot;translation&quot;</span><span class=p>][</span><span class=s2>&quot;en&quot;</span><span class=p>]</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=n>ja_sentence</span> <span class=o>=</span> <span class=n>split_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>][</span><span class=s2>&quot;translation&quot;</span><span class=p>][</span><span class=s2>&quot;ja&quot;</span><span class=p>]</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=c1># 入力文章とターゲット文章をトークン化</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>en_sentence</span><span class=p>,</span> <span class=n>text_target</span><span class=o>=</span><span class=n>ja_sentence</span><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=n>inputs</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a>{&#39;input_ids&#39;: [31, 62, 2315, 616, 2513, 20, 33, 3761, 6359, 4, 31, 62, 9099, 428, 1, 44823, 203, 48, 253, 422, 24303, 4, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], &#39;labels&#39;: [2249, 18925, 115, 14755, 652, 6, 2338, 1, 570, 2666, 4550, 1, 1382, 1845, 572, 315, 0]}
</span></code></pre></div></p> <p>ご覧のとおり、出力には英語の文章に関連付けられた入力IDが含まれ、日本語に関連付けられたIDは <code>labels</code> フィールドに格納されます。ラベルをトークン化していることを示すのを忘れると、入力tokenizerによってトークン化されることになり、Marianモデルの場合はうまくいきません：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># 間違った方法：日本語文章を英語tokenizerで処理</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>wrong_targets</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>ja_sentence</span><span class=p>)</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>convert_ids_to_tokens</span><span class=p>(</span><span class=n>wrong_targets</span><span class=p>[</span><span class=s2>&quot;input_ids&quot;</span><span class=p>]))</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>convert_ids_to_tokens</span><span class=p>(</span><span class=n>inputs</span><span class=p>[</span><span class=s2>&quot;labels&quot;</span><span class=p>]))</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a>[&#39;▁&#39;, &#39;&lt;unk&gt;&#39;, &#39;▁&#39;, &#39;ä»–ã®&#39;, &#39;&lt;unk&gt;&#39;, &#39;&lt;unk&gt;&#39;, &#39;!&#39;, &#39;&lt;/s&gt;&#39;]
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>[&#39;▁いま&#39;, &#39;地下&#39;, &#39;に&#39;, &#39;居&#39;, &#39;ます&#39;, &#39;▁&#39;, &#39;ä»–ã®&#39;, &#39;&lt;unk&gt;&#39;, &#39;人&#39;, &#39;と一緒に&#39;, &#39;誘&#39;, &#39;&lt;unk&gt;&#39;, &#39;された&#39;, &#39;んで&#39;, &#39;す&#39;, &#39;!&#39;, &#39;&lt;/s&gt;&#39;]
</span></code></pre></div></p> <p>ご覧のとおり、英語tokenizerを使ってフランス語（日本語）の文章を前処理すると、tokenizerが日本語の単語を知らないため（英語にも現れる単語を除いて、例えば「discussion」など）、はるかに多くのトークンが生成されます。</p> <p><code>inputs</code> は通常のキー（入力ID、attention mask など）を持つ辞書なので、最後のステップは、データセットに適用する前処理関数を定義することです：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># 最大長を設定</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=n>max_length</span> <span class=o>=</span> <span class=mi>128</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=k>def</span><span class=w> </span><span class=nf>preprocess_function</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=c1># 英語と日本語の文章を分離</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=n>inputs</span> <span class=o>=</span> <span class=p>[</span><span class=n>ex</span><span class=p>[</span><span class=s2>&quot;en&quot;</span><span class=p>]</span> <span class=k>for</span> <span class=n>ex</span> <span class=ow>in</span> <span class=n>examples</span><span class=p>[</span><span class=s2>&quot;translation&quot;</span><span class=p>]]</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>    <span class=n>targets</span> <span class=o>=</span> <span class=p>[</span><span class=n>ex</span><span class=p>[</span><span class=s2>&quot;ja&quot;</span><span class=p>]</span> <span class=k>for</span> <span class=n>ex</span> <span class=ow>in</span> <span class=n>examples</span><span class=p>[</span><span class=s2>&quot;translation&quot;</span><span class=p>]]</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=c1># 入力とターゲットを同時にトークン化</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>    <span class=n>model_inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a>        <span class=n>inputs</span><span class=p>,</span> <span class=n>text_target</span><span class=o>=</span><span class=n>targets</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=n>max_length</span><span class=p>,</span> <span class=n>truncation</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a>    <span class=p>)</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a>    <span class=k>return</span> <span class=n>model_inputs</span>
</span></code></pre></div> <p>入力と出力に同じ最大長を設定していることに注意してください。扱っているテキストは非常に短いようなので、128を使用します。</p> <p><strong>💡 注意点:</strong></p> <p>ターゲットのattention maskには注意を払いません。代わりに、パディングトークンに対応するラベルは、損失計算で無視されるように <code>-100</code> に設定する必要があります。これは、動的パディングを適用しているため、後でデータコレクターによって行われますが、ここでパディングを使用する場合は、パディングトークンに対応するすべてのラベルを <code>-100</code> に設定するように前処理関数を適応させる必要があります。</p> <p>データセットのすべての分割で前処理を一度に適用できます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># データセット全体に前処理を適用</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=n>tokenized_datasets</span> <span class=o>=</span> <span class=n>split_datasets</span><span class=o>.</span><span class=n>map</span><span class=p>(</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=n>preprocess_function</span><span class=p>,</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=n>batched</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=n>remove_columns</span><span class=o>=</span><span class=n>split_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>column_names</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=p>)</span>
</span></code></pre></div> <p>データが前処理されたので、事前訓練済みモデルをファインチューニングする準備が整いました。</p> <h2 id=trainer-api>Trainer API を使用したモデルのファインチューニング<a class=headerlink href=#trainer-api title="Permanent link">&para;</a></h2> <p><code>Trainer</code> を使用した実際のコードは以前と同じで、小さな変更が一つだけあります：ここでは <a href=https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainer><code>Seq2SeqTrainer</code></a> を使用します。これは <code>Trainer</code> のサブクラスで、<code>generate()</code> メソッドを使用して入力から出力を予測することで、評価を適切に処理できます。メトリック計算について話すときに、これについてより詳細に説明します。</p> <p>まず第一に、ファインチューニングする実際のモデルが必要です。通常の <code>AutoModel</code> API を使用します：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>AutoModelForSeq2SeqLM</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=c1># Sequence-to-Sequence 学習用モデルを読み込み</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForSeq2SeqLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_checkpoint</span><span class=p>)</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=c1># デバイスの設定（MPS, GPU, CPUの順で利用可能なものを使用）</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;mps&quot;</span><span class=p>)</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;cpu&quot;</span><span class=p>)</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></code></pre></div> <h3 id=_6>データコレクション<a class=headerlink href=#_6 title="Permanent link">&para;</a></h3> <p>動的バッチ処理のパディングを処理するために、データコレクターが必要です。<code>DataCollatorWithPadding</code> だけは使用できません。これは入力（入力ID、attention mask、トークンタイプID）のみをパッドするからです。ラベルも、ラベル内で遭遇した最大長にパッドされる必要があります。そして、前述のとおり、ラベルをパッドするために使用されるパディング値は、損失計算でパッドされた値が無視されるように、tokenizerのパディングトークンではなく <code>-100</code> である必要があります。</p> <p>これはすべて <a href=https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq><code>DataCollatorForSeq2Seq</code></a> によって行われます。<code>DataCollatorWithPadding</code> と同様に、入力を前処理するために使用される <code>tokenizer</code> を取りますが、<code>model</code> も取ります。このデータコレクターは、特別なトークンを先頭に持つラベルのシフトバージョンであるデコーダー入力IDの準備も担当するからです。このシフトは異なるアーキテクチャで若干異なって行われるため、<code>DataCollatorForSeq2Seq</code> は <code>model</code> オブジェクトを知る必要があります：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>DataCollatorForSeq2Seq</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=c1># Seq2Seq用のデータコレクターを初期化</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=n>data_collator</span> <span class=o>=</span> <span class=n>DataCollatorForSeq2Seq</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>)</span>
</span></code></pre></div> <p>いくつかのサンプルでテストするために、トークン化された訓練セットのサンプルリストで呼び出します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># データコレクターのテスト実行</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=n>batch</span> <span class=o>=</span> <span class=n>data_collator</span><span class=p>([</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>][</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>)])</span>
</span></code></pre></div> <p>ラベルがバッチの最大長にパッドされ、<code>-100</code> が使用されていることを確認できます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># パディングされたラベルを確認</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;labels&quot;</span><span class=p>]</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>tensor([[ 2249, 18925,   115, 14755,   652,     6,  2338,     1,   570,  2666,
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>          4550,     1,  1382,  1845,   572,   315,     0],
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>        [    6,  1695,   621,   261,   315,     0,  -100,  -100,  -100,  -100,
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>          -100,  -100,  -100,  -100,  -100,  -100,  -100]])
</span></code></pre></div></p> <p>また、デコーダー入力IDを見ることもできます。これらがラベルのシフトされたバージョンであることがわかります。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=c1># デコーダー入力IDを確認</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;decoder_input_ids&quot;</span><span class=p>]</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>tensor([[46275,  2249, 18925,   115, 14755,   652,     6,  2338,     1,   570,
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>          2666,  4550,     1,  1382,  1845,   572,   315],
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>        [46275,     6,  1695,   621,   261,   315,     0, 46275, 46275, 46275,
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a>         46275, 46275, 46275, 46275, 46275, 46275, 46275]])
</span></code></pre></div></p> <p>データセットの最初と2番目の要素のラベルは次のとおりです。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=c1># 元のラベルを確認</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>):</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a>    <span class=nb>print</span><span class=p>(</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>][</span><span class=n>i</span><span class=p>][</span><span class=s2>&quot;labels&quot;</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>[2249, 18925, 115, 14755, 652, 6, 2338, 1, 570, 2666, 4550, 1, 1382, 1845, 572, 315, 0]
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>[6, 1695, 621, 261, 315, 0]
</span></code></pre></div></p> <p>この <code>data_collator</code> を <code>Seq2SeqTrainer</code> に渡します。次に、メトリックを見てみましょう。</p> <h3 id=_7>評価メトリック<a class=headerlink href=#_7 title="Permanent link">&para;</a></h3> <p><code>Seq2SeqTrainer</code> がスーパークラス <code>Trainer</code> に追加する機能は、評価や予測中に <code>generate()</code> メソッドを使用する能力です。訓練中、モデルは予測しようとしているトークンの後のトークンを使用しないようにするattention maskを持つ <code>decoder_input_ids</code> を使用して、訓練を高速化します。推論中はラベルがないため、これらを使用することはできないので、同じセットアップでモデルを評価することは良いアイデアです。</p> <p>デコーダーは、一度に一つずつトークンを予測することで推論を実行します。これは、Hugging Face Transformersの <code>generate()</code> メソッドによって舞台裏で実装されています。<code>Seq2SeqTrainer</code> では、<code>predict_with_generate=True</code> を設定すると、評価にそのメソッドを使用できます。</p> <p>翻訳に使用される伝統的なメトリックは、Kishore Papineni らによる <a href=https://aclanthology.org/P02-1040.pdf>2002年の論文</a> で紹介された <a href=https://en.wikipedia.org/wiki/BLEU>BLEU スコア</a> です。BLEUスコアは、翻訳がラベルにどれだけ近いかを評価します。モデルが生成した出力の理解可能性や文法的正確性を測定するのではなく、統計的ルールを使用して、生成された出力内のすべての単語がターゲット内にも現れることを確認します。さらに、ターゲットでも繰り返されていない場合に同じ単語の繰り返しを罰するルール（モデルが <code>"the the the the the"</code> のような文章を出力することを避けるため）と、ターゲット内のものより短い出力文章を罰するルール（モデルが <code>"the"</code> のような文章を出力することを避けるため）があります。</p> <p>BLEUの弱点の一つは、テキストが既にトークン化されていることを期待することで、異なるtokenizerを使用するモデル間でスコアを比較することが困難になります。そのため、今日の翻訳モデルのベンチマークに最もよく使用されるメトリックは <a href=https://github.com/mjpost/sacrebleu>SacreBLEU</a> です。これはトークン化ステップを標準化することで、この弱点（および他の弱点）を対処します。このメトリックを使用するには、まずSacreBLEUライブラリをインストールする必要があります：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=c1># !pip install sacrebleu</span>
</span></code></pre></div> <p>その後、<code>evaluate.load()</code> を介して読み込むことができます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=kn>import</span><span class=w> </span><span class=nn>evaluate</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a><span class=c1># SacreBLEUメトリックを読み込み</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a><span class=n>metric</span> <span class=o>=</span> <span class=n>evaluate</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;sacrebleu&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>このメトリックは、入力とターゲットとしてテキストを受け取ります。複数の受け入れ可能なターゲットを受け入れるように設計されています。同じ文章に対して複数の受け入れ可能な翻訳があることが多いからです。使用しているデータセットは1つしか提供していませんが、NLPでラベルとして複数の文章を提供するデータセットを見つけることは珍しくありません。したがって、予測は文章のリストである必要がありますが、参照は文章のリストのリストである必要があります。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=c1># BLEUスコアの計算例</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a><span class=n>predictions</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a>    <span class=s2>&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a><span class=p>]</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a><span class=n>references</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a>    <span class=p>[</span>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a>        <span class=s2>&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8 href=#__codelineno-24-8></a>    <span class=p>]</span>
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9 href=#__codelineno-24-9></a><span class=p>]</span>
</span><span id=__span-24-10><a id=__codelineno-24-10 name=__codelineno-24-10 href=#__codelineno-24-10></a><span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>predictions</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>references</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a>{&#39;score&#39;: 46.750469682990186,
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a> &#39;counts&#39;: [11, 6, 4, 3],
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a> &#39;totals&#39;: [12, 11, 10, 9],
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a> &#39;precisions&#39;: [91.66666666666667,
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a>  54.54545454545455,
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>  40.0,
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>  33.333333333333336],
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a> &#39;bp&#39;: 0.9200444146293233,
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a> &#39;sys_len&#39;: 12,
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a> &#39;ref_len&#39;: 13}
</span></code></pre></div></p> <p>これは46.75のBLEUスコアを取得します。これは非常に良いスコアです。参考として、<a href=https://arxiv.org/pdf/1706.03762.pdf>"Attention Is All You Need" 論文</a> の元のTransformerモデルは、英語とフランス語間の同様の翻訳タスクで41.8のBLEUスコアを達成しました！（<code>counts</code> や <code>bp</code> などの個別のメトリックの詳細については、<a href=https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74>SacreBLEU リポジトリ</a> を参照してください。）</p> <p>一方、翻訳モデルからよく出てくる2つの悪いタイプの予測（大量の繰り返しや短すぎるもの）を試すと、かなり悪いBLEUスコアが得られます：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=c1># 悪い予測例1：繰り返しが多い場合</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a><span class=n>predictions</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;This This This This&quot;</span><span class=p>]</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a><span class=n>references</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a>    <span class=p>[</span>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a>        <span class=s2>&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a>    <span class=p>]</span>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a><span class=p>]</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a><span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>predictions</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>references</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a>{&#39;score&#39;: 1.683602693167689,
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a> &#39;counts&#39;: [1, 0, 0, 0],
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a> &#39;totals&#39;: [4, 3, 2, 1],
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a> &#39;precisions&#39;: [25.0, 16.666666666666668, 12.5, 12.5],
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a> &#39;bp&#39;: 0.10539922456186433,
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a> &#39;sys_len&#39;: 4,
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a> &#39;ref_len&#39;: 13}
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=c1># 悪い予測例2：短すぎる場合</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a><span class=n>predictions</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;This plugin&quot;</span><span class=p>]</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a><span class=n>references</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a>    <span class=p>[</span>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a>        <span class=s2>&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a>    <span class=p>]</span>
</span><span id=__span-28-7><a id=__codelineno-28-7 name=__codelineno-28-7 href=#__codelineno-28-7></a><span class=p>]</span>
</span><span id=__span-28-8><a id=__codelineno-28-8 name=__codelineno-28-8 href=#__codelineno-28-8></a><span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>predictions</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>references</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a>{&#39;score&#39;: 0.0,
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a> &#39;counts&#39;: [2, 1, 0, 0],
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a> &#39;totals&#39;: [2, 1, 0, 0],
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a> &#39;precisions&#39;: [100.0, 100.0, 0.0, 0.0],
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a> &#39;bp&#39;: 0.004086771438464067,
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6 href=#__codelineno-29-6></a> &#39;sys_len&#39;: 2,
</span><span id=__span-29-7><a id=__codelineno-29-7 name=__codelineno-29-7 href=#__codelineno-29-7></a> &#39;ref_len&#39;: 13}
</span></code></pre></div></p> <p>スコアは0から100の範囲で、高いほど良いです。</p> <p>モデルの出力からメトリックが使用できるテキストに変換するには、<code>tokenizer.batch_decode()</code> メソッドを使用します。ラベル内のすべての <code>-100</code> をクリーンアップする必要があります（tokenizerはパディングトークンに対して自動的に同じことを行います）。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a><span class=k>def</span><span class=w> </span><span class=nf>compute_metrics</span><span class=p>(</span><span class=n>eval_preds</span><span class=p>):</span>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a>    <span class=n>preds</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>eval_preds</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a>    <span class=c1># モデルが予測logit以上を返す場合</span>
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6 href=#__codelineno-30-6></a>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>preds</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span><span id=__span-30-7><a id=__codelineno-30-7 name=__codelineno-30-7 href=#__codelineno-30-7></a>        <span class=n>preds</span> <span class=o>=</span> <span class=n>preds</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-30-8><a id=__codelineno-30-8 name=__codelineno-30-8 href=#__codelineno-30-8></a>
</span><span id=__span-30-9><a id=__codelineno-30-9 name=__codelineno-30-9 href=#__codelineno-30-9></a>    <span class=c1># 予測をデコードしてテキストに変換</span>
</span><span id=__span-30-10><a id=__codelineno-30-10 name=__codelineno-30-10 href=#__codelineno-30-10></a>    <span class=n>decoded_preds</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>preds</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-30-11><a id=__codelineno-30-11 name=__codelineno-30-11 href=#__codelineno-30-11></a>
</span><span id=__span-30-12><a id=__codelineno-30-12 name=__codelineno-30-12 href=#__codelineno-30-12></a>    <span class=c1># ラベルの-100をパディングトークンIDに置き換えてデコード</span>
</span><span id=__span-30-13><a id=__codelineno-30-13 name=__codelineno-30-13 href=#__codelineno-30-13></a>    <span class=n>labels</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>labels</span> <span class=o>!=</span> <span class=o>-</span><span class=mi>100</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>)</span>
</span><span id=__span-30-14><a id=__codelineno-30-14 name=__codelineno-30-14 href=#__codelineno-30-14></a>    <span class=n>decoded_labels</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-30-15><a id=__codelineno-30-15 name=__codelineno-30-15 href=#__codelineno-30-15></a>
</span><span id=__span-30-16><a id=__codelineno-30-16 name=__codelineno-30-16 href=#__codelineno-30-16></a>    <span class=c1># 簡単な後処理：空白の削除</span>
</span><span id=__span-30-17><a id=__codelineno-30-17 name=__codelineno-30-17 href=#__codelineno-30-17></a>    <span class=n>decoded_preds</span> <span class=o>=</span> <span class=p>[</span><span class=n>pred</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=k>for</span> <span class=n>pred</span> <span class=ow>in</span> <span class=n>decoded_preds</span><span class=p>]</span>
</span><span id=__span-30-18><a id=__codelineno-30-18 name=__codelineno-30-18 href=#__codelineno-30-18></a>    <span class=n>decoded_labels</span> <span class=o>=</span> <span class=p>[[</span><span class=n>label</span><span class=o>.</span><span class=n>strip</span><span class=p>()]</span> <span class=k>for</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>decoded_labels</span><span class=p>]</span>
</span><span id=__span-30-19><a id=__codelineno-30-19 name=__codelineno-30-19 href=#__codelineno-30-19></a>
</span><span id=__span-30-20><a id=__codelineno-30-20 name=__codelineno-30-20 href=#__codelineno-30-20></a>    <span class=c1># BLEUスコアを計算</span>
</span><span id=__span-30-21><a id=__codelineno-30-21 name=__codelineno-30-21 href=#__codelineno-30-21></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>decoded_preds</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>decoded_labels</span><span class=p>)</span>
</span><span id=__span-30-22><a id=__codelineno-30-22 name=__codelineno-30-22 href=#__codelineno-30-22></a>    <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;bleu&quot;</span><span class=p>:</span> <span class=n>result</span><span class=p>[</span><span class=s2>&quot;score&quot;</span><span class=p>]}</span>
</span></code></pre></div> <h3 id=_8>モデルのファインチューニング<a class=headerlink href=#_8 title="Permanent link">&para;</a></h3> <p><code>Seq2SeqTrainingArguments</code> を定義できます。<code>Trainer</code> と同様に、いくつかのフィールドが追加された <code>TrainingArguments</code> のサブクラスを使用します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>Seq2SeqTrainingArguments</span>
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2 href=#__codelineno-31-2></a>
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3 href=#__codelineno-31-3></a><span class=c1># 訓練パラメータの設定</span>
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4 href=#__codelineno-31-4></a><span class=n>args</span> <span class=o>=</span> <span class=n>Seq2SeqTrainingArguments</span><span class=p>(</span>
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5 href=#__codelineno-31-5></a>    <span class=sa>f</span><span class=s2>&quot;marian-finetuned-opus-100-en-to-ja&quot;</span><span class=p>,</span>  <span class=c1># 出力ディレクトリ</span>
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6 href=#__codelineno-31-6></a>    <span class=n>eval_strategy</span><span class=o>=</span><span class=s2>&quot;no&quot;</span><span class=p>,</span>  <span class=c1># 評価戦略</span>
</span><span id=__span-31-7><a id=__codelineno-31-7 name=__codelineno-31-7 href=#__codelineno-31-7></a>    <span class=n>save_strategy</span><span class=o>=</span><span class=s2>&quot;epoch&quot;</span><span class=p>,</span>  <span class=c1># 保存戦略</span>
</span><span id=__span-31-8><a id=__codelineno-31-8 name=__codelineno-31-8 href=#__codelineno-31-8></a>    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>2e-5</span><span class=p>,</span>  <span class=c1># 学習率</span>
</span><span id=__span-31-9><a id=__codelineno-31-9 name=__codelineno-31-9 href=#__codelineno-31-9></a>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>  <span class=c1># 訓練時のバッチサイズ</span>
</span><span id=__span-31-10><a id=__codelineno-31-10 name=__codelineno-31-10 href=#__codelineno-31-10></a>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>   <span class=c1># 評価時のバッチサイズ</span>
</span><span id=__span-31-11><a id=__codelineno-31-11 name=__codelineno-31-11 href=#__codelineno-31-11></a>    <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>  <span class=c1># 重み減衰</span>
</span><span id=__span-31-12><a id=__codelineno-31-12 name=__codelineno-31-12 href=#__codelineno-31-12></a>    <span class=n>save_total_limit</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>  <span class=c1># 保存するチェックポイントの最大数</span>
</span><span id=__span-31-13><a id=__codelineno-31-13 name=__codelineno-31-13 href=#__codelineno-31-13></a>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>  <span class=c1># エポック数</span>
</span><span id=__span-31-14><a id=__codelineno-31-14 name=__codelineno-31-14 href=#__codelineno-31-14></a>    <span class=n>predict_with_generate</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=c1># 評価時にgenerate()メソッドを使用</span>
</span><span id=__span-31-15><a id=__codelineno-31-15 name=__codelineno-31-15 href=#__codelineno-31-15></a>    <span class=n>push_to_hub</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>  <span class=c1># Hubにアップロードしない</span>
</span><span id=__span-31-16><a id=__codelineno-31-16 name=__codelineno-31-16 href=#__codelineno-31-16></a><span class=p>)</span>
</span></code></pre></div> <p>前のセクションで見たものと比較して、通常のハイパーパラメータ（学習率、エポック数、バッチサイズ、重み減衰など）に加えて、いくつかの変更があります：</p> <ul> <li>評価には時間がかかるため、定期的な評価は設定しません。訓練前と訓練後に一度だけモデルを評価します</li> <li>上記で説明したように、<code>predict_with_generate=True</code> を設定します</li> </ul> <p>最後に、すべてを <code>Seq2SeqTrainer</code> に渡します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>Seq2SeqTrainer</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a><span class=c1># Seq2SeqTrainerの初期化</span>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a><span class=n>trainer</span> <span class=o>=</span> <span class=n>Seq2SeqTrainer</span><span class=p>(</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a>    <span class=n>model</span><span class=p>,</span>
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6 href=#__codelineno-32-6></a>    <span class=n>args</span><span class=p>,</span>
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7 href=#__codelineno-32-7></a>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>],</span>
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8 href=#__codelineno-32-8></a>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;validation&quot;</span><span class=p>],</span>
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9 href=#__codelineno-32-9></a>    <span class=n>data_collator</span><span class=o>=</span><span class=n>data_collator</span><span class=p>,</span>
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10 href=#__codelineno-32-10></a>    <span class=n>processing_class</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span><span id=__span-32-11><a id=__codelineno-32-11 name=__codelineno-32-11 href=#__codelineno-32-11></a>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span><span class=p>,</span>
</span><span id=__span-32-12><a id=__codelineno-32-12 name=__codelineno-32-12 href=#__codelineno-32-12></a><span class=p>)</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a><span class=c1># 実際の訓練実行（コメントアウト）</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2 href=#__codelineno-33-2></a><span class=c1># trainer.train()</span>
</span></code></pre></div> <h2 id=_9>カスタム訓練ループ<a class=headerlink href=#_9 title="Permanent link">&para;</a></h2> <h3 id=_10>訓練の準備<a class=headerlink href=#_10 title="Permanent link">&para;</a></h3> <p>これまでに何度か見てきたので、コードを素早く進めます。まず、データセットを <code>"torch"</code> 形式に設定してPyTorchテンソルを取得した後、データセットから <code>DataLoader</code> を構築します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>DataLoader</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a><span class=c1># データセットをPyTorch形式に設定</span>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a><span class=n>tokenized_datasets</span><span class=o>.</span><span class=n>set_format</span><span class=p>(</span><span class=s2>&quot;torch&quot;</span><span class=p>)</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a><span class=c1># 訓練用データローダーの作成</span>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a><span class=n>train_dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a>    <span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>],</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=c1># データをシャッフル</span>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10 href=#__codelineno-34-10></a>    <span class=n>collate_fn</span><span class=o>=</span><span class=n>data_collator</span><span class=p>,</span>
</span><span id=__span-34-11><a id=__codelineno-34-11 name=__codelineno-34-11 href=#__codelineno-34-11></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-34-12><a id=__codelineno-34-12 name=__codelineno-34-12 href=#__codelineno-34-12></a><span class=p>)</span>
</span><span id=__span-34-13><a id=__codelineno-34-13 name=__codelineno-34-13 href=#__codelineno-34-13></a>
</span><span id=__span-34-14><a id=__codelineno-34-14 name=__codelineno-34-14 href=#__codelineno-34-14></a><span class=c1># 評価用データローダーの作成</span>
</span><span id=__span-34-15><a id=__codelineno-34-15 name=__codelineno-34-15 href=#__codelineno-34-15></a><span class=n>eval_dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span><span id=__span-34-16><a id=__codelineno-34-16 name=__codelineno-34-16 href=#__codelineno-34-16></a>    <span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;validation&quot;</span><span class=p>],</span> 
</span><span id=__span-34-17><a id=__codelineno-34-17 name=__codelineno-34-17 href=#__codelineno-34-17></a>    <span class=n>collate_fn</span><span class=o>=</span><span class=n>data_collator</span><span class=p>,</span> 
</span><span id=__span-34-18><a id=__codelineno-34-18 name=__codelineno-34-18 href=#__codelineno-34-18></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>8</span>
</span><span id=__span-34-19><a id=__codelineno-34-19 name=__codelineno-34-19 href=#__codelineno-34-19></a><span class=p>)</span>
</span></code></pre></div> <p>次に、以前のファインチューニングから続行するのではなく、事前訓練済みモデルから再開することを確認するために、モデルを再インスタンス化します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a><span class=c1># モデルを再度読み込み（前回の訓練状態をリセット）</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2 href=#__codelineno-35-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForSeq2SeqLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_checkpoint</span><span class=p>)</span>
</span></code></pre></div> <p>次に、オプティマイザーが必要です。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.optim</span><span class=w> </span><span class=kn>import</span> <span class=n>AdamW</span>
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a>
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a><span class=c1># Adam optimizerの初期化</span>
</span><span id=__span-36-4><a id=__codelineno-36-4 name=__codelineno-36-4 href=#__codelineno-36-4></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>2e-5</span><span class=p>)</span>
</span></code></pre></div> <p>これらのオブジェクトがすべて揃ったら、<code>accelerator.prepare()</code> メソッドに送信できます。ColabノートブックでTPUで訓練したい場合は、このコードをすべて訓練関数に移動する必要があり、<code>Accelerator</code> をインスタンス化するセルは実行すべきではないことを忘れないでください。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a><span class=kn>from</span><span class=w> </span><span class=nn>accelerate</span><span class=w> </span><span class=kn>import</span> <span class=n>Accelerator</span>
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2 href=#__codelineno-37-2></a>
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3 href=#__codelineno-37-3></a><span class=c1># 分散訓練のためのAcceleratorを初期化</span>
</span><span id=__span-37-4><a id=__codelineno-37-4 name=__codelineno-37-4 href=#__codelineno-37-4></a><span class=n>accelerator</span> <span class=o>=</span> <span class=n>Accelerator</span><span class=p>()</span>
</span><span id=__span-37-5><a id=__codelineno-37-5 name=__codelineno-37-5 href=#__codelineno-37-5></a><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>train_dataloader</span><span class=p>,</span> <span class=n>eval_dataloader</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>prepare</span><span class=p>(</span>
</span><span id=__span-37-6><a id=__codelineno-37-6 name=__codelineno-37-6 href=#__codelineno-37-6></a>    <span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>train_dataloader</span><span class=p>,</span> <span class=n>eval_dataloader</span>
</span><span id=__span-37-7><a id=__codelineno-37-7 name=__codelineno-37-7 href=#__codelineno-37-7></a><span class=p>)</span>
</span></code></pre></div> <p><code>train_dataloader</code> を <code>accelerator.prepare()</code> に送信したので、その長さを使用して訓練ステップ数を計算できます。データローダーを準備した後は、その方法が <code>DataLoader</code> の長さを変更するため、常にこれを行う必要があることを忘れないでください。学習率から0への古典的な線形スケジュールを使用します：</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>get_scheduler</span>
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a>
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a><span class=c1># 訓練ステップ数の計算</span>
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a><span class=n>num_train_epochs</span> <span class=o>=</span> <span class=mi>3</span>
</span><span id=__span-38-5><a id=__codelineno-38-5 name=__codelineno-38-5 href=#__codelineno-38-5></a><span class=n>num_update_steps_per_epoch</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_dataloader</span><span class=p>)</span>
</span><span id=__span-38-6><a id=__codelineno-38-6 name=__codelineno-38-6 href=#__codelineno-38-6></a><span class=n>num_training_steps</span> <span class=o>=</span> <span class=n>num_train_epochs</span> <span class=o>*</span> <span class=n>num_update_steps_per_epoch</span>
</span><span id=__span-38-7><a id=__codelineno-38-7 name=__codelineno-38-7 href=#__codelineno-38-7></a>
</span><span id=__span-38-8><a id=__codelineno-38-8 name=__codelineno-38-8 href=#__codelineno-38-8></a><span class=c1># 学習率スケジューラーの設定</span>
</span><span id=__span-38-9><a id=__codelineno-38-9 name=__codelineno-38-9 href=#__codelineno-38-9></a><span class=n>lr_scheduler</span> <span class=o>=</span> <span class=n>get_scheduler</span><span class=p>(</span>
</span><span id=__span-38-10><a id=__codelineno-38-10 name=__codelineno-38-10 href=#__codelineno-38-10></a>    <span class=s2>&quot;linear&quot;</span><span class=p>,</span>  <span class=c1># 線形減衰</span>
</span><span id=__span-38-11><a id=__codelineno-38-11 name=__codelineno-38-11 href=#__codelineno-38-11></a>    <span class=n>optimizer</span><span class=o>=</span><span class=n>optimizer</span><span class=p>,</span>
</span><span id=__span-38-12><a id=__codelineno-38-12 name=__codelineno-38-12 href=#__codelineno-38-12></a>    <span class=n>num_warmup_steps</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>  <span class=c1># ウォームアップなし</span>
</span><span id=__span-38-13><a id=__codelineno-38-13 name=__codelineno-38-13 href=#__codelineno-38-13></a>    <span class=n>num_training_steps</span><span class=o>=</span><span class=n>num_training_steps</span><span class=p>,</span>
</span><span id=__span-38-14><a id=__codelineno-38-14 name=__codelineno-38-14 href=#__codelineno-38-14></a><span class=p>)</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1 href=#__codelineno-39-1></a><span class=c1># 出力ディレクトリの設定</span>
</span><span id=__span-39-2><a id=__codelineno-39-2 name=__codelineno-39-2 href=#__codelineno-39-2></a><span class=n>output_dir</span> <span class=o>=</span> <span class=s2>&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
</span></code></pre></div> <h3 id=_11>訓練ループ<a class=headerlink href=#_11 title="Permanent link">&para;</a></h3> <p>完全な訓練ループを書く準備が整いました。評価部分を簡素化するために、予測とラベルを受け取り、<code>metric</code> オブジェクトが期待する文字列のリストに変換する <code>postprocess()</code> 関数を定義します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-40-1><a id=__codelineno-40-1 name=__codelineno-40-1 href=#__codelineno-40-1></a><span class=k>def</span><span class=w> </span><span class=nf>postprocess</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>labels</span><span class=p>):</span>
</span><span id=__span-40-2><a id=__codelineno-40-2 name=__codelineno-40-2 href=#__codelineno-40-2></a>    <span class=c1># CPUにデータを移動してnumpy配列に変換</span>
</span><span id=__span-40-3><a id=__codelineno-40-3 name=__codelineno-40-3 href=#__codelineno-40-3></a>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>predictions</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span><span id=__span-40-4><a id=__codelineno-40-4 name=__codelineno-40-4 href=#__codelineno-40-4></a>    <span class=n>labels</span> <span class=o>=</span> <span class=n>labels</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span><span id=__span-40-5><a id=__codelineno-40-5 name=__codelineno-40-5 href=#__codelineno-40-5></a>
</span><span id=__span-40-6><a id=__codelineno-40-6 name=__codelineno-40-6 href=#__codelineno-40-6></a>    <span class=c1># 予測をテキストにデコード</span>
</span><span id=__span-40-7><a id=__codelineno-40-7 name=__codelineno-40-7 href=#__codelineno-40-7></a>    <span class=n>decoded_preds</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-40-8><a id=__codelineno-40-8 name=__codelineno-40-8 href=#__codelineno-40-8></a>
</span><span id=__span-40-9><a id=__codelineno-40-9 name=__codelineno-40-9 href=#__codelineno-40-9></a>    <span class=c1># ラベルの-100をパディングトークンIDに置き換えてデコード</span>
</span><span id=__span-40-10><a id=__codelineno-40-10 name=__codelineno-40-10 href=#__codelineno-40-10></a>    <span class=n>labels</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>labels</span> <span class=o>!=</span> <span class=o>-</span><span class=mi>100</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>)</span>
</span><span id=__span-40-11><a id=__codelineno-40-11 name=__codelineno-40-11 href=#__codelineno-40-11></a>    <span class=n>decoded_labels</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-40-12><a id=__codelineno-40-12 name=__codelineno-40-12 href=#__codelineno-40-12></a>
</span><span id=__span-40-13><a id=__codelineno-40-13 name=__codelineno-40-13 href=#__codelineno-40-13></a>    <span class=c1># 簡単な後処理：空白の削除とリスト形式への変換</span>
</span><span id=__span-40-14><a id=__codelineno-40-14 name=__codelineno-40-14 href=#__codelineno-40-14></a>    <span class=n>decoded_preds</span> <span class=o>=</span> <span class=p>[</span><span class=n>pred</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=k>for</span> <span class=n>pred</span> <span class=ow>in</span> <span class=n>decoded_preds</span><span class=p>]</span>
</span><span id=__span-40-15><a id=__codelineno-40-15 name=__codelineno-40-15 href=#__codelineno-40-15></a>    <span class=n>decoded_labels</span> <span class=o>=</span> <span class=p>[[</span><span class=n>label</span><span class=o>.</span><span class=n>strip</span><span class=p>()]</span> <span class=k>for</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>decoded_labels</span><span class=p>]</span>
</span><span id=__span-40-16><a id=__codelineno-40-16 name=__codelineno-40-16 href=#__codelineno-40-16></a>    <span class=k>return</span> <span class=n>decoded_preds</span><span class=p>,</span> <span class=n>decoded_labels</span>
</span></code></pre></div> <p>注意すべき最初の点は、予測を計算するために <code>generate()</code> メソッドを使用することですが、これはHugging Face Accelerateが <code>prepare()</code> メソッドで作成したラップされたモデルではなく、ベースモデルのメソッドです。そのため、最初にモデルをアンラップしてから、このメソッドを呼び出します。</p> <p>2番目の点は、<strong>トークン分類</strong>と同様に、2つのプロセスが入力とラベルを異なる形状にパディングしている可能性があるため、<code>gather()</code> メソッドを呼び出す前に、<code>accelerator.pad_across_processes()</code> を使用して予測とラベルを同じ形状にします。これを行わないと、評価がエラーアウトするか、永続的にハングします。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-41-1><a id=__codelineno-41-1 name=__codelineno-41-1 href=#__codelineno-41-1></a><span class=kn>from</span><span class=w> </span><span class=nn>tqdm.auto</span><span class=w> </span><span class=kn>import</span> <span class=n>tqdm</span>
</span><span id=__span-41-2><a id=__codelineno-41-2 name=__codelineno-41-2 href=#__codelineno-41-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-41-3><a id=__codelineno-41-3 name=__codelineno-41-3 href=#__codelineno-41-3></a>
</span><span id=__span-41-4><a id=__codelineno-41-4 name=__codelineno-41-4 href=#__codelineno-41-4></a><span class=c1># 進捗バーの設定</span>
</span><span id=__span-41-5><a id=__codelineno-41-5 name=__codelineno-41-5 href=#__codelineno-41-5></a><span class=n>progress_bar</span> <span class=o>=</span> <span class=n>tqdm</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>num_training_steps</span><span class=p>))</span>
</span><span id=__span-41-6><a id=__codelineno-41-6 name=__codelineno-41-6 href=#__codelineno-41-6></a>
</span><span id=__span-41-7><a id=__codelineno-41-7 name=__codelineno-41-7 href=#__codelineno-41-7></a><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_train_epochs</span><span class=p>):</span>
</span><span id=__span-41-8><a id=__codelineno-41-8 name=__codelineno-41-8 href=#__codelineno-41-8></a>    <span class=c1># 訓練フェーズ</span>
</span><span id=__span-41-9><a id=__codelineno-41-9 name=__codelineno-41-9 href=#__codelineno-41-9></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-41-10><a id=__codelineno-41-10 name=__codelineno-41-10 href=#__codelineno-41-10></a>    <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>train_dataloader</span><span class=p>:</span>
</span><span id=__span-41-11><a id=__codelineno-41-11 name=__codelineno-41-11 href=#__codelineno-41-11></a>        <span class=c1># 順伝播</span>
</span><span id=__span-41-12><a id=__codelineno-41-12 name=__codelineno-41-12 href=#__codelineno-41-12></a>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>batch</span><span class=p>)</span>
</span><span id=__span-41-13><a id=__codelineno-41-13 name=__codelineno-41-13 href=#__codelineno-41-13></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>loss</span>
</span><span id=__span-41-14><a id=__codelineno-41-14 name=__codelineno-41-14 href=#__codelineno-41-14></a>
</span><span id=__span-41-15><a id=__codelineno-41-15 name=__codelineno-41-15 href=#__codelineno-41-15></a>        <span class=c1># 逆伝播</span>
</span><span id=__span-41-16><a id=__codelineno-41-16 name=__codelineno-41-16 href=#__codelineno-41-16></a>        <span class=n>accelerator</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span><span id=__span-41-17><a id=__codelineno-41-17 name=__codelineno-41-17 href=#__codelineno-41-17></a>
</span><span id=__span-41-18><a id=__codelineno-41-18 name=__codelineno-41-18 href=#__codelineno-41-18></a>        <span class=c1># パラメータ更新</span>
</span><span id=__span-41-19><a id=__codelineno-41-19 name=__codelineno-41-19 href=#__codelineno-41-19></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-41-20><a id=__codelineno-41-20 name=__codelineno-41-20 href=#__codelineno-41-20></a>        <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-41-21><a id=__codelineno-41-21 name=__codelineno-41-21 href=#__codelineno-41-21></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-41-22><a id=__codelineno-41-22 name=__codelineno-41-22 href=#__codelineno-41-22></a>        <span class=n>progress_bar</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-41-23><a id=__codelineno-41-23 name=__codelineno-41-23 href=#__codelineno-41-23></a>
</span><span id=__span-41-24><a id=__codelineno-41-24 name=__codelineno-41-24 href=#__codelineno-41-24></a>    <span class=c1># 評価フェーズ</span>
</span><span id=__span-41-25><a id=__codelineno-41-25 name=__codelineno-41-25 href=#__codelineno-41-25></a>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-41-26><a id=__codelineno-41-26 name=__codelineno-41-26 href=#__codelineno-41-26></a>    <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>eval_dataloader</span><span class=p>):</span>
</span><span id=__span-41-27><a id=__codelineno-41-27 name=__codelineno-41-27 href=#__codelineno-41-27></a>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-41-28><a id=__codelineno-41-28 name=__codelineno-41-28 href=#__codelineno-41-28></a>            <span class=c1># generate()メソッドを使用してテキスト生成</span>
</span><span id=__span-41-29><a id=__codelineno-41-29 name=__codelineno-41-29 href=#__codelineno-41-29></a>            <span class=n>generated_tokens</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>unwrap_model</span><span class=p>(</span><span class=n>model</span><span class=p>)</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span><span id=__span-41-30><a id=__codelineno-41-30 name=__codelineno-41-30 href=#__codelineno-41-30></a>                <span class=n>batch</span><span class=p>[</span><span class=s2>&quot;input_ids&quot;</span><span class=p>],</span>
</span><span id=__span-41-31><a id=__codelineno-41-31 name=__codelineno-41-31 href=#__codelineno-41-31></a>                <span class=n>attention_mask</span><span class=o>=</span><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;attention_mask&quot;</span><span class=p>],</span>
</span><span id=__span-41-32><a id=__codelineno-41-32 name=__codelineno-41-32 href=#__codelineno-41-32></a>                <span class=n>max_length</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-41-33><a id=__codelineno-41-33 name=__codelineno-41-33 href=#__codelineno-41-33></a>            <span class=p>)</span>
</span><span id=__span-41-34><a id=__codelineno-41-34 name=__codelineno-41-34 href=#__codelineno-41-34></a>        <span class=n>labels</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s2>&quot;labels&quot;</span><span class=p>]</span>
</span><span id=__span-41-35><a id=__codelineno-41-35 name=__codelineno-41-35 href=#__codelineno-41-35></a>
</span><span id=__span-41-36><a id=__codelineno-41-36 name=__codelineno-41-36 href=#__codelineno-41-36></a>        <span class=c1># 予測とラベルを各プロセス間で同じ形状にパディング</span>
</span><span id=__span-41-37><a id=__codelineno-41-37 name=__codelineno-41-37 href=#__codelineno-41-37></a>        <span class=n>generated_tokens</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>pad_across_processes</span><span class=p>(</span>
</span><span id=__span-41-38><a id=__codelineno-41-38 name=__codelineno-41-38 href=#__codelineno-41-38></a>            <span class=n>generated_tokens</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pad_index</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span>
</span><span id=__span-41-39><a id=__codelineno-41-39 name=__codelineno-41-39 href=#__codelineno-41-39></a>        <span class=p>)</span>
</span><span id=__span-41-40><a id=__codelineno-41-40 name=__codelineno-41-40 href=#__codelineno-41-40></a>        <span class=n>labels</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>pad_across_processes</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pad_index</span><span class=o>=-</span><span class=mi>100</span><span class=p>)</span>
</span><span id=__span-41-41><a id=__codelineno-41-41 name=__codelineno-41-41 href=#__codelineno-41-41></a>
</span><span id=__span-41-42><a id=__codelineno-41-42 name=__codelineno-41-42 href=#__codelineno-41-42></a>        <span class=c1># 全プロセスから予測とラベルを収集</span>
</span><span id=__span-41-43><a id=__codelineno-41-43 name=__codelineno-41-43 href=#__codelineno-41-43></a>        <span class=n>predictions_gathered</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>generated_tokens</span><span class=p>)</span>
</span><span id=__span-41-44><a id=__codelineno-41-44 name=__codelineno-41-44 href=#__codelineno-41-44></a>        <span class=n>labels_gathered</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span><span id=__span-41-45><a id=__codelineno-41-45 name=__codelineno-41-45 href=#__codelineno-41-45></a>
</span><span id=__span-41-46><a id=__codelineno-41-46 name=__codelineno-41-46 href=#__codelineno-41-46></a>        <span class=c1># テキストに変換してメトリックに追加</span>
</span><span id=__span-41-47><a id=__codelineno-41-47 name=__codelineno-41-47 href=#__codelineno-41-47></a>        <span class=n>decoded_preds</span><span class=p>,</span> <span class=n>decoded_labels</span> <span class=o>=</span> <span class=n>postprocess</span><span class=p>(</span><span class=n>predictions_gathered</span><span class=p>,</span> <span class=n>labels_gathered</span><span class=p>)</span>
</span><span id=__span-41-48><a id=__codelineno-41-48 name=__codelineno-41-48 href=#__codelineno-41-48></a>        <span class=n>metric</span><span class=o>.</span><span class=n>add_batch</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>decoded_preds</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>decoded_labels</span><span class=p>)</span>
</span><span id=__span-41-49><a id=__codelineno-41-49 name=__codelineno-41-49 href=#__codelineno-41-49></a>
</span><span id=__span-41-50><a id=__codelineno-41-50 name=__codelineno-41-50 href=#__codelineno-41-50></a>    <span class=c1># BLEUスコアを計算して表示</span>
</span><span id=__span-41-51><a id=__codelineno-41-51 name=__codelineno-41-51 href=#__codelineno-41-51></a>    <span class=n>results</span> <span class=o>=</span> <span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>()</span>
</span><span id=__span-41-52><a id=__codelineno-41-52 name=__codelineno-41-52 href=#__codelineno-41-52></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>, BLEU score: </span><span class=si>{</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;score&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-41-53><a id=__codelineno-41-53 name=__codelineno-41-53 href=#__codelineno-41-53></a>
</span><span id=__span-41-54><a id=__codelineno-41-54 name=__codelineno-41-54 href=#__codelineno-41-54></a>    <span class=c1># モデルの保存とアップロード</span>
</span><span id=__span-41-55><a id=__codelineno-41-55 name=__codelineno-41-55 href=#__codelineno-41-55></a>    <span class=n>accelerator</span><span class=o>.</span><span class=n>wait_for_everyone</span><span class=p>()</span>
</span><span id=__span-41-56><a id=__codelineno-41-56 name=__codelineno-41-56 href=#__codelineno-41-56></a>    <span class=n>unwrapped_model</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>unwrap_model</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span><span id=__span-41-57><a id=__codelineno-41-57 name=__codelineno-41-57 href=#__codelineno-41-57></a>    <span class=n>unwrapped_model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>output_dir</span><span class=p>,</span> <span class=n>save_function</span><span class=o>=</span><span class=n>accelerator</span><span class=o>.</span><span class=n>save</span><span class=p>)</span>
</span><span id=__span-41-58><a id=__codelineno-41-58 name=__codelineno-41-58 href=#__codelineno-41-58></a>    <span class=k>if</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>is_main_process</span><span class=p>:</span>
</span><span id=__span-41-59><a id=__codelineno-41-59 name=__codelineno-41-59 href=#__codelineno-41-59></a>        <span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>output_dir</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-42-1><a id=__codelineno-42-1 name=__codelineno-42-1 href=#__codelineno-42-1></a>epoch 0, BLEU score: 33.26
</span><span id=__span-42-2><a id=__codelineno-42-2 name=__codelineno-42-2 href=#__codelineno-42-2></a>epoch 1, BLEU score: 38.19
</span><span id=__span-42-3><a id=__codelineno-42-3 name=__codelineno-42-3 href=#__codelineno-42-3></a>epoch 2, BLEU score: 41.56
</span></code></pre></div></p> <h2 id=_12>参考資料<a class=headerlink href=#_12 title="Permanent link">&para;</a></h2> <p><strong>使用したデータセットとモデル:</strong> - <a href=https://huggingface.co/datasets/Helsinki-NLP/opus-100>Helsinki-NLP/opus-100</a>: 大規模多言語翻訳データセット - <a href=https://huggingface.co/Helsinki-NLP/opus-mt-en-jap>Helsinki-NLP/opus-mt-en-jap</a>: 英日翻訳用事前訓練済みモデル</p> <p><strong>評価メトリック:</strong> - <a href=https://github.com/mjpost/sacrebleu>SacreBLEU</a>: 標準化されたBLEU評価ツール - <a href=https://aclanthology.org/P02-1040.pdf>BLEU: a Method for Automatic Evaluation of Machine Translation</a>: BLEUスコアの原論文</p> <p><strong>関連技術資料:</strong> - <a href=https://arxiv.org/pdf/1706.03762.pdf>Attention Is All You Need</a>: Transformerアーキテクチャの原論文 - <a href=https://huggingface.co/transformers/ >Hugging Face Transformers Documentation</a>: 公式ドキュメント - <a href=https://huggingface.co/Helsinki-NLP>Helsinki-NLP Organization</a>: 1000以上の翻訳モデルを提供</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title=最終更新日> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年9月28日 19:08:34 JST">2025年9月28日 19:08:34</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> ページトップへ戻る </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 - 2025 vinsmoke-three </div> </div> <div class=md-social> <a href=https://github.com/vinsmoke-three target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.copy", "navigation.expand", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": {"BERT": "bert", "CNN": "convolutional-neural-network", "FashionMNIST": "fashion-mnist", "GPT": "gpt", "LLM": "large-language-model", "ML\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3": "ml-pipeline", "NLP": "nlp", "PyTorch": "pytorch", "Python": "python", "TensorBoard": "tensorboard", "TinyVGG": "tinyvgg", "Transformer": "transformer", "\u30ab\u30b9\u30bf\u30e0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8": "custom-datasets", "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3": "computer-vision", "\u30b9\u30af\u30ea\u30d7\u30c8\u30e2\u30fc\u30c9": "script-mode", "\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb": "tutorial", "\u30c6\u30f3\u30bd\u30eb": "tensor", "\u30c7\u30fc\u30bf\u62e1\u5f35": "data-augmentation", "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af": "neural-network", "\u30e2\u30b8\u30e5\u30fc\u30eb\u5316": "modularization", "\u30ef\u30fc\u30af\u30d5\u30ed\u30fc": "workflow", "\u4e0a\u7d1a\u8005\u5411\u3051": "advanced", "\u4e2d\u7d1a\u8005\u5411\u3051": "intermediate", "\u518d\u5229\u7528": "reusability", "\u5206\u985e": "classification", "\u521d\u5fc3\u8005\u5411\u3051": "beginner", "\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb": "large-language-model", "\u5b9f\u8df5": "practical", "\u5b9f\u9a13\u8ffd\u8de1": "experiment-tracking", "\u6a5f\u68b0\u5b66\u7fd2": "machine-learning", "\u6df1\u5c64\u5b66\u7fd2": "deep-learning", "\u753b\u50cf\u5206\u985e": "image-classification", "\u7dda\u5f62\u56de\u5e30": "linear-regression", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406": "natural-language-processing", "\u8ee2\u79fb\u5b66\u7fd2": "transfer-learning"}, "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=../../../javascripts/meta.js></script> <script src=../../../javascripts/structured-data.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>