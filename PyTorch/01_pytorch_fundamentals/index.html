<!doctype html><html lang=ja class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=PyTorchの基本的なテンソル操作を学び、機械学習の土台を築くための実践的なガイド><meta name=author content=vinsmoke-three><link href=https://vinsmoke-three.com/PyTorch/01_pytorch_fundamentals/ rel=canonical><link href=../00_setup/ rel=prev><link href=../02_pytorch_workflow/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.20"><title>PyTorch基礎：テンソル操作から始める深層学習 - vinsmoke-three - 機械学習・深層学習ドキュメント</title><link rel=stylesheet href=../../assets/stylesheets/main.e53b48f4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-BXKYE0NT9N"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-BXKYE0NT9N",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-BXKYE0NT9N",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#pytorch class=md-skip> コンテンツにスキップ </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=ヘッダー> <a href=../.. title="vinsmoke-three - 機械学習・深層学習ドキュメント" class="md-header__button md-logo" aria-label="vinsmoke-three - 機械学習・深層学習ドキュメント" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 14.27 10.64 13A11.24 11.24 0 0 0 5 10.18v6.95c2.61.34 5 1.34 7 2.82 2-1.48 4.39-2.48 7-2.82v-6.95c-2.16.39-4.09 1.39-5.64 2.82M19 8.15c.65-.1 1.32-.15 2-.15v11c-3.5 0-6.64 1.35-9 3.54C9.64 20.35 6.5 19 3 19V8c.68 0 1.35.05 2 .15 2.69.41 5.1 1.63 7 3.39 1.9-1.76 4.31-2.98 7-3.39M12 6c.27 0 .5-.1.71-.29.19-.21.29-.44.29-.71s-.1-.5-.29-.71C12.5 4.11 12.27 4 12 4s-.5.11-.71.29c-.18.21-.29.45-.29.71s.11.5.29.71c.21.19.45.29.71.29m2.12 1.12a2.997 2.997 0 1 1-4.24-4.24 2.997 2.997 0 1 1 4.24 4.24"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> vinsmoke-three - 機械学習・深層学習ドキュメント </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> PyTorch基礎：テンソル操作から始める深層学習 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=検索 placeholder=検索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=検索> <a href=javascript:void(0) class="md-search__icon md-icon" title=共有 aria-label=共有 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=クリア aria-label=クリア tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 検索を初期化 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=タブ data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../00_setup/ class=md-tabs__link> PyTorch </a> </li> <li class=md-tabs__item> <a href=../../LLM/00_illustrated_transformer/ class=md-tabs__link> LLM </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=ナビゲーション data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="vinsmoke-three - 機械学習・深層学習ドキュメント" class="md-nav__button md-logo" aria-label="vinsmoke-three - 機械学習・深層学習ドキュメント" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 14.27 10.64 13A11.24 11.24 0 0 0 5 10.18v6.95c2.61.34 5 1.34 7 2.82 2-1.48 4.39-2.48 7-2.82v-6.95c-2.16.39-4.09 1.39-5.64 2.82M19 8.15c.65-.1 1.32-.15 2-.15v11c-3.5 0-6.64 1.35-9 3.54C9.64 20.35 6.5 19 3 19V8c.68 0 1.35.05 2 .15 2.69.41 5.1 1.63 7 3.39 1.9-1.76 4.31-2.98 7-3.39M12 6c.27 0 .5-.1.71-.29.19-.21.29-.44.29-.71s-.1-.5-.29-.71C12.5 4.11 12.27 4 12 4s-.5.11-.71.29c-.18.21-.29.45-.29.71s.11.5.29.71c.21.19.45.29.71.29m2.12 1.12a2.997 2.997 0 1 1-4.24-4.24 2.997 2.997 0 1 1 4.24 4.24"/></svg> </a> vinsmoke-three - 機械学習・深層学習ドキュメント </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> PyTorch </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> PyTorch </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../00_setup/ class=md-nav__link> <span class=md-ellipsis> 0. setup </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 1. PyTorch fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 1. PyTorch fundamentals </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目次> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目次 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 概要 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 前提知識 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 環境設定とライブラリインポート </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> テンソルの基礎概念 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> ランダムテンソルの重要性 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 特殊なテンソルの作成 </span> </a> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 範囲指定テンソルとテンソルライク操作 </span> </a> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> テンソルのデータ型 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> テンソル情報の取得 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> テンソル演算 </span> </a> </li> <li class=md-nav__item> <a href=#_23 class=md-nav__link> <span class=md-ellipsis> 集約演算（最小、最大、平均、合計） </span> </a> </li> <li class=md-nav__item> <a href=#_25 class=md-nav__link> <span class=md-ellipsis> テンソルの形状操作 </span> </a> </li> <li class=md-nav__item> <a href=#_29 class=md-nav__link> <span class=md-ellipsis> テンソルインデックス </span> </a> </li> <li class=md-nav__item> <a href=#pytorchnumpy class=md-nav__link> <span class=md-ellipsis> PyTorchテンソルとNumPy </span> </a> </li> <li class=md-nav__item> <a href=#_30 class=md-nav__link> <span class=md-ellipsis> 再現性の確保 </span> </a> </li> <li class=md-nav__item> <a href=#gpumps class=md-nav__link> <span class=md-ellipsis> GPU（MPS）での高速計算 </span> </a> </li> <li class=md-nav__item> <a href=#_32 class=md-nav__link> <span class=md-ellipsis> まとめ </span> </a> </li> <li class=md-nav__item> <a href=#_34 class=md-nav__link> <span class=md-ellipsis> 参考資料 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../02_pytorch_workflow/ class=md-nav__link> <span class=md-ellipsis> 2. PyTorch workflow </span> </a> </li> <li class=md-nav__item> <a href=../03_pytorch_classification/ class=md-nav__link> <span class=md-ellipsis> 3. PyTorch classification </span> </a> </li> <li class=md-nav__item> <a href=../04_pytorch_computer_vision/ class=md-nav__link> <span class=md-ellipsis> 4. PyTorch computer vision </span> </a> </li> <li class=md-nav__item> <a href=../05_pytorch_custom_datasets/ class=md-nav__link> <span class=md-ellipsis> 5. PyTorch custom datasets </span> </a> </li> <li class=md-nav__item> <a href=../06_pytorch_modular/ class=md-nav__link> <span class=md-ellipsis> 6. PyTorch modular </span> </a> </li> <li class=md-nav__item> <a href=../07_pytorch_transfer_learning/ class=md-nav__link> <span class=md-ellipsis> 7. PyTorch transfer learning </span> </a> </li> <li class=md-nav__item> <a href=../08_pytorch_experiment_tracking/ class=md-nav__link> <span class=md-ellipsis> 8. PyTorch experiment tracking </span> </a> </li> <li class=md-nav__item> <a href=../09_pytorch_paper_replicating/ class=md-nav__link> <span class=md-ellipsis> 9. PyTorch paper replicating </span> </a> </li> <li class=md-nav__item> <a href=../10_pytorch_model_deployment/ class=md-nav__link> <span class=md-ellipsis> 10. PyTorch model deployment </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> LLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../LLM/00_illustrated_transformer/ class=md-nav__link> <span class=md-ellipsis> 0. The illustrated transformer </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/01_transformer_models/ class=md-nav__link> <span class=md-ellipsis> 1. Transformer models </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/02_using_transformers/ class=md-nav__link> <span class=md-ellipsis> 2. Using transformers </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/03_fine_tuning_a_pretrained_model/ class=md-nav__link> <span class=md-ellipsis> 3. Fine-tuning a pretrained model </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/04_the_huggingface_tokenizers_library/ class=md-nav__link> <span class=md-ellipsis> 4. Tokenizers library </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/05_Let%27s_build_GPT_from_scratch/ class=md-nav__link> <span class=md-ellipsis> 5. Let't build GPT from scratch </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/06_the_huggingface_datasets_library/ class=md-nav__link> <span class=md-ellipsis> 6. Datasets library </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> 7. Classical NLP Tasks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> 7. Classical NLP Tasks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../LLM/ClassicalNLP/71_token_classification/ class=md-nav__link> <span class=md-ellipsis> Token Classification </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/ClassicalNLP/72_masked_language_modeling/ class=md-nav__link> <span class=md-ellipsis> Masked Language Modeling </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/ClassicalNLP/73_translation/ class=md-nav__link> <span class=md-ellipsis> Translation </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/ClassicalNLP/74_summarization/ class=md-nav__link> <span class=md-ellipsis> Summarization </span> </a> </li> <li class=md-nav__item> <a href=../../LLM/ClassicalNLP/75_question_answering/ class=md-nav__link> <span class=md-ellipsis> Question Answering </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目次> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目次 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 概要 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 前提知識 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 環境設定とライブラリインポート </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> テンソルの基礎概念 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> ランダムテンソルの重要性 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 特殊なテンソルの作成 </span> </a> </li> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 範囲指定テンソルとテンソルライク操作 </span> </a> </li> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> テンソルのデータ型 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> テンソル情報の取得 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> テンソル演算 </span> </a> </li> <li class=md-nav__item> <a href=#_23 class=md-nav__link> <span class=md-ellipsis> 集約演算（最小、最大、平均、合計） </span> </a> </li> <li class=md-nav__item> <a href=#_25 class=md-nav__link> <span class=md-ellipsis> テンソルの形状操作 </span> </a> </li> <li class=md-nav__item> <a href=#_29 class=md-nav__link> <span class=md-ellipsis> テンソルインデックス </span> </a> </li> <li class=md-nav__item> <a href=#pytorchnumpy class=md-nav__link> <span class=md-ellipsis> PyTorchテンソルとNumPy </span> </a> </li> <li class=md-nav__item> <a href=#_30 class=md-nav__link> <span class=md-ellipsis> 再現性の確保 </span> </a> </li> <li class=md-nav__item> <a href=#gpumps class=md-nav__link> <span class=md-ellipsis> GPU（MPS）での高速計算 </span> </a> </li> <li class=md-nav__item> <a href=#_32 class=md-nav__link> <span class=md-ellipsis> まとめ </span> </a> </li> <li class=md-nav__item> <a href=#_34 class=md-nav__link> <span class=md-ellipsis> 参考資料 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=pytorch>PyTorch基礎：テンソル操作から始める深層学習<a class=headerlink href=#pytorch title="Permanent link">&para;</a></h1> <h2 id=_1>概要<a class=headerlink href=#_1 title="Permanent link">&para;</a></h2> <p>この記事では、PyTorchの最も重要な概念である「テンソル」について基礎から学習します。テンソルは深層学習における数値計算の基本単位であり、PyTorchを使いこなすために必須の知識です。</p> <h3 id=_2>学習目標<a class=headerlink href=#_2 title="Permanent link">&para;</a></h3> <ul> <li>テンソルの概念と種類を理解する</li> <li>PyTorchでの基本的なテンソル操作をマスターする</li> <li>GPU（MPS）を活用した高速計算の方法を学ぶ</li> <li>実際のコードを通じて実践的な技術を身につける</li> </ul> <h2 id=_3>前提知識<a class=headerlink href=#_3 title="Permanent link">&para;</a></h2> <ul> <li>Python基礎（リスト、関数、ライブラリ）</li> <li>数学基礎（行列、ベクトルの概念）</li> <li>Jupyter Notebookの基本的な使い方</li> </ul> <h2 id=_4>環境設定とライブラリインポート<a class=headerlink href=#_4 title="Permanent link">&para;</a></h2> <p>まず、必要なライブラリをインポートし、Mac環境でのMPS（Metal Performance Shaders）が利用可能かを確認します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=c1># MPSが利用されているかを確認</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=c1># 期待値　tensor([1.], device=&#39;mps:0&#39;)</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    <span class=n>mps_device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;mps&quot;</span><span class=p>)</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>mps_device</span><span class=p>)</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>    <span class=nb>print</span> <span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>    <span class=nb>print</span> <span class=p>(</span><span class=s2>&quot;MPS device not found.&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>tensor([1.], device=&#39;mps:0&#39;)
</span></code></pre></div></p> <p>MPSデバイスが正常に認識され、GPU加速が利用可能であることが確認できました。</p> <h2 id=_5>テンソルの基礎概念<a class=headerlink href=#_5 title="Permanent link">&para;</a></h2> <h3 id=0>スカラー（0次元テンソル）<a class=headerlink href=#0 title="Permanent link">&para;</a></h3> <p>スカラーは単一の数値を表す最もシンプルなテンソルです。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># scalar 1つの数字</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>scalar</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=mi>7</span><span class=p>)</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=nb>print</span><span class=p>(</span><span class=n>scalar</span><span class=o>.</span><span class=n>ndim</span><span class=p>)</span>  <span class=c1># 次元数を表示</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=c1># 単一の値を含むテンソルからPythonの数値を取得するために使用します</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=nb>print</span><span class=p>(</span><span class=n>scalar</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>  <span class=c1># Pythonの数値として取得</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>0
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>7
</span></code></pre></div></p> <p><strong>ポイント:</strong> - <code>ndim</code>で次元数を確認（スカラーは0次元） - <code>item()</code>でPythonの標準的な数値型に変換</p> <h3 id=1>ベクトル（1次元テンソル）<a class=headerlink href=#1 title="Permanent link">&para;</a></h3> <p>ベクトルは数値の1次元配列で、方向と大きさを持つ量を表現できます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Vector 方向を持つ数値（例: 風速と方向）ですが、他の多くの数値を持つこともできます</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>vector</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>7</span><span class=p>,</span> <span class=mi>7</span><span class=p>])</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=n>vector</span><span class=o>.</span><span class=n>ndim</span><span class=p>,</span> <span class=n>vector</span><span class=o>.</span><span class=n>shape</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a>(1, torch.Size([2]))
</span></code></pre></div></p> <h3 id=2>行列（2次元テンソル）<a class=headerlink href=#2 title="Permanent link">&para;</a></h3> <p>行列は数値の2次元配列で、画像データや表形式データの表現に使用されます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Matrix 数値の2次元配列</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=c1># 大文字は一般的です</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=n>MATRIX</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>                       <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>]])</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=nb>print</span><span class=p>(</span><span class=n>MATRIX</span><span class=p>)</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=nb>print</span><span class=p>(</span><span class=n>MATRIX</span><span class=o>.</span><span class=n>ndim</span><span class=p>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=nb>print</span><span class=p>(</span><span class=n>MATRIX</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a><span class=nb>print</span><span class=p>(</span><span class=n>MATRIX</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>  <span class=c1># 最初の行を取得</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a>tensor([[1, 3],
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>        [2, 4]])
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>2
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>torch.Size([2, 2])
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>tensor([1, 3])
</span></code></pre></div></p> <h3 id=3>高次元テンソル（3次元以上）<a class=headerlink href=#3 title="Permanent link">&para;</a></h3> <p>3次元以上のテンソルは、カラー画像、動画、バッチデータなどの複雑な構造を表現します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Tensor 数値のn次元配列</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=c1># 大文字は一般的です</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=n>TENSOR</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>                        <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>                        <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>]]])</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=nb>print</span><span class=p>(</span><span class=n>TENSOR</span><span class=p>)</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=nb>print</span><span class=p>(</span><span class=n>TENSOR</span><span class=o>.</span><span class=n>ndim</span><span class=p>)</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=nb>print</span><span class=p>(</span><span class=n>TENSOR</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=nb>print</span><span class=p>(</span><span class=n>TENSOR</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>1</span><span class=p>][</span><span class=mi>1</span><span class=p>])</span>  <span class=c1># 特定の要素にアクセス</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a>tensor([[[1, 2, 3],
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>         [3, 4, 5],
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>         [5, 6, 7]]])
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>3
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>torch.Size([1, 3, 3])
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>tensor(4)
</span></code></pre></div></p> <h2 id=_6>ランダムテンソルの重要性<a class=headerlink href=#_6 title="Permanent link">&para;</a></h2> <h3 id=_7>なぜランダムテンソルが重要なのか？<a class=headerlink href=#_7 title="Permanent link">&para;</a></h3> <p>機械学習モデルは通常、ランダムな値で初期化されたテンソルから学習を開始します。これは、モデルが学習データから最適なパターンを発見するためのスタート地点として機能します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># 3×4のランダムテンソルを作成</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>random_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=n>random_tensor</span><span class=p>,</span> <span class=n>random_tensor</span><span class=o>.</span><span class=n>ndim</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a>(tensor([[0.6824, 0.4339, 0.7100, 0.4324],
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>         [0.1593, 0.0316, 0.4038, 0.4528],
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>         [0.5886, 0.0108, 0.5766, 0.2656]]),
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a> 2)
</span></code></pre></div></p> <h3 id=_8>画像サイズのテンソル<a class=headerlink href=#_8 title="Permanent link">&para;</a></h3> <p>実際のコンピュータビジョンタスクでよく使用される画像サイズのテンソルを作成してみます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># 画像テンソルと同様の形状でランダムテンソルを作成</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=n>random_image_size_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>))</span>  <span class=c1># R, G, B</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=n>random_image_size_tensor</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>random_image_size_tensor</span><span class=o>.</span><span class=n>ndim</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a>(torch.Size([3, 224, 224]), 3)
</span></code></pre></div></p> <p>この形状は、3チャンネル（RGB）の224×224ピクセルの画像を表現しており、多くの深層学習モデルの標準的な入力サイズです。</p> <h2 id=_9>特殊なテンソルの作成<a class=headerlink href=#_9 title="Permanent link">&para;</a></h2> <h3 id=_10>ゼロ埋めテンソル<a class=headerlink href=#_10 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># すべての要素が0のテンソルを作成</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>zeros</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=n>zeros</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a>tensor([[0., 0., 0., 0.],
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>        [0., 0., 0., 0.],
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>        [0., 0., 0., 0.]])
</span></code></pre></div></p> <h3 id=1_1>1埋めテンソル<a class=headerlink href=#1_1 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># すべての要素が1のテンソルを作成</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=n>ones</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a><span class=n>ones</span><span class=o>.</span><span class=n>dtype</span><span class=p>,</span> <span class=n>ones</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>(torch.float32,
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a> tensor([[1., 1., 1., 1.],
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>         [1., 1., 1., 1.],
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>         [1., 1., 1., 1.]]))
</span></code></pre></div></p> <h2 id=_11>範囲指定テンソルとテンソルライク操作<a class=headerlink href=#_11 title="Permanent link">&para;</a></h2> <h3 id=_12>連続値テンソルの作成<a class=headerlink href=#_12 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=c1># torch.range()は非推奨のため、torch.arange()を使用</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=n>torch</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>  <span class=c1># 警告が表示される</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>  <span class=c1># 推奨される方法</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=n>one_to_ten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>start</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=n>one_to_ten</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>/var/folders/.../UserWarning: torch.range is deprecated...
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>tensor([1, 3, 5, 7, 9])
</span></code></pre></div></p> <h3 id=_13>既存テンソルと同じ形状での新規作成<a class=headerlink href=#_13 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=c1># 既存テンソルと同じ形状でゼロ埋めテンソルを作成</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=n>ten_zeros</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=nb>input</span><span class=o>=</span><span class=n>one_to_ten</span><span class=p>)</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=n>ten_zeros</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>tensor([0, 0, 0, 0, 0])
</span></code></pre></div></p> <h2 id=_14>テンソルのデータ型<a class=headerlink href=#_14 title="Permanent link">&para;</a></h2> <p>PyTorchには様々なデータ型があり、計算精度と処理速度のバランスを考慮して選択します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=c1># Float 32 tensor</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a><span class=n>float_32_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>3.0</span><span class=p>,</span> <span class=mf>4.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>],</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>                                <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span>  <span class=c1># デフォルトはNone（torch.float32）</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a>                                <span class=n>device</span><span class=o>=</span><span class=s2>&quot;mps&quot;</span><span class=p>,</span>  <span class=c1># デバイス指定（MPS使用）</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>                                <span class=n>requires_grad</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>  <span class=c1># 勾配計算の要否</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a><span class=n>float_32_tensor</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a>tensor([3., 4., 5.], device=&#39;mps:0&#39;)
</span></code></pre></div></p> <h3 id=_15>データ型変換<a class=headerlink href=#_15 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=c1># 32ビットから16ビット浮動小数点に変換</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a><span class=n>float_16_tensor</span> <span class=o>=</span> <span class=n>float_32_tensor</span><span class=o>.</span><span class=n>type</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a><span class=n>float_16_tensor</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a>tensor([3., 4., 5.], device=&#39;mps:0&#39;, dtype=torch.float16)
</span></code></pre></div></p> <h3 id=_16>異なるデータ型間の演算<a class=headerlink href=#_16 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=c1># 異なるデータ型のテンソル同士の演算</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a><span class=n>float_32_tensor</span> <span class=o>*</span> <span class=n>float_16_tensor</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a>tensor([ 9., 16., 25.], device=&#39;mps:0&#39;)
</span></code></pre></div></p> <p>PyTorchは自動的にデータ型を統一して計算を実行します。</p> <h2 id=_17>テンソル情報の取得<a class=headerlink href=#_17 title="Permanent link">&para;</a></h2> <p>テンソル操作において、形状、データ型、デバイスの情報は重要です。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=c1># テンソルを作成</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a><span class=n>some_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a><span class=nb>print</span><span class=p>(</span><span class=n>some_tensor</span><span class=p>)</span>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Datatype of tensor: </span><span class=si>{</span><span class=n>some_tensor</span><span class=o>.</span><span class=n>dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a><span class=nb>print</span><span class=p>(</span><span class=n>some_tensor</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a><span class=nb>print</span><span class=p>(</span><span class=n>some_tensor</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a>tensor([[0.1515, 0.4290, 0.8059, 0.6290],
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a>        [0.3464, 0.7190, 0.4837, 0.6463],
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a>        [0.9553, 0.6466, 0.0363, 0.1495]])
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a>Datatype of tensor: torch.float32
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a>torch.Size([3, 4])
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6 href=#__codelineno-29-6></a>cpu
</span></code></pre></div></p> <h2 id=_18>テンソル演算<a class=headerlink href=#_18 title="Permanent link">&para;</a></h2> <h3 id=_19>基本的な算術演算<a class=headerlink href=#_19 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span> <span class=o>+</span> <span class=mi>10</span><span class=p>)</span>    <span class=c1># 加算</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span> <span class=o>-</span> <span class=mi>10</span><span class=p>)</span>    <span class=c1># 減算</span>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span> <span class=o>*</span> <span class=mi>10</span><span class=p>)</span>    <span class=c1># 乗算</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span> <span class=o>/</span> <span class=mi>10</span><span class=p>)</span>    <span class=c1># 除算</span>
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6 href=#__codelineno-30-6></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>    <span class=c1># 関数を使った乗算</span>
</span><span id=__span-30-7><a id=__codelineno-30-7 name=__codelineno-30-7 href=#__codelineno-30-7></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>    <span class=c1># 関数を使った加算</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a>tensor([11, 13, 15])
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2 href=#__codelineno-31-2></a>tensor([-9, -7, -5])
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3 href=#__codelineno-31-3></a>tensor([10, 30, 50])
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4 href=#__codelineno-31-4></a>tensor([0.1000, 0.3000, 0.5000])
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5 href=#__codelineno-31-5></a>tensor([10, 30, 50])
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6 href=#__codelineno-31-6></a>tensor([11, 13, 15])
</span></code></pre></div></p> <h3 id=_20>行列の乗算（重要な概念）<a class=headerlink href=#_20 title="Permanent link">&para;</a></h3> <p>行列の乗算は深層学習において最も重要な演算の一つです。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a><span class=c1># ベクトルの内積計算</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a><span class=c1># 1*1 + 2*2 + 3*3 = 14</span>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a><span class=n>tensor_a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a><span class=n>tensor_b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a><span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>tensor_a</span><span class=p>,</span> <span class=n>tensor_b</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a>tensor(14)
</span></code></pre></div></p> <h3 id=_21>行列乗算のルール<a class=headerlink href=#_21 title="Permanent link">&para;</a></h3> <p>行列乗算には重要なルールがあります：</p> <ol> <li><strong>内側の次元が一致する必要がある</strong></li> <li><strong>結果の形状は外側の次元になる</strong></li> </ol> <div class="language-python highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a><span class=c1># 形状を確認しながら行列を定義</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a><span class=n>tensor_A</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a>                         <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a>                         <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a><span class=n>tensor_B</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a>                         <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> 
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a>                         <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>12</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10 href=#__codelineno-34-10></a><span class=c1># torch.matmul(tensor_A, tensor_B)  # これはエラーになる</span>
</span></code></pre></div> <h3 id=_22>転置を使った行列乗算<a class=headerlink href=#_22 title="Permanent link">&para;</a></h3> <p>形状が合わない場合は、転置を使って調整します。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>tensor_A</span><span class=p>,</span> <span class=n>tensor_B</span><span class=o>.</span><span class=n>T</span><span class=p>))</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2 href=#__codelineno-35-2></a>
</span><span id=__span-35-3><a id=__codelineno-35-3 name=__codelineno-35-3 href=#__codelineno-35-3></a><span class=c1># 詳細な説明</span>
</span><span id=__span-35-4><a id=__codelineno-35-4 name=__codelineno-35-4 href=#__codelineno-35-4></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;元の形状: tensor_A = </span><span class=si>{</span><span class=n>tensor_A</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>, tensor_B = </span><span class=si>{</span><span class=n>tensor_B</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-35-5><a id=__codelineno-35-5 name=__codelineno-35-5 href=#__codelineno-35-5></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;新しい形状: tensor_A = </span><span class=si>{</span><span class=n>tensor_A</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2> (同じ), tensor_B.T = </span><span class=si>{</span><span class=n>tensor_B</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-35-6><a id=__codelineno-35-6 name=__codelineno-35-6 href=#__codelineno-35-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;乗算: </span><span class=si>{</span><span class=n>tensor_A</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2> * </span><span class=si>{</span><span class=n>tensor_B</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2> &lt;- 内側の次元が一致</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-35-7><a id=__codelineno-35-7 name=__codelineno-35-7 href=#__codelineno-35-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;結果:</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-35-8><a id=__codelineno-35-8 name=__codelineno-35-8 href=#__codelineno-35-8></a><span class=n>output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>tensor_A</span><span class=p>,</span> <span class=n>tensor_B</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
</span><span id=__span-35-9><a id=__codelineno-35-9 name=__codelineno-35-9 href=#__codelineno-35-9></a><span class=nb>print</span><span class=p>(</span><span class=n>output</span><span class=p>)</span> 
</span><span id=__span-35-10><a id=__codelineno-35-10 name=__codelineno-35-10 href=#__codelineno-35-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>出力の形状: </span><span class=si>{</span><span class=n>output</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a>tensor([[ 27.,  30.,  33.],
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a>        [ 61.,  68.,  75.],
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a>        [ 95., 106., 117.]])
</span><span id=__span-36-4><a id=__codelineno-36-4 name=__codelineno-36-4 href=#__codelineno-36-4></a>
</span><span id=__span-36-5><a id=__codelineno-36-5 name=__codelineno-36-5 href=#__codelineno-36-5></a>元の形状: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])
</span><span id=__span-36-6><a id=__codelineno-36-6 name=__codelineno-36-6 href=#__codelineno-36-6></a>
</span><span id=__span-36-7><a id=__codelineno-36-7 name=__codelineno-36-7 href=#__codelineno-36-7></a>新しい形状: tensor_A = torch.Size([3, 2]) (同じ), tensor_B.T = torch.Size([2, 3])
</span><span id=__span-36-8><a id=__codelineno-36-8 name=__codelineno-36-8 href=#__codelineno-36-8></a>
</span><span id=__span-36-9><a id=__codelineno-36-9 name=__codelineno-36-9 href=#__codelineno-36-9></a>乗算: torch.Size([3, 2]) * torch.Size([2, 3]) &lt;- 内側の次元が一致
</span><span id=__span-36-10><a id=__codelineno-36-10 name=__codelineno-36-10 href=#__codelineno-36-10></a>
</span><span id=__span-36-11><a id=__codelineno-36-11 name=__codelineno-36-11 href=#__codelineno-36-11></a>結果:
</span><span id=__span-36-12><a id=__codelineno-36-12 name=__codelineno-36-12 href=#__codelineno-36-12></a>
</span><span id=__span-36-13><a id=__codelineno-36-13 name=__codelineno-36-13 href=#__codelineno-36-13></a>tensor([[ 27.,  30.,  33.],
</span><span id=__span-36-14><a id=__codelineno-36-14 name=__codelineno-36-14 href=#__codelineno-36-14></a>        [ 61.,  68.,  75.],
</span><span id=__span-36-15><a id=__codelineno-36-15 name=__codelineno-36-15 href=#__codelineno-36-15></a>        [ 95., 106., 117.]])
</span><span id=__span-36-16><a id=__codelineno-36-16 name=__codelineno-36-16 href=#__codelineno-36-16></a>
</span><span id=__span-36-17><a id=__codelineno-36-17 name=__codelineno-36-17 href=#__codelineno-36-17></a>出力の形状: torch.Size([3, 3])
</span></code></pre></div></p> <h2 id=_23>集約演算（最小、最大、平均、合計）<a class=headerlink href=#_23 title="Permanent link">&para;</a></h2> <div class="language-python highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a><span class=c1># テンソルを作成</span>
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2 href=#__codelineno-37-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3 href=#__codelineno-37-3></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>dtype</span><span class=p>)</span>
</span><span id=__span-37-4><a id=__codelineno-37-4 name=__codelineno-37-4 href=#__codelineno-37-4></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>      <span class=c1># 最小値</span>
</span><span id=__span-37-5><a id=__codelineno-37-5 name=__codelineno-37-5 href=#__codelineno-37-5></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>           <span class=c1># 同上（メソッド版）</span>
</span><span id=__span-37-6><a id=__codelineno-37-6 name=__codelineno-37-6 href=#__codelineno-37-6></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>      <span class=c1># 最大値</span>
</span><span id=__span-37-7><a id=__codelineno-37-7 name=__codelineno-37-7 href=#__codelineno-37-7></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>max</span><span class=p>())</span>           <span class=c1># 同上（メソッド版）</span>
</span><span id=__span-37-8><a id=__codelineno-37-8 name=__codelineno-37-8 href=#__codelineno-37-8></a><span class=c1># 平均値計算にはfloat型が必要</span>
</span><span id=__span-37-9><a id=__codelineno-37-9 name=__codelineno-37-9 href=#__codelineno-37-9></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>type</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)))</span>
</span><span id=__span-37-10><a id=__codelineno-37-10 name=__codelineno-37-10 href=#__codelineno-37-10></a><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>      <span class=c1># 合計</span>
</span><span id=__span-37-11><a id=__codelineno-37-11 name=__codelineno-37-11 href=#__codelineno-37-11></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>sum</span><span class=p>())</span>           <span class=c1># 同上（メソッド版）</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a>tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) torch.int64
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a>tensor(0)
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a>tensor(0)
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a>tensor(90)
</span><span id=__span-38-5><a id=__codelineno-38-5 name=__codelineno-38-5 href=#__codelineno-38-5></a>tensor(90)
</span><span id=__span-38-6><a id=__codelineno-38-6 name=__codelineno-38-6 href=#__codelineno-38-6></a>tensor(45.)
</span><span id=__span-38-7><a id=__codelineno-38-7 name=__codelineno-38-7 href=#__codelineno-38-7></a>tensor(450)
</span><span id=__span-38-8><a id=__codelineno-38-8 name=__codelineno-38-8 href=#__codelineno-38-8></a>tensor(450)
</span></code></pre></div></p> <h3 id=_24>インデックス取得<a class=headerlink href=#_24 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1 href=#__codelineno-39-1></a><span class=c1># 最大値・最小値のインデックスを取得</span>
</span><span id=__span-39-2><a id=__codelineno-39-2 name=__codelineno-39-2 href=#__codelineno-39-2></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>argmax</span><span class=p>())</span>  <span class=c1># 最大値の位置</span>
</span><span id=__span-39-3><a id=__codelineno-39-3 name=__codelineno-39-3 href=#__codelineno-39-3></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>argmin</span><span class=p>())</span>  <span class=c1># 最小値の位置</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-40-1><a id=__codelineno-40-1 name=__codelineno-40-1 href=#__codelineno-40-1></a>tensor(9)
</span><span id=__span-40-2><a id=__codelineno-40-2 name=__codelineno-40-2 href=#__codelineno-40-2></a>tensor(0)
</span></code></pre></div></p> <h2 id=_25>テンソルの形状操作<a class=headerlink href=#_25 title="Permanent link">&para;</a></h2> <h3 id=_26>基本的な形状変更操作<a class=headerlink href=#_26 title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>メソッド</th> <th>説明</th> </tr> </thead> <tbody> <tr> <td><code>torch.reshape()</code></td> <td>互換性がある場合に形状を変更</td> </tr> <tr> <td><code>tensor.view()</code></td> <td>元のテンソルと同じデータを共有する異なる形状のビューを返す</td> </tr> <tr> <td><code>torch.stack()</code></td> <td>新しい次元でテンソルを連結</td> </tr> <tr> <td><code>torch.squeeze()</code></td> <td>サイズ1の次元を削除</td> </tr> <tr> <td><code>torch.unsqueeze()</code></td> <td>指定位置にサイズ1の次元を追加</td> </tr> <tr> <td><code>torch.permute()</code></td> <td>次元の順序を変更</td> </tr> </tbody> </table> <div class="language-python highlight"><pre><span></span><code><span id=__span-41-1><a id=__codelineno-41-1 name=__codelineno-41-1 href=#__codelineno-41-1></a><span class=c1># テンソルを作成</span>
</span><span id=__span-41-2><a id=__codelineno-41-2 name=__codelineno-41-2 href=#__codelineno-41-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>1.</span><span class=p>,</span> <span class=mf>10.</span><span class=p>)</span>
</span><span id=__span-41-3><a id=__codelineno-41-3 name=__codelineno-41-3 href=#__codelineno-41-3></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-41-4><a id=__codelineno-41-4 name=__codelineno-41-4 href=#__codelineno-41-4></a>
</span><span id=__span-41-5><a id=__codelineno-41-5 name=__codelineno-41-5 href=#__codelineno-41-5></a><span class=c1># 形状を変更</span>
</span><span id=__span-41-6><a id=__codelineno-41-6 name=__codelineno-41-6 href=#__codelineno-41-6></a><span class=n>x_reshaped</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
</span><span id=__span-41-7><a id=__codelineno-41-7 name=__codelineno-41-7 href=#__codelineno-41-7></a><span class=nb>print</span><span class=p>(</span><span class=n>x_reshaped</span><span class=p>,</span> <span class=n>x_reshaped</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-41-8><a id=__codelineno-41-8 name=__codelineno-41-8 href=#__codelineno-41-8></a>
</span><span id=__span-41-9><a id=__codelineno-41-9 name=__codelineno-41-9 href=#__codelineno-41-9></a><span class=c1># ビューを作成（データを共有）</span>
</span><span id=__span-41-10><a id=__codelineno-41-10 name=__codelineno-41-10 href=#__codelineno-41-10></a><span class=n>z</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
</span><span id=__span-41-11><a id=__codelineno-41-11 name=__codelineno-41-11 href=#__codelineno-41-11></a><span class=nb>print</span><span class=p>(</span><span class=n>z</span><span class=p>,</span> <span class=n>z</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-41-12><a id=__codelineno-41-12 name=__codelineno-41-12 href=#__codelineno-41-12></a>
</span><span id=__span-41-13><a id=__codelineno-41-13 name=__codelineno-41-13 href=#__codelineno-41-13></a><span class=c1># ビューを変更すると元のテンソルも変更される</span>
</span><span id=__span-41-14><a id=__codelineno-41-14 name=__codelineno-41-14 href=#__codelineno-41-14></a><span class=n>z</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>5</span>
</span><span id=__span-41-15><a id=__codelineno-41-15 name=__codelineno-41-15 href=#__codelineno-41-15></a><span class=nb>print</span><span class=p>(</span><span class=n>z</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-42-1><a id=__codelineno-42-1 name=__codelineno-42-1 href=#__codelineno-42-1></a>tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([9])
</span><span id=__span-42-2><a id=__codelineno-42-2 name=__codelineno-42-2 href=#__codelineno-42-2></a>tensor([[1., 2., 3.],
</span><span id=__span-42-3><a id=__codelineno-42-3 name=__codelineno-42-3 href=#__codelineno-42-3></a>        [4., 5., 6.],
</span><span id=__span-42-4><a id=__codelineno-42-4 name=__codelineno-42-4 href=#__codelineno-42-4></a>        [7., 8., 9.]]) torch.Size([3, 3])
</span><span id=__span-42-5><a id=__codelineno-42-5 name=__codelineno-42-5 href=#__codelineno-42-5></a>tensor([[1., 2., 3.],
</span><span id=__span-42-6><a id=__codelineno-42-6 name=__codelineno-42-6 href=#__codelineno-42-6></a>        [4., 5., 6.],
</span><span id=__span-42-7><a id=__codelineno-42-7 name=__codelineno-42-7 href=#__codelineno-42-7></a>        [7., 8., 9.]]) torch.Size([3, 3])
</span><span id=__span-42-8><a id=__codelineno-42-8 name=__codelineno-42-8 href=#__codelineno-42-8></a>tensor([[5., 5.],
</span><span id=__span-42-9><a id=__codelineno-42-9 name=__codelineno-42-9 href=#__codelineno-42-9></a>        [2., 2.],
</span><span id=__span-42-10><a id=__codelineno-42-10 name=__codelineno-42-10 href=#__codelineno-42-10></a>        [3., 3.],
</span><span id=__span-42-11><a id=__codelineno-42-11 name=__codelineno-42-11 href=#__codelineno-42-11></a>        [5., 5.],
</span><span id=__span-42-12><a id=__codelineno-42-12 name=__codelineno-42-12 href=#__codelineno-42-12></a>        [5., 5.],
</span><span id=__span-42-13><a id=__codelineno-42-13 name=__codelineno-42-13 href=#__codelineno-42-13></a>        [6., 6.],
</span><span id=__span-42-14><a id=__codelineno-42-14 name=__codelineno-42-14 href=#__codelineno-42-14></a>        [5., 5.],
</span><span id=__span-42-15><a id=__codelineno-42-15 name=__codelineno-42-15 href=#__codelineno-42-15></a>        [8., 8.],
</span><span id=__span-42-16><a id=__codelineno-42-16 name=__codelineno-42-16 href=#__codelineno-42-16></a>        [9., 9.]]) tensor([5., 2., 3., 5., 5., 6., 5., 8., 9.])
</span></code></pre></div></p> <h3 id=_27>スタック操作<a class=headerlink href=#_27 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-43-1><a id=__codelineno-43-1 name=__codelineno-43-1 href=#__codelineno-43-1></a><span class=c1># テンソルを積み重ねる</span>
</span><span id=__span-43-2><a id=__codelineno-43-2 name=__codelineno-43-2 href=#__codelineno-43-2></a><span class=n>x_stacked</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>x</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-43-3><a id=__codelineno-43-3 name=__codelineno-43-3 href=#__codelineno-43-3></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-43-4><a id=__codelineno-43-4 name=__codelineno-43-4 href=#__codelineno-43-4></a><span class=nb>print</span><span class=p>(</span><span class=n>x_stacked</span><span class=p>,</span> <span class=n>x_stacked</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-44-1><a id=__codelineno-44-1 name=__codelineno-44-1 href=#__codelineno-44-1></a>tensor([5., 2., 3., 5., 5., 6., 5., 8., 9.])
</span><span id=__span-44-2><a id=__codelineno-44-2 name=__codelineno-44-2 href=#__codelineno-44-2></a>tensor([[5., 5.],
</span><span id=__span-44-3><a id=__codelineno-44-3 name=__codelineno-44-3 href=#__codelineno-44-3></a>        [2., 2.],
</span><span id=__span-44-4><a id=__codelineno-44-4 name=__codelineno-44-4 href=#__codelineno-44-4></a>        [3., 3.],
</span><span id=__span-44-5><a id=__codelineno-44-5 name=__codelineno-44-5 href=#__codelineno-44-5></a>        [5., 5.],
</span><span id=__span-44-6><a id=__codelineno-44-6 name=__codelineno-44-6 href=#__codelineno-44-6></a>        [5., 5.],
</span><span id=__span-44-7><a id=__codelineno-44-7 name=__codelineno-44-7 href=#__codelineno-44-7></a>        [6., 6.],
</span><span id=__span-44-8><a id=__codelineno-44-8 name=__codelineno-44-8 href=#__codelineno-44-8></a>        [5., 5.],
</span><span id=__span-44-9><a id=__codelineno-44-9 name=__codelineno-44-9 href=#__codelineno-44-9></a>        [8., 8.],
</span><span id=__span-44-10><a id=__codelineno-44-10 name=__codelineno-44-10 href=#__codelineno-44-10></a>        [9., 9.]]) torch.Size([9, 2])
</span></code></pre></div></p> <h3 id=squeezeunsqueeze>squeeze操作とunsqueeze操作<a class=headerlink href=#squeezeunsqueeze title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-45-1><a id=__codelineno-45-1 name=__codelineno-45-1 href=#__codelineno-45-1></a><span class=c1># サイズ1の次元を削除</span>
</span><span id=__span-45-2><a id=__codelineno-45-2 name=__codelineno-45-2 href=#__codelineno-45-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-45-3><a id=__codelineno-45-3 name=__codelineno-45-3 href=#__codelineno-45-3></a><span class=n>x_squeeze</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-45-4><a id=__codelineno-45-4 name=__codelineno-45-4 href=#__codelineno-45-4></a><span class=nb>print</span><span class=p>(</span><span class=n>x_squeeze</span><span class=p>,</span> <span class=n>x_squeeze</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-46-1><a id=__codelineno-46-1 name=__codelineno-46-1 href=#__codelineno-46-1></a>tensor([[[0., 0.],
</span><span id=__span-46-2><a id=__codelineno-46-2 name=__codelineno-46-2 href=#__codelineno-46-2></a>         [0., 0.]],
</span><span id=__span-46-3><a id=__codelineno-46-3 name=__codelineno-46-3 href=#__codelineno-46-3></a>
</span><span id=__span-46-4><a id=__codelineno-46-4 name=__codelineno-46-4 href=#__codelineno-46-4></a>        [[0., 0.],
</span><span id=__span-46-5><a id=__codelineno-46-5 name=__codelineno-46-5 href=#__codelineno-46-5></a>         [0., 0.]]]) torch.Size([2, 2, 2])
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-47-1><a id=__codelineno-47-1 name=__codelineno-47-1 href=#__codelineno-47-1></a><span class=c1># 次元を追加</span>
</span><span id=__span-47-2><a id=__codelineno-47-2 name=__codelineno-47-2 href=#__codelineno-47-2></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;元のテンソル: </span><span class=si>{</span><span class=n>x_squeeze</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-47-3><a id=__codelineno-47-3 name=__codelineno-47-3 href=#__codelineno-47-3></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;元の形状: </span><span class=si>{</span><span class=n>x_squeeze</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-47-4><a id=__codelineno-47-4 name=__codelineno-47-4 href=#__codelineno-47-4></a>
</span><span id=__span-47-5><a id=__codelineno-47-5 name=__codelineno-47-5 href=#__codelineno-47-5></a><span class=n>x_unsqueezed</span> <span class=o>=</span> <span class=n>x_squeeze</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-47-6><a id=__codelineno-47-6 name=__codelineno-47-6 href=#__codelineno-47-6></a><span class=nb>print</span><span class=p>(</span><span class=n>x_unsqueezed</span><span class=p>,</span> <span class=n>x_unsqueezed</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-48-1><a id=__codelineno-48-1 name=__codelineno-48-1 href=#__codelineno-48-1></a>元のテンソル: tensor([[[0., 0.],
</span><span id=__span-48-2><a id=__codelineno-48-2 name=__codelineno-48-2 href=#__codelineno-48-2></a>         [0., 0.]],
</span><span id=__span-48-3><a id=__codelineno-48-3 name=__codelineno-48-3 href=#__codelineno-48-3></a>
</span><span id=__span-48-4><a id=__codelineno-48-4 name=__codelineno-48-4 href=#__codelineno-48-4></a>        [[0., 0.],
</span><span id=__span-48-5><a id=__codelineno-48-5 name=__codelineno-48-5 href=#__codelineno-48-5></a>         [0., 0.]]])
</span><span id=__span-48-6><a id=__codelineno-48-6 name=__codelineno-48-6 href=#__codelineno-48-6></a>元の形状: torch.Size([2, 2, 2])
</span><span id=__span-48-7><a id=__codelineno-48-7 name=__codelineno-48-7 href=#__codelineno-48-7></a>tensor([[[[0., 0.],
</span><span id=__span-48-8><a id=__codelineno-48-8 name=__codelineno-48-8 href=#__codelineno-48-8></a>          [0., 0.]]],
</span><span id=__span-48-9><a id=__codelineno-48-9 name=__codelineno-48-9 href=#__codelineno-48-9></a>
</span><span id=__span-48-10><a id=__codelineno-48-10 name=__codelineno-48-10 href=#__codelineno-48-10></a>
</span><span id=__span-48-11><a id=__codelineno-48-11 name=__codelineno-48-11 href=#__codelineno-48-11></a>        [[[0., 0.],
</span><span id=__span-48-12><a id=__codelineno-48-12 name=__codelineno-48-12 href=#__codelineno-48-12></a>          [0., 0.]]]]) torch.Size([2, 1, 2, 2])
</span></code></pre></div></p> <h3 id=_28>次元の順序変更<a class=headerlink href=#_28 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-49-1><a id=__codelineno-49-1 name=__codelineno-49-1 href=#__codelineno-49-1></a><span class=c1># 次元の順序を変更（カラー画像の例）</span>
</span><span id=__span-49-2><a id=__codelineno-49-2 name=__codelineno-49-2 href=#__codelineno-49-2></a><span class=n>x_original</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>  <span class=c1># Height, Width, Channels</span>
</span><span id=__span-49-3><a id=__codelineno-49-3 name=__codelineno-49-3 href=#__codelineno-49-3></a><span class=n>x_permuted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=n>x_original</span><span class=p>,</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>  <span class=c1># Channels, Height, Width</span>
</span><span id=__span-49-4><a id=__codelineno-49-4 name=__codelineno-49-4 href=#__codelineno-49-4></a><span class=nb>print</span><span class=p>(</span><span class=n>x_permuted</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-49-5><a id=__codelineno-49-5 name=__codelineno-49-5 href=#__codelineno-49-5></a><span class=nb>print</span><span class=p>(</span><span class=n>x_original</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-49-6><a id=__codelineno-49-6 name=__codelineno-49-6 href=#__codelineno-49-6></a>
</span><span id=__span-49-7><a id=__codelineno-49-7 name=__codelineno-49-7 href=#__codelineno-49-7></a><span class=c1># ビューなので同じメモリを共有</span>
</span><span id=__span-49-8><a id=__codelineno-49-8 name=__codelineno-49-8 href=#__codelineno-49-8></a><span class=n>x_permuted</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>2222</span>
</span><span id=__span-49-9><a id=__codelineno-49-9 name=__codelineno-49-9 href=#__codelineno-49-9></a><span class=nb>print</span><span class=p>(</span><span class=n>x_original</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>x_permuted</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-50-1><a id=__codelineno-50-1 name=__codelineno-50-1 href=#__codelineno-50-1></a>torch.Size([3, 224, 224])
</span><span id=__span-50-2><a id=__codelineno-50-2 name=__codelineno-50-2 href=#__codelineno-50-2></a>torch.Size([224, 224, 3])
</span><span id=__span-50-3><a id=__codelineno-50-3 name=__codelineno-50-3 href=#__codelineno-50-3></a>tensor(2222.) tensor(2222.)
</span></code></pre></div></p> <h2 id=_29>テンソルインデックス<a class=headerlink href=#_29 title="Permanent link">&para;</a></h2> <div class="language-python highlight"><pre><span></span><code><span id=__span-51-1><a id=__codelineno-51-1 name=__codelineno-51-1 href=#__codelineno-51-1></a><span class=c1># テンソルを作成</span>
</span><span id=__span-51-2><a id=__codelineno-51-2 name=__codelineno-51-2 href=#__codelineno-51-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
</span><span id=__span-51-3><a id=__codelineno-51-3 name=__codelineno-51-3 href=#__codelineno-51-3></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-51-4><a id=__codelineno-51-4 name=__codelineno-51-4 href=#__codelineno-51-4></a>
</span><span id=__span-51-5><a id=__codelineno-51-5 name=__codelineno-51-5 href=#__codelineno-51-5></a><span class=c1># インデックスによるアクセス</span>
</span><span id=__span-51-6><a id=__codelineno-51-6 name=__codelineno-51-6 href=#__codelineno-51-6></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>          <span class=c1># 最初の次元</span>
</span><span id=__span-51-7><a id=__codelineno-51-7 name=__codelineno-51-7 href=#__codelineno-51-7></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>       <span class=c1># 最初の行</span>
</span><span id=__span-51-8><a id=__codelineno-51-8 name=__codelineno-51-8 href=#__codelineno-51-8></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>    <span class=c1># 特定の要素</span>
</span><span id=__span-51-9><a id=__codelineno-51-9 name=__codelineno-51-9 href=#__codelineno-51-9></a>
</span><span id=__span-51-10><a id=__codelineno-51-10 name=__codelineno-51-10 href=#__codelineno-51-10></a><span class=c1># スライス記法</span>
</span><span id=__span-51-11><a id=__codelineno-51-11 name=__codelineno-51-11 href=#__codelineno-51-11></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>,</span> <span class=p>:])</span>    <span class=c1># すべての0番目の行</span>
</span><span id=__span-51-12><a id=__codelineno-51-12 name=__codelineno-51-12 href=#__codelineno-51-12></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>])</span>    <span class=c1># すべての0番目の列</span>
</span><span id=__span-51-13><a id=__codelineno-51-13 name=__codelineno-51-13 href=#__codelineno-51-13></a><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>    <span class=c1># 特定の位置の要素</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-52-1><a id=__codelineno-52-1 name=__codelineno-52-1 href=#__codelineno-52-1></a>tensor([[[1, 2, 3],
</span><span id=__span-52-2><a id=__codelineno-52-2 name=__codelineno-52-2 href=#__codelineno-52-2></a>         [4, 5, 6],
</span><span id=__span-52-3><a id=__codelineno-52-3 name=__codelineno-52-3 href=#__codelineno-52-3></a>         [7, 8, 9]]]) torch.Size([1, 3, 3])
</span><span id=__span-52-4><a id=__codelineno-52-4 name=__codelineno-52-4 href=#__codelineno-52-4></a>tensor([[1, 2, 3],
</span><span id=__span-52-5><a id=__codelineno-52-5 name=__codelineno-52-5 href=#__codelineno-52-5></a>        [4, 5, 6],
</span><span id=__span-52-6><a id=__codelineno-52-6 name=__codelineno-52-6 href=#__codelineno-52-6></a>        [7, 8, 9]])
</span><span id=__span-52-7><a id=__codelineno-52-7 name=__codelineno-52-7 href=#__codelineno-52-7></a>tensor([1, 2, 3])
</span><span id=__span-52-8><a id=__codelineno-52-8 name=__codelineno-52-8 href=#__codelineno-52-8></a>tensor(1)
</span><span id=__span-52-9><a id=__codelineno-52-9 name=__codelineno-52-9 href=#__codelineno-52-9></a>tensor([[1, 2, 3]])
</span><span id=__span-52-10><a id=__codelineno-52-10 name=__codelineno-52-10 href=#__codelineno-52-10></a>tensor([[1, 4, 7]])
</span><span id=__span-52-11><a id=__codelineno-52-11 name=__codelineno-52-11 href=#__codelineno-52-11></a>tensor([1])
</span></code></pre></div></p> <h2 id=pytorchnumpy>PyTorchテンソルとNumPy<a class=headerlink href=#pytorchnumpy title="Permanent link">&para;</a></h2> <p>PyTorchとNumPyは相互運用性に優れており、簡単に変換できます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-53-1><a id=__codelineno-53-1 name=__codelineno-53-1 href=#__codelineno-53-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-53-2><a id=__codelineno-53-2 name=__codelineno-53-2 href=#__codelineno-53-2></a>
</span><span id=__span-53-3><a id=__codelineno-53-3 name=__codelineno-53-3 href=#__codelineno-53-3></a><span class=c1># NumPy配列からPyTorchテンソルへ</span>
</span><span id=__span-53-4><a id=__codelineno-53-4 name=__codelineno-53-4 href=#__codelineno-53-4></a><span class=n>array</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>8.0</span><span class=p>)</span>
</span><span id=__span-53-5><a id=__codelineno-53-5 name=__codelineno-53-5 href=#__codelineno-53-5></a><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>array</span><span class=p>)</span><span class=o>.</span><span class=n>type</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span><span id=__span-53-6><a id=__codelineno-53-6 name=__codelineno-53-6 href=#__codelineno-53-6></a><span class=nb>print</span><span class=p>(</span><span class=n>array</span><span class=o>.</span><span class=n>dtype</span><span class=p>)</span>
</span><span id=__span-53-7><a id=__codelineno-53-7 name=__codelineno-53-7 href=#__codelineno-53-7></a><span class=nb>print</span><span class=p>(</span><span class=n>array</span><span class=p>,</span> <span class=n>tensor</span><span class=p>,</span> <span class=n>tensor</span><span class=o>.</span><span class=n>dtype</span><span class=p>)</span>
</span><span id=__span-53-8><a id=__codelineno-53-8 name=__codelineno-53-8 href=#__codelineno-53-8></a>
</span><span id=__span-53-9><a id=__codelineno-53-9 name=__codelineno-53-9 href=#__codelineno-53-9></a><span class=c1># 配列を変更（新しいオブジェクトを作成）</span>
</span><span id=__span-53-10><a id=__codelineno-53-10 name=__codelineno-53-10 href=#__codelineno-53-10></a><span class=n>array</span> <span class=o>=</span> <span class=n>array</span> <span class=o>*</span> <span class=mi>10</span>
</span><span id=__span-53-11><a id=__codelineno-53-11 name=__codelineno-53-11 href=#__codelineno-53-11></a><span class=nb>print</span><span class=p>(</span><span class=n>array</span><span class=p>,</span> <span class=n>tensor</span><span class=p>)</span>  <span class=c1># tensorは変更されない</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-54-1><a id=__codelineno-54-1 name=__codelineno-54-1 href=#__codelineno-54-1></a>float64
</span><span id=__span-54-2><a id=__codelineno-54-2 name=__codelineno-54-2 href=#__codelineno-54-2></a>[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.]) torch.float32
</span><span id=__span-54-3><a id=__codelineno-54-3 name=__codelineno-54-3 href=#__codelineno-54-3></a>[10. 20. 30. 40. 50. 60. 70.] tensor([1., 2., 3., 4., 5., 6., 7.])
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-55-1><a id=__codelineno-55-1 name=__codelineno-55-1 href=#__codelineno-55-1></a><span class=c1># PyTorchテンソルからNumPy配列へ</span>
</span><span id=__span-55-2><a id=__codelineno-55-2 name=__codelineno-55-2 href=#__codelineno-55-2></a><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>8</span><span class=p>)</span>
</span><span id=__span-55-3><a id=__codelineno-55-3 name=__codelineno-55-3 href=#__codelineno-55-3></a><span class=n>numpy_tensor</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span><span id=__span-55-4><a id=__codelineno-55-4 name=__codelineno-55-4 href=#__codelineno-55-4></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>numpy_tensor</span><span class=p>,</span> <span class=n>numpy_tensor</span><span class=o>.</span><span class=n>dtype</span><span class=p>)</span>
</span><span id=__span-55-5><a id=__codelineno-55-5 name=__codelineno-55-5 href=#__codelineno-55-5></a>
</span><span id=__span-55-6><a id=__codelineno-55-6 name=__codelineno-55-6 href=#__codelineno-55-6></a><span class=c1># テンソルを変更（新しいオブジェクトを作成）</span>
</span><span id=__span-55-7><a id=__codelineno-55-7 name=__codelineno-55-7 href=#__codelineno-55-7></a><span class=n>tensor</span> <span class=o>=</span> <span class=n>tensor</span> <span class=o>*</span> <span class=mi>10</span>
</span><span id=__span-55-8><a id=__codelineno-55-8 name=__codelineno-55-8 href=#__codelineno-55-8></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>numpy_tensor</span><span class=p>)</span>  <span class=c1># numpy_tensorは変更されない</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-56-1><a id=__codelineno-56-1 name=__codelineno-56-1 href=#__codelineno-56-1></a>tensor([1., 1., 1., 1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1. 1. 1. 1.] float32
</span><span id=__span-56-2><a id=__codelineno-56-2 name=__codelineno-56-2 href=#__codelineno-56-2></a>tensor([10., 10., 10., 10., 10., 10., 10., 10.]) [1. 1. 1. 1. 1. 1. 1. 1.]
</span></code></pre></div></p> <h2 id=_30>再現性の確保<a class=headerlink href=#_30 title="Permanent link">&para;</a></h2> <p>機械学習実験では再現性が重要です。<code>torch.manual_seed()</code>を使用してランダム性を制御できます。</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-57-1><a id=__codelineno-57-1 name=__codelineno-57-1 href=#__codelineno-57-1></a><span class=c1># 再現性なしの例</span>
</span><span id=__span-57-2><a id=__codelineno-57-2 name=__codelineno-57-2 href=#__codelineno-57-2></a><span class=n>random_tensor_A</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-57-3><a id=__codelineno-57-3 name=__codelineno-57-3 href=#__codelineno-57-3></a><span class=n>random_tensor_B</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-57-4><a id=__codelineno-57-4 name=__codelineno-57-4 href=#__codelineno-57-4></a>
</span><span id=__span-57-5><a id=__codelineno-57-5 name=__codelineno-57-5 href=#__codelineno-57-5></a><span class=nb>print</span><span class=p>(</span><span class=n>random_tensor_A</span><span class=p>)</span>
</span><span id=__span-57-6><a id=__codelineno-57-6 name=__codelineno-57-6 href=#__codelineno-57-6></a><span class=nb>print</span><span class=p>(</span><span class=n>random_tensor_B</span><span class=p>)</span>
</span><span id=__span-57-7><a id=__codelineno-57-7 name=__codelineno-57-7 href=#__codelineno-57-7></a><span class=nb>print</span><span class=p>(</span><span class=n>random_tensor_A</span> <span class=o>==</span> <span class=n>random_tensor_B</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-58-1><a id=__codelineno-58-1 name=__codelineno-58-1 href=#__codelineno-58-1></a>tensor([[0.4391, 0.6196, 0.7505, 0.7156],
</span><span id=__span-58-2><a id=__codelineno-58-2 name=__codelineno-58-2 href=#__codelineno-58-2></a>        [0.9042, 0.2950, 0.4127, 0.0252],
</span><span id=__span-58-3><a id=__codelineno-58-3 name=__codelineno-58-3 href=#__codelineno-58-3></a>        [0.5446, 0.3252, 0.6805, 0.1873]])
</span><span id=__span-58-4><a id=__codelineno-58-4 name=__codelineno-58-4 href=#__codelineno-58-4></a>tensor([[0.2874, 0.8757, 0.1099, 0.1557],
</span><span id=__span-58-5><a id=__codelineno-58-5 name=__codelineno-58-5 href=#__codelineno-58-5></a>        [0.6750, 0.5061, 0.6277, 0.4129],
</span><span id=__span-58-6><a id=__codelineno-58-6 name=__codelineno-58-6 href=#__codelineno-58-6></a>        [0.6435, 0.6629, 0.5479, 0.1246]])
</span><span id=__span-58-7><a id=__codelineno-58-7 name=__codelineno-58-7 href=#__codelineno-58-7></a>tensor([[False, False, False, False],
</span><span id=__span-58-8><a id=__codelineno-58-8 name=__codelineno-58-8 href=#__codelineno-58-8></a>        [False, False, False, False],
</span><span id=__span-58-9><a id=__codelineno-58-9 name=__codelineno-58-9 href=#__codelineno-58-9></a>        [False, False, False, False]])
</span></code></pre></div></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-59-1><a id=__codelineno-59-1 name=__codelineno-59-1 href=#__codelineno-59-1></a><span class=c1># 再現性ありの例</span>
</span><span id=__span-59-2><a id=__codelineno-59-2 name=__codelineno-59-2 href=#__codelineno-59-2></a><span class=n>RANDOM_SEED</span> <span class=o>=</span> <span class=mi>42</span>
</span><span id=__span-59-3><a id=__codelineno-59-3 name=__codelineno-59-3 href=#__codelineno-59-3></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>RANDOM_SEED</span><span class=p>)</span>
</span><span id=__span-59-4><a id=__codelineno-59-4 name=__codelineno-59-4 href=#__codelineno-59-4></a><span class=n>random_tensor_C</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-59-5><a id=__codelineno-59-5 name=__codelineno-59-5 href=#__codelineno-59-5></a><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>RANDOM_SEED</span><span class=p>)</span>
</span><span id=__span-59-6><a id=__codelineno-59-6 name=__codelineno-59-6 href=#__codelineno-59-6></a><span class=n>random_tensor_D</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span><span id=__span-59-7><a id=__codelineno-59-7 name=__codelineno-59-7 href=#__codelineno-59-7></a>
</span><span id=__span-59-8><a id=__codelineno-59-8 name=__codelineno-59-8 href=#__codelineno-59-8></a><span class=nb>print</span><span class=p>(</span><span class=n>random_tensor_C</span><span class=p>)</span>
</span><span id=__span-59-9><a id=__codelineno-59-9 name=__codelineno-59-9 href=#__codelineno-59-9></a><span class=nb>print</span><span class=p>(</span><span class=n>random_tensor_D</span><span class=p>)</span>
</span><span id=__span-59-10><a id=__codelineno-59-10 name=__codelineno-59-10 href=#__codelineno-59-10></a><span class=nb>print</span><span class=p>(</span><span class=n>random_tensor_C</span> <span class=o>==</span> <span class=n>random_tensor_D</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-60-1><a id=__codelineno-60-1 name=__codelineno-60-1 href=#__codelineno-60-1></a>tensor([[0.8823, 0.9150, 0.3829, 0.9593],
</span><span id=__span-60-2><a id=__codelineno-60-2 name=__codelineno-60-2 href=#__codelineno-60-2></a>        [0.3904, 0.6009, 0.2566, 0.7936],
</span><span id=__span-60-3><a id=__codelineno-60-3 name=__codelineno-60-3 href=#__codelineno-60-3></a>        [0.9408, 0.1332, 0.9346, 0.5936]])
</span><span id=__span-60-4><a id=__codelineno-60-4 name=__codelineno-60-4 href=#__codelineno-60-4></a>tensor([[0.8823, 0.9150, 0.3829, 0.9593],
</span><span id=__span-60-5><a id=__codelineno-60-5 name=__codelineno-60-5 href=#__codelineno-60-5></a>        [0.3904, 0.6009, 0.2566, 0.7936],
</span><span id=__span-60-6><a id=__codelineno-60-6 name=__codelineno-60-6 href=#__codelineno-60-6></a>        [0.9408, 0.1332, 0.9346, 0.5936]])
</span><span id=__span-60-7><a id=__codelineno-60-7 name=__codelineno-60-7 href=#__codelineno-60-7></a>tensor([[True, True, True, True],
</span><span id=__span-60-8><a id=__codelineno-60-8 name=__codelineno-60-8 href=#__codelineno-60-8></a>        [True, True, True, True],
</span><span id=__span-60-9><a id=__codelineno-60-9 name=__codelineno-60-9 href=#__codelineno-60-9></a>        [True, True, True, True]])
</span></code></pre></div></p> <h2 id=gpumps>GPU（MPS）での高速計算<a class=headerlink href=#gpumps title="Permanent link">&para;</a></h2> <h3 id=_31>デバイス設定<a class=headerlink href=#_31 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-61-1><a id=__codelineno-61-1 name=__codelineno-61-1 href=#__codelineno-61-1></a><span class=c1># Apple Silicon Mac用のMPSデバイス設定</span>
</span><span id=__span-61-2><a id=__codelineno-61-2 name=__codelineno-61-2 href=#__codelineno-61-2></a><span class=n>device</span> <span class=o>=</span> <span class=s2>&quot;mps&quot;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&quot;cpu&quot;</span>
</span><span id=__span-61-3><a id=__codelineno-61-3 name=__codelineno-61-3 href=#__codelineno-61-3></a><span class=nb>print</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-62-1><a id=__codelineno-62-1 name=__codelineno-62-1 href=#__codelineno-62-1></a>mps
</span></code></pre></div></p> <h3 id=gpu>テンソルのGPU移動<a class=headerlink href=#gpu title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-63-1><a id=__codelineno-63-1 name=__codelineno-63-1 href=#__codelineno-63-1></a><span class=c1># CPUテンソルを作成</span>
</span><span id=__span-63-2><a id=__codelineno-63-2 name=__codelineno-63-2 href=#__codelineno-63-2></a><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
</span><span id=__span-63-3><a id=__codelineno-63-3 name=__codelineno-63-3 href=#__codelineno-63-3></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>tensor</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-63-4><a id=__codelineno-63-4 name=__codelineno-63-4 href=#__codelineno-63-4></a>
</span><span id=__span-63-5><a id=__codelineno-63-5 name=__codelineno-63-5 href=#__codelineno-63-5></a><span class=c1># MPSデバイスに移動</span>
</span><span id=__span-63-6><a id=__codelineno-63-6 name=__codelineno-63-6 href=#__codelineno-63-6></a><span class=n>tensor_on_gpu</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-63-7><a id=__codelineno-63-7 name=__codelineno-63-7 href=#__codelineno-63-7></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor_on_gpu</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-64-1><a id=__codelineno-64-1 name=__codelineno-64-1 href=#__codelineno-64-1></a>tensor([1, 2, 3]) cpu
</span><span id=__span-64-2><a id=__codelineno-64-2 name=__codelineno-64-2 href=#__codelineno-64-2></a>tensor([1, 2, 3], device=&#39;mps:0&#39;)
</span></code></pre></div></p> <h3 id=gpucpu>GPU→CPU変換<a class=headerlink href=#gpucpu title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-65-1><a id=__codelineno-65-1 name=__codelineno-65-1 href=#__codelineno-65-1></a><span class=c1># NumPyはGPUを直接サポートしないため、CPUに戻す必要がある</span>
</span><span id=__span-65-2><a id=__codelineno-65-2 name=__codelineno-65-2 href=#__codelineno-65-2></a><span class=c1># tensor_on_gpu.numpy()  # これはエラーになる</span>
</span><span id=__span-65-3><a id=__codelineno-65-3 name=__codelineno-65-3 href=#__codelineno-65-3></a>
</span><span id=__span-65-4><a id=__codelineno-65-4 name=__codelineno-65-4 href=#__codelineno-65-4></a><span class=c1># CPUに戻してからNumPy配列に変換</span>
</span><span id=__span-65-5><a id=__codelineno-65-5 name=__codelineno-65-5 href=#__codelineno-65-5></a><span class=n>tensor_back_on_cpu</span> <span class=o>=</span> <span class=n>tensor_on_gpu</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span><span id=__span-65-6><a id=__codelineno-65-6 name=__codelineno-65-6 href=#__codelineno-65-6></a><span class=nb>print</span><span class=p>(</span><span class=n>tensor_back_on_cpu</span><span class=p>)</span>
</span></code></pre></div> <p><strong>実行結果:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-66-1><a id=__codelineno-66-1 name=__codelineno-66-1 href=#__codelineno-66-1></a>[1 2 3]
</span></code></pre></div></p> <h2 id=_32>まとめ<a class=headerlink href=#_32 title="Permanent link">&para;</a></h2> <p>この記事では、PyTorchテンソルの基礎から応用までを学習しました。</p> <h3 id=_33>重要なポイント<a class=headerlink href=#_33 title="Permanent link">&para;</a></h3> <ol> <li><strong>テンソルの種類</strong>: スカラー、ベクトル、行列、高次元テンソル</li> <li><strong>基本操作</strong>: 作成、演算、形状変更、インデックス</li> <li><strong>行列乗算</strong>: 深層学習の核となる重要な演算</li> <li><strong>デバイス管理</strong>: CPU/GPU間でのテンソル移動</li> <li><strong>再現性</strong>: 実験の信頼性確保</li> </ol> <h2 id=_34>参考資料<a class=headerlink href=#_34 title="Permanent link">&para;</a></h2> <h3 id=_35>公式ドキュメント<a class=headerlink href=#_35 title="Permanent link">&para;</a></h3> <ul> <li><a href=https://docs.pytorch.org/stable/tensors.html>PyTorch公式テンソルドキュメント</a></li> <li><a href=https://docs.pytorch.org/stable/torch.html>PyTorch基本操作ガイド</a></li> </ul> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title=最終更新日> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年9月28日 19:08:34 JST">2025年9月28日 19:08:34</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> ページトップへ戻る </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 - 2025 vinsmoke-three </div> </div> <div class=md-social> <a href=https://github.com/vinsmoke-three target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": {"BERT": "bert", "CNN": "convolutional-neural-network", "FashionMNIST": "fashion-mnist", "GPT": "gpt", "LLM": "large-language-model", "ML\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3": "ml-pipeline", "NLP": "nlp", "PyTorch": "pytorch", "Python": "python", "TensorBoard": "tensorboard", "TinyVGG": "tinyvgg", "Transformer": "transformer", "\u30ab\u30b9\u30bf\u30e0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8": "custom-datasets", "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3": "computer-vision", "\u30b9\u30af\u30ea\u30d7\u30c8\u30e2\u30fc\u30c9": "script-mode", "\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb": "tutorial", "\u30c6\u30f3\u30bd\u30eb": "tensor", "\u30c7\u30fc\u30bf\u62e1\u5f35": "data-augmentation", "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af": "neural-network", "\u30e2\u30b8\u30e5\u30fc\u30eb\u5316": "modularization", "\u30ef\u30fc\u30af\u30d5\u30ed\u30fc": "workflow", "\u4e0a\u7d1a\u8005\u5411\u3051": "advanced", "\u4e2d\u7d1a\u8005\u5411\u3051": "intermediate", "\u518d\u5229\u7528": "reusability", "\u5206\u985e": "classification", "\u521d\u5fc3\u8005\u5411\u3051": "beginner", "\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb": "large-language-model", "\u5b9f\u8df5": "practical", "\u5b9f\u9a13\u8ffd\u8de1": "experiment-tracking", "\u6a5f\u68b0\u5b66\u7fd2": "machine-learning", "\u6df1\u5c64\u5b66\u7fd2": "deep-learning", "\u753b\u50cf\u5206\u985e": "image-classification", "\u7dda\u5f62\u56de\u5e30": "linear-regression", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406": "natural-language-processing", "\u8ee2\u79fb\u5b66\u7fd2": "transfer-learning"}, "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}, "version": null}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/meta.js></script> <script src=../../javascripts/structured-data.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>