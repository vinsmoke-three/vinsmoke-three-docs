---
title: "SQuADè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ - BERTãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œå…¨ã‚¬ã‚¤ãƒ‰"
description: "BERTãƒ¢ãƒ‡ãƒ«ã‚’SQuADãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€é«˜ç²¾åº¦ãªè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’è©³ç´°ã«è§£èª¬ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€è©•ä¾¡ã¾ã§å®Œå…¨ã‚«ãƒãƒ¼ã€‚"
date: "2025-01-15"
tags: ["æ©Ÿæ¢°å­¦ç¿’", "è‡ªç„¶è¨€èªå‡¦ç†", "BERT", "è³ªå•å¿œç­”", "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", "SQuAD", "transformers"]
---

# SQuADè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ - BERTãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œå…¨ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

ã“ã®è¨˜äº‹ã§ã¯ã€BERTãƒ¢ãƒ‡ãƒ«ã‚’SQuADãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€é«˜ç²¾åº¦ãªè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’è§£èª¬ã—ã¾ã™ã€‚è³ªå•å¿œç­”ï¼ˆQuestion Answeringï¼‰ã¯è‡ªç„¶è¨€èªå‡¦ç†ã®é‡è¦ãªã‚¿ã‚¹ã‚¯ã®ä¸€ã¤ã§ã€æ–‡æ›¸ã‹ã‚‰è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆã‚’æŠ½å‡ºã™ã‚‹æŠ€è¡“ã§ã™ã€‚

!!! info "å‚è€ƒè³‡æ–™"
    æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ [Hugging Face LLM Course](https://huggingface.co/learn/llm-course/chapter7/7) ã‚’å‚è€ƒã«ã€æ—¥æœ¬èªã§å­¦ç¿’å†…å®¹ã‚’ã¾ã¨ã‚ãŸå€‹äººçš„ãªå­¦ç¿’ãƒãƒ¼ãƒˆã§ã™ã€‚è©³ç´°ãªå†…å®¹ã‚„æœ€æ–°æƒ…å ±ã«ã¤ã„ã¦ã¯ã€åŸæ–‡ã‚‚ä½µã›ã¦ã”å‚ç…§ãã ã•ã„ã€‚

## å‰æçŸ¥è­˜

- PythonåŸºç¤ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°
- æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬æ¦‚å¿µ
- transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
- PyTorchã®åŸºç¤çŸ¥è­˜

## è³ªå•å¿œç­”ã¨ã¯

è³ªå•å¿œç­”ã«ã¯ã•ã¾ã–ã¾ãªå½¢å¼ãŒã‚ã‚Šã¾ã™ãŒã€ã“ã®è¨˜äº‹ã§ã¯**æŠ½å‡ºå‹è³ªå•å¿œç­”**ï¼ˆextractive question answeringï¼‰ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚ã“ã‚Œã¯ã€æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã—ã€ãã®ç­”ãˆã‚’æ–‡æ›¸å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒ‘ãƒ³ã¨ã—ã¦ç‰¹å®šã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚

ç§ãŸã¡ã¯[SQuAD dataset](https://rajpurkar.github.io/SQuAD-explorer/)ã§BERTãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚SQuADã¯ã€Wikipediaè¨˜äº‹ã«å¯¾ã—ã¦ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒä½œæˆã—ãŸè³ªå•ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

## ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

æŠ½å‡ºå‹è³ªå•å¿œç­”ã®å­¦è¡“ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦æœ€ã‚‚ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã®ã¯[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)ãªã®ã§ã€ä»Šå›ã¯ã“ã‚Œã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã‚ˆã‚Šå›°é›£ãª[SQuAD v2](https://huggingface.co/datasets/rajpurkar/squad_v2)ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚‚ã‚ã‚Šã€ã“ã‚Œã«ã¯ç­”ãˆãŒå­˜åœ¨ã—ãªã„è³ªå•ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

### SQuADãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿

`load_dataset()`ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç°¡å˜ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã¾ã™ï¼š

```python
from datasets import load_dataset

raw_datasets = load_dataset("rajpurkar/squad_v2")
```

**å®Ÿè¡Œçµæœ:**
```
DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 130319
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 11873
    })
})
```

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹é€ ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
raw_datasets
```

**å®Ÿè¡Œçµæœ:**
```
DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 130319
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 11873
    })
})
```

å¿…è¦ãª`context`ã€`question`ã€`answers`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã™ã¹ã¦æƒã£ã¦ã„ã¾ã™ã€‚è¨“ç·´ã‚»ãƒƒãƒˆã®æœ€åˆã®è¦ç´ ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
print("Context: ", raw_datasets["train"][0]["context"])
print("Question: ", raw_datasets["train"][0]["question"])
print("Answer: ", raw_datasets["train"][0]["answers"])
```

**å®Ÿè¡Œçµæœ:**
```
Context:  BeyoncÃƒÂ© Giselle Knowles-Carter (/biÃ‹Ã‹Ë†jÃ‰'nseÃ‰Âª/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of BeyoncÃƒÂ©'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles "Crazy in Love" and "Baby Boy".
Question:  When did Beyonce start becoming popular?
Answer:  {'text': ['in the late 1990s'], 'answer_start': [269]}
```

`context`ã¨`question`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ç›´æ„Ÿçš„ã§ã™ã€‚`answers`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å°‘ã—è¤‡é›‘ã§ã€ã©ã¡ã‚‰ã‚‚ãƒªã‚¹ãƒˆã§ã‚ã‚‹2ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤è¾æ›¸å½¢å¼ã«ãªã£ã¦ã„ã¾ã™ã€‚`text`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯æ˜ç¢ºã§ã€`answer_start`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯æ–‡è„ˆå†…ã§ã®å„ç­”ãˆã®é–‹å§‹æ–‡å­—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

SQuAD2.0ã§ã¯ã€SQuAD1.1ã®10ä¸‡å•ã«åŠ ãˆã¦ã€5ä¸‡å•ä»¥ä¸Šã®ç­”ãˆã®ãªã„è³ªå•ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã€ç­”ãˆã®ã‚ã‚‹è³ªå•ã«ä¼¼ã›ã¦ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒä½œæˆã—ãŸå¯¾æŠ—çš„ãªè³ªå•ã§ã™ã€‚

ç­”ãˆã®ãªã„è³ªå•ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
unanswerable = raw_datasets["train"].filter(lambda x: len(x["answers"]["text"]) != 1)
```

```python
unanswerable[0]
```

**å®Ÿè¡Œçµæœ:**
```
{'id': '5a8d7bf7df8bba001a0f9ab1',
 'title': 'The_Legend_of_Zelda:_Twilight_Princess',
 'context': 'The Legend of Zelda: Twilight Princess (Japanese: ã‚¼ãƒ«ãƒ€ã®ä¼èª¬ ãƒˆãƒ¯ã‚¤ãƒ©ã‚¤ãƒˆãƒ—ãƒªãƒ³ã‚»ã‚¹, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]',
 'question': 'What category of game is Legend of Zelda: Australia Twilight?',
 'answers': {'text': [], 'answer_start': []}}
```

è©•ä¾¡æ™‚ã«ã¯ã€å„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦è¤‡æ•°ã®æ­£è§£ãŒå­˜åœ¨ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼š

```python
print(raw_datasets["validation"][132]["answers"])
print(raw_datasets["validation"][3]["answers"])
```

**å®Ÿè¡Œçµæœ:**
```
{'text': ['1018', '1064', '1018'], 'answer_start': [221, 345, 221]}
{'text': ['Rollo', 'Rollo', 'Rollo', 'Rollo'], 'answer_start': [308, 308, 308, 308]}
```

ä¾‹ã¨ã—ã¦ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹132ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
print(raw_datasets["validation"][132]["context"])
print(raw_datasets["validation"][132]["question"])
```

**å®Ÿè¡Œçµæœ:**
```
The legendary religious zeal of the Normans was exercised in religious wars long before the First Crusade carved out a Norman principality in Antioch. They were major foreign participants in the Reconquista in Iberia. In 1018, Roger de Tosny travelled to the Iberian Peninsula to carve out a state for himself from Moorish lands, but failed. In 1064, during the War of Barbastro, William of Montreuil led the papal army and took a huge booty.
What year did Roger de Tosny fail to accomplish what he set out to do?
```

## è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚æœ€ã‚‚é‡è¦ãªå‡¦ç†ã¯ã€è³ªå•ã®ç­”ãˆã®ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯ã€æ–‡è„ˆå†…ã§ç­”ãˆã«å¯¾å¿œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®é–‹å§‹ä½ç½®ã¨çµ‚äº†ä½ç½®ã«ãªã‚Šã¾ã™ã€‚

ã¾ãšã€tokenizerã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã§ãã‚‹IDã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```python
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

BERTãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ãŒã€é«˜é€ŸtokenizerãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚`is_fast`å±æ€§ã‚’ç¢ºèªã—ã¦ã€tokenizerãŒå®Ÿéš›ã«ğŸ¤— Tokenizersã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã§ãã¾ã™ï¼š

```python
tokenizer.is_fast
```

**å®Ÿè¡Œçµæœ:**
```
True
```

tokenizerã«è³ªå•ã¨æ–‡è„ˆã‚’ä¸€ç·’ã«æ¸¡ã™ã“ã¨ã§ã€é©åˆ‡ãªç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ¿å…¥ã•ã‚ŒãŸä»¥ä¸‹ã®ã‚ˆã†ãªæ–‡ãŒå½¢æˆã•ã‚Œã¾ã™ï¼š

```
[CLS] question [SEP] context [SEP]
```

```python
context = raw_datasets["train"][0]["context"]
question = raw_datasets["train"][0]["question"]

inputs = tokenizer(question, context)
tokenizer.decode(inputs["input_ids"])
```

**å®Ÿè¡Œçµæœ:**
```
'[CLS] When did Beyonce start becoming popular? [SEP] BeyoncÃƒÂ© Giselle Knowles - Carter ( / [UNK] / bee - YON - say ) ( born September 4, 1981 ) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R & B girl - group Destiny \' s Child. Managed by her father, Mathew Knowles, the group became one of the world \' s best - selling girl groups of all time. Their hiatus saw the release of BeyoncÃƒÂ© \' s debut album, Dangerously in Love ( 2003 ), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number - one singles " Crazy in Love " and " Baby Boy ". [SEP]'
```

### é•·ã„æ–‡è„ˆã¸ã®å¯¾å¿œ

ã“ã®ä¾‹ã§ã¯æ–‡è„ˆã¯é•·ã™ãã¾ã›ã‚“ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ä¸€éƒ¨ã®ä¾‹ã§ã¯ã€è¨­å®šã—ãŸæœ€å¤§é•·ï¼ˆã“ã“ã§ã¯384ï¼‰ã‚’è¶…ãˆã‚‹éå¸¸ã«é•·ã„æ–‡è„ˆãŒã‚ã‚Šã¾ã™ã€‚é•·ã„æ–‡è„ˆã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½¿ç”¨ã—ã¦1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰è¤‡æ•°ã®è¨“ç·´ç‰¹å¾´ã‚’ä½œæˆã—ã¾ã™ã€‚

ç¾åœ¨ã®ä¾‹ã‚’ä½¿ã£ã¦ã€é•·ã•ã‚’100ã«åˆ¶é™ã—ã€50ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True
)

for ids in inputs["input_ids"]:
    print(tokenizer.decode(ids))
```

**å®Ÿè¡Œçµæœ:**
```
[CLS] When did Beyonce start becoming popular? [SEP] BeyoncÃƒÂ© Giselle Knowles - Carter ( / [UNK] / bee - YON - say ) ( born September 4, 1981 ) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R & B girl - group Destiny ' s Child. Managed by her father, Mathew Knowles [SEP]
[CLS] When did Beyonce start becoming popular? [SEP] raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R & B girl - group Destiny ' s Child. Managed by her father, Mathew Knowles, the group became one of the world ' s best - selling girl groups of all time. Their hiatus saw the release of BeyoncÃƒÂ© ' s debut album, Dangerously in Love ( 2003 ) [SEP]
[CLS] When did Beyonce start becoming popular? [SEP] s Child. Managed by her father, Mathew Knowles, the group became one of the world ' s best - selling girl groups of all time. Their hiatus saw the release of BeyoncÃƒÂ© ' s debut album, Dangerously in Love ( 2003 ), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number - one singles " Crazy in Love " and " Baby Boy ". [SEP]
```

ä¾‹ãŒ4ã¤ã®å…¥åŠ›ã«åˆ†å‰²ã•ã‚Œã€ãã‚Œãã‚ŒãŒè³ªå•ã¨æ–‡è„ˆã®ä¸€éƒ¨ã‚’å«ã‚“ã§ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ç­”ãˆãŒæ–‡è„ˆã«å®Œå…¨ã«å«ã¾ã‚Œãªã„å ´åˆã¯ã€ãƒ©ãƒ™ãƒ«ã‚’`start_position = end_position = 0`ï¼ˆ`[CLS]`ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ï¼‰ã«è¨­å®šã—ã¾ã™ã€‚

### ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã®æ´»ç”¨

ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ã€`return_offsets_mapping=True`ã‚’æ¸¡ã—ã¾ã™ï¼š

```python
inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)
inputs.data.keys()
```

**å®Ÿè¡Œçµæœ:**
```
dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])
```

`overflow_to_sample_mapping`ã¯ã€å„ç‰¹å¾´ãŒã©ã®ä¾‹ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸã‹ã‚’ç¤ºã—ã¾ã™ï¼š

```python
inputs["overflow_to_sample_mapping"]
```

**å®Ÿè¡Œçµæœ:**
```
[0, 0, 0]
```

è¤‡æ•°ã®ä¾‹ã‚’tokenizeã™ã‚‹ã¨ã€ã“ã®æƒ…å ±ãŒã‚ˆã‚Šæœ‰ç”¨ã«ãªã‚Šã¾ã™ï¼š

```python
inputs = tokenizer(
    raw_datasets["train"][2:6]["question"],
    raw_datasets["train"][2:6]["context"],
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)

print(f"4ã¤ã®ä¾‹ã‹ã‚‰{len(inputs['input_ids'])}å€‹ã®ç‰¹å¾´ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
print(f"å„ç‰¹å¾´ã®å…ƒã®ä¾‹: {inputs['overflow_to_sample_mapping']}")
```

**å®Ÿè¡Œçµæœ:**
```
4ã¤ã®ä¾‹ã‹ã‚‰15å€‹ã®ç‰¹å¾´ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚
å„ç‰¹å¾´ã®å…ƒã®ä¾‹: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3]
```

### ãƒ©ãƒ™ãƒ«ã®ç”Ÿæˆ

é©åˆ‡ãªãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€æ–‡è„ˆå†…ã§ã®ç­”ãˆã®ä½ç½®ã‚’ç‰¹å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```python
answers = raw_datasets["train"][2:6]["answers"]
start_positions = []
end_positions = []

for i, offset in enumerate(inputs["offset_mapping"]):
    sample_idx = inputs["overflow_to_sample_mapping"][i]
    answer = answers[sample_idx]
    start_char = answer["answer_start"][0]
    end_char = answer["answer_start"][0] + len(answer["text"][0])
    sequence_ids = inputs.sequence_ids(i)

    # æ–‡è„ˆã®é–‹å§‹ã¨çµ‚äº†ã‚’è¦‹ã¤ã‘ã‚‹
    idx = 0
    while sequence_ids[idx] != 1:
        idx += 1
    context_start = idx
    while sequence_ids[idx] == 1:
        idx += 1
    context_end = idx - 1

    # ç­”ãˆãŒæ–‡è„ˆå†…ã«å®Œå…¨ã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ©ãƒ™ãƒ«ã¯(0, 0)
    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
        start_positions.append(0)
        end_positions.append(0)
    else:
        # ãã†ã§ãªã‘ã‚Œã°ã€é–‹å§‹ã¨çµ‚äº†ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®
        idx = context_start
        while idx <= context_end and offset[idx][0] <= start_char:
            idx += 1
        start_positions.append(idx - 1)

        idx = context_end
        while idx >= context_start and offset[idx][1] >= end_char:
            idx -= 1
        end_positions.append(idx + 1)

start_positions, end_positions
```

**å®Ÿè¡Œçµæœ:**
```
([0, 0, 80, 49, 54, 19, 0, 0, 74, 37, 0, 88, 53, 18, 0],
 [0, 0, 80, 49, 56, 21, 0, 0, 75, 38, 0, 91, 56, 21, 0])
```

çµæœã‚’æ¤œè¨¼ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
idx = 2
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

start = start_positions[idx]
end = end_positions[idx]
labeled_answer = tokenizer.decode(inputs["input_ids"][idx][start : end + 1])

print(f"ç†è«–ä¸Šã®ç­”ãˆ: {answer}, ãƒ©ãƒ™ãƒ«ã‹ã‚‰: {labeled_answer}")
```

**å®Ÿè¡Œçµæœ:**
```
ç†è«–ä¸Šã®ç­”ãˆ: 2003, ãƒ©ãƒ™ãƒ«ã‹ã‚‰: 2003
```

### å‰å‡¦ç†é–¢æ•°ã®å®Ÿè£…

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«é©ç”¨ã™ã‚‹å‰å‡¦ç†é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ï¼š

```python
max_length = 384
stride = 128

def preprocess_training_example(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length"
    )

    offset_mapping = inputs.pop("offset_mapping")
    sample_map = inputs.pop("overflow_to_sample_mapping")
    answers = examples["answers"]
    start_positions = []
    end_positions = []

    for i, offset in enumerate(offset_mapping):
        sample_idx = sample_map[i]
        answer = answers[sample_idx]
        # ç©ºã®ç­”ãˆã‚’ãƒã‚§ãƒƒã‚¯
        if (not answer or 
            not answer.get("answer_start") or 
            not answer.get("text") or
            len(answer["answer_start"]) == 0 or 
            len(answer["text"]) == 0):
            start_positions.append(0)
            end_positions.append(0)
            continue
        start_char = answer["answer_start"][0]
        end_char = answer["answer_start"][0] + len(answer["text"][0])
        sequence_ids = inputs.sequence_ids(i)

        # æ–‡è„ˆã®é–‹å§‹ã¨çµ‚äº†ã‚’è¦‹ã¤ã‘ã‚‹
        idx = 0
        while sequence_ids[idx] != 1:
            idx += 1
        context_start = idx
        while sequence_ids[idx] ==1:
            idx += 1
        context_end = idx - 1

        # ç­”ãˆãŒæ–‡è„ˆå†…ã«å®Œå…¨ã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ©ãƒ™ãƒ«ã¯(0, 0)
        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
            start_positions.append(0)
            end_positions.append(0)
        else:
            # ãã†ã§ãªã‘ã‚Œã°ã€é–‹å§‹ã¨çµ‚äº†ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®
            idx = context_start
            while idx <= context_end and offset[idx][0] <= start_char:
                idx += 1
            start_positions.append(idx - 1)

            idx = context_end
            while idx >= context_start and offset[idx][1] >= end_char:
                idx -= 1
            end_positions.append(idx + 1)
    
    inputs["start_positions"] = start_positions
    inputs["end_positions"] = end_positions

    return inputs
```

ã“ã®é–¢æ•°ã‚’è¨“ç·´ã‚»ãƒƒãƒˆå…¨ä½“ã«é©ç”¨ã—ã¾ã™ï¼š

```python
train_dataset = raw_datasets["train"].map(
    preprocess_training_example,
    batched=True,
    remove_columns=raw_datasets["train"].column_names
)
len(raw_datasets["train"]), len(train_dataset)
```

**å®Ÿè¡Œçµæœ:**
```
(130319, 132079)
```

```python
print(train_dataset.column_names)
```

**å®Ÿè¡Œçµæœ:**
```
['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']
```

## æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†

æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¯ã€ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹å¿…è¦ãŒãªã„ãŸã‚å°‘ã—ç°¡å˜ã§ã™ã€‚é‡è¦ãªã®ã¯ã€ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã¨å„ç‰¹å¾´ã‚’å…ƒã®ä¾‹ã«ãƒãƒƒãƒã•ã›ã‚‹æ–¹æ³•ã‚’ä¿å­˜ã™ã‚‹ã“ã¨ã§ã™ï¼š

```python
def preprocess_validation_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    sample_map = inputs.pop("overflow_to_sample_mapping")
    example_ids = []

    for i in range(len(inputs["input_ids"])):
        sample_idx = sample_map[i]
        example_ids.append(examples["id"][sample_idx])

        sequence_ids = inputs.sequence_ids(i)
        offset = inputs["offset_mapping"][i]
        inputs["offset_mapping"][i] = [
            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)
        ]

    inputs["example_id"] = example_ids
    return inputs
```

æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«é©ç”¨ã—ã¾ã™ï¼š

```python
validation_dataset = raw_datasets["validation"].map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)
len(raw_datasets["validation"]), len(validation_dataset)
```

**å®Ÿè¡Œçµæœ:**
```
(11873, 12199)
```

## TrainerAPIã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

### å¾Œå‡¦ç†é–¢æ•°ã®å®Ÿè£…

ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å…ƒã®ä¾‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒ‘ãƒ³ã«å¤‰æ›ã™ã‚‹å¾Œå‡¦ç†é–¢æ•°ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```python
small_eval_set = raw_datasets["validation"].select(range(100))
trained_checkpoint = "distilbert-base-cased-distilled-squad"

tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)
eval_set = small_eval_set.map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)

eval_set
```

**å®Ÿè¡Œçµæœ:**
```
Dataset({
    features: ['input_ids', 'attention_mask', 'offset_mapping', 'example_id'],
    num_rows: 107
})
```

tokenizerã‚’å…ƒã«æˆ»ã—ã¾ã™ï¼š

```python
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’ç”Ÿæˆã—ã¾ã™ï¼š

```python
import torch
from transformers import AutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("torch")
print(eval_set_for_model)

device = torch.device("mps") if torch.mps.is_available() else torch.device("cpu")
batch = {k: eval_set_for_model[:][k].to(device) for k in eval_set_for_model.column_names}
trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(device)

with torch.no_grad():
    outputs = trained_model(**batch)
```

**å®Ÿè¡Œçµæœ:**
```
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 107
})
```

logitsã‚’NumPyé…åˆ—ã«å¤‰æ›ã—ã¾ã™ï¼š

```python
start_logits = outputs.start_logits.cpu().numpy()
end_logits = outputs.end_logits.cpu().numpy()
```

ä¾‹ã¨ç‰¹å¾´ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆã—ã¾ã™ï¼š

```python
import collections

example_to_features = collections.defaultdict(list)
for idx, feature in enumerate(eval_set):
    example_to_features[feature["example_id"]].append(idx)
```

æœ€é©ãªç­”ãˆã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã—ã¾ã™ï¼ˆSQuAD 2.0å¯¾å¿œç‰ˆï¼‰ï¼š

```python
import numpy as np

n_best = 20
max_answer_length = 30
predicted_answers = []

for example in small_eval_set:
    example_id = example["id"]
    context = example["context"]
    answers = []
    null_scores = []  # å„ç‰¹å¾´ã®null scoreï¼ˆCLSãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ã‚³ã‚¢ï¼‰

    for feature_index in example_to_features[example_id]:
        start_logit = start_logits[feature_index]
        end_logit = end_logits[feature_index]
        offsets = eval_set["offset_mapping"][feature_index]

        # Null scoreï¼ˆç­”ãˆãªã—ã®ä¿¡é ¼åº¦ï¼‰ã‚’è¨ˆç®—
        null_score = start_logit[0] + end_logit[0]
        null_scores.append(null_score)

        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()

        for start_index in start_indexes:
            for end_index in end_indexes:
                # æ–‡è„ˆå†…ã«å®Œå…¨ã«å«ã¾ã‚Œã¦ã„ãªã„ç­”ãˆã‚’ã‚¹ã‚­ãƒƒãƒ—
                if offsets[start_index] is None or offsets[end_index] is None:
                    continue
                # é•·ã•ãŒä¸æ­£ãªç­”ãˆã‚’ã‚¹ã‚­ãƒƒãƒ—
                if (
                    end_index < start_index
                    or end_index - start_index + 1 > max_answer_length
                ):
                    continue

                answer_score = start_logit[start_index] + end_logit[end_index]
                answers.append(
                    {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": answer_score,
                    }
                )

    # SQuAD 2.0ã®é‡è¦ãªå‡¦ç†ï¼šç­”ãˆãªã—åˆ¤å®š
    min_null_score = min(null_scores) if null_scores else 0.0

    if answers:
        best_answer = max(answers, key=lambda x: x["logit_score"])
        # ç­”ãˆã‚ã‚Šã‚¹ã‚³ã‚¢ã¨nullã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒ
        score_diff = best_answer["logit_score"] - min_null_score

        if score_diff > 0.0:  # é–¾å€¤ï¼š0.0ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
            # ç­”ãˆã‚ã‚Š
            predicted_answers.append({
                "id": example_id,
                "prediction_text": best_answer["text"],
                "no_answer_probability": 0.0
            })
        else:
            # ç­”ãˆãªã—
            predicted_answers.append({
                "id": example_id,
                "prediction_text": "",
                "no_answer_probability": 1.0
            })
    else:
        # å€™è£œãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç­”ãˆãªã—
        predicted_answers.append({
            "id": example_id,
            "prediction_text": "",
            "no_answer_probability": 1.0
        })
```

è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã™ï¼š

```python
import evaluate

metric = evaluate.load("squad_v2")
```

ç†è«–çš„ãªç­”ãˆã®å½¢å¼ã‚’æº–å‚™ã—ã¾ã™ï¼š

```python
theoretical_answers = [
    {"id": ex["id"], "answers": ex["answers"]} for ex in small_eval_set
]
```

äºˆæ¸¬çµæœã‚’ç¢ºèªã—ã¾ã™ï¼š

```python
print(predicted_answers[1])
print(theoretical_answers[1])
```

**å®Ÿè¡Œçµæœ:**
```
{'id': '56ddde6b9a695914005b9629', 'prediction_text': '10th and 11th centuries', 'no_answer_probability': 0.0}
{'id': '56ddde6b9a695914005b9629', 'answers': {'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries', '10th and 11th centuries'], 'answer_start': [94, 87, 94, 94]}}
```

è©•ä¾¡é–¢æ•°ã‚’å®Ÿè£…ã—ã¾ã™ï¼ˆSQuAD 2.0å¯¾å¿œä¿®æ­£ç‰ˆï¼‰ï¼š

```python
def evaluate_squad_format():
    """SQuAD 2.0æ¨™æº–å½¢å¼ã§è©•ä¾¡ï¼ˆç­”ãˆãªã—å¯¾å¿œï¼‰"""

    # æ­£ã—ã„å½¢å¼ã«å¤‰æ›
    formatted_predictions = []
    formatted_references = []

    for pred, ref in zip(predicted_answers, theoretical_answers):
        # äºˆæ¸¬å½¢å¼ï¼ˆä¿®æ­£ç‰ˆï¼šno_answer_probabilityã‚’æ­£ã—ãè¨­å®šï¼‰
        formatted_predictions.append({
            "id": pred["id"],
            "prediction_text": pred["prediction_text"],
            "no_answer_probability": pred["no_answer_probability"]  # ä¿®æ­£ï¼šå‹•çš„ã«è¨­å®š
        })

        # å‚è€ƒå½¢å¼
        formatted_references.append({
            "id": ref["id"],
            "answers": ref["answers"]
        })

    # SQuADæŒ‡æ¨™ã‚’ä½¿ç”¨
    results = metric.compute(
        predictions=formatted_predictions,
        references=formatted_references
    )

    return results

# è©•ä¾¡ã‚’å®Ÿè¡Œ
try:
    results = evaluate_squad_format()
    print("SQuADè©•ä¾¡çµæœ:")
    for key, value in results.items():
        print(f"  {key}: {value:.4f}")
except Exception as e:
    print(f"SQuADè©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼: {e}")
```

**å®Ÿè¡Œçµæœ:**
```
SQuADè©•ä¾¡çµæœ:
  exact: 68.0000
  f1: 69.7262
  total: 100.0000
  HasAns_exact: 73.3333
  HasAns_f1: 77.1693
  HasAns_total: 45.0000
  NoAns_exact: 63.6364
  NoAns_f1: 63.6364
  NoAns_total: 55.0000
  best_exact: 68.0000
  best_exact_thresh: 0.0000
  best_f1: 69.7262
  best_f1_thresh: 0.0000
```

å®Œå…¨ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```python
from tqdm.auto import tqdm
import numpy as np

def find_optimal_threshold(start_logits, end_logits, features, examples):
    """æœ€é©ãªé–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹é–¢æ•°"""
    best_f1 = 0
    best_threshold = 0

    for threshold in np.arange(-5.0, 5.0, 0.5):
        metrics = compute_metrics(
            start_logits, end_logits, features, examples,
            null_score_diff_threshold=threshold
        )
        if metrics['f1'] > best_f1:
            best_f1 = metrics['f1']
            best_threshold = threshold

    return best_threshold

def compute_metrics(start_logits, end_logits, features, examples,
                           null_score_diff_threshold=0.0):
    """SQuAD 2.0å¯¾å¿œã€ç­”ãˆãªã—æ¤œå‡ºã‚’ã‚µãƒãƒ¼ãƒˆ"""
    
    example_to_features = collections.defaultdict(list)
    for idx, feature in enumerate(features):
        example_to_features[feature["example_id"]].append(idx)
    
    predicted_answers = []
    
    for example in tqdm(examples):
        example_id = example["id"]
        context = example["context"]
        answers = []
        
        # å…¨ç‰¹å¾´ã®null score (CLS token score)ã‚’åé›†
        null_scores = []

        # ã“ã®ä¾‹ã«é–¢é€£ã™ã‚‹å…¨ç‰¹å¾´ã‚’ãƒ«ãƒ¼ãƒ—å‡¦ç†
        for feature_index in example_to_features[example_id]:
            start_logit = start_logits[feature_index]
            end_logit = end_logits[feature_index]
            offsets = features[feature_index]["offset_mapping"]
            
            # null score (CLSãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ã‚³ã‚¢)ã‚’è¨ˆç®—
            null_score = start_logit[0] + end_logit[0]
            null_scores.append(null_score)
            
            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
            
            for start_index in start_indexes:
                for end_index in end_indexes:
                    # æ–‡è„ˆå†…ã«ãªã„ç­”ãˆã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if offsets[start_index] is None or offsets[end_index] is None:
                        continue
                    # é•·ã•ãŒä¸é©åˆ‡ãªç­”ãˆã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if (
                        end_index < start_index
                        or end_index - start_index + 1 > max_answer_length
                    ):
                        continue
                    
                    answer = {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                        "feature_index": feature_index
                    }
                    answers.append(answer)
        
        # æœ€é©ãªnull scoreã‚’è¨ˆç®—
        min_null_score = min(null_scores) if null_scores else 0.0

        # æœ€é©ãªç­”ãˆã‚’é¸æŠ
        if len(answers) > 0:
            best_answer = max(answers, key=lambda x: x["logit_score"])
            
            # SQuAD 2.0ã®é‡è¦ãªç‚¹ï¼šæœ€é©ç­”æ¡ˆã‚¹ã‚³ã‚¢ã¨nullã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒ
            score_diff = best_answer["logit_score"] - min_null_score

            if score_diff > null_score_diff_threshold:
                # ç­”ãˆã‚ã‚Š
                predicted_answers.append({
                    "id": example_id, 
                    "prediction_text": best_answer["text"],
                    "no_answer_probability": 0.0
                })
            else:
                # ç­”ãˆãªã—
                predicted_answers.append({
                    "id": example_id, 
                    "prediction_text": "",
                    "no_answer_probability": 1.0
                })
        else:
            # å€™è£œç­”æ¡ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ç¢ºå®Ÿã«ç­”ãˆãªã—
            predicted_answers.append({
                "id": example_id, 
                "prediction_text": "",
                "no_answer_probability": 1.0
            })
    
    theoretical_answers = [{"id": ex["id"], "answers": ex["answers"]} for ex in examples]
    return metric.compute(predictions=predicted_answers, references=theoretical_answers)
```

è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š

```python
compute_metrics(start_logits, end_logits, eval_set, small_eval_set)
```

**å®Ÿè¡Œçµæœ:**
```
{'exact': 68.0,
 'f1': 69.72619047619048,
 'total': 100,
 'HasAns_exact': 73.33333333333333,
 'HasAns_f1': 77.16931216931216,
 'HasAns_total': 45,
 'NoAns_exact': 63.63636363636363,
 'NoAns_f1': 63.63636363636363,
 'NoAns_total': 55,
 'best_exact': 68.0,
 'best_exact_thresh': 0.0,
 'best_f1': 69.72619047619048,
 'best_f1_thresh': 0.0}
```

### ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

è³ªå•å¿œç­”ç”¨ã®BERTãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼š

```python
from transformers import AutoModelForQuestionAnswering

model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

**å®Ÿè¡Œçµæœ:**
```
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

è¨“ç·´å¼•æ•°ã‚’è¨­å®šã—ã¾ã™ï¼š

```python
from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-squad",
    eval_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=False,
    dataloader_pin_memory=False,
)
```

Trainerã‚¯ãƒ©ã‚¹ã§è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™ï¼š

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=validation_dataset,
    processing_class=tokenizer,
)

print(next(model.parameters()).device) 
```

**å®Ÿè¡Œçµæœ:**
```
mps:0
```

```python
# trainer.train()
```

## ã‚«ã‚¹ã‚¿ãƒ è¨“ç·´ãƒ«ãƒ¼ãƒ—

å®Œå…¨ãªè¨“ç·´ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…ã—ã¦ã€å¿…è¦ãªéƒ¨åˆ†ã‚’ç°¡å˜ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚

### è¨“ç·´ã®æº–å‚™

ã¾ãšã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰DataLoaderã‚’æ§‹ç¯‰ã—ã¾ã™ï¼š

```python
from torch.utils.data import DataLoader
from transformers import default_data_collator

train_dataset.set_format("torch")
validation_set = validation_dataset.remove_columns(["example_id", "offset_mapping"])
validation_set.set_format("torch")

train_dataloader = DataLoader(
    train_dataset,
    shuffle=True,
    collate_fn=default_data_collator,
    batch_size=16,  # é«˜é€ŸåŒ–ã®ãŸã‚å€å¢—
)
eval_dataloader = DataLoader(
    validation_set, collate_fn=default_data_collator, batch_size=16  # è©•ä¾¡ã‚‚é«˜é€ŸåŒ–
)
```

ãƒ¢ãƒ‡ãƒ«ã‚’å†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ï¼š

```python
model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’è¨­å®šã—ã¾ã™ï¼š

```python
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

Acceleratorã‚’ä½¿ç”¨ã—ã¦åˆ†æ•£è¨“ç·´ã‚’æº–å‚™ã—ã¾ã™ï¼š

```python
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’è¨­å®šã—ã¾ã™ï¼š

```python
from transformers import get_scheduler

num_train_epochs = 1  # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

```python
output_dir = "bert-finetuned-squad-accelerate"
```

### è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ

å®Œå…¨ãªè¨“ç·´ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

```python
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))
print(next(model.parameters()).device)
for epoch in range(num_train_epochs):
    # è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º
    model.train()
    for step, batch in enumerate(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # è©•ä¾¡ãƒ•ã‚§ãƒ¼ã‚º
    model.eval()
    start_logits = []
    end_logits = []
    accelerator.print("è©•ä¾¡ä¸­!")
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            outputs = model(**batch)

        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())
        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())

    start_logits = np.concatenate(start_logits)
    end_logits = np.concatenate(end_logits)
    start_logits = start_logits[: len(validation_dataset)]
    end_logits = end_logits[: len(validation_dataset)]

    # æœ€é©é–¾å€¤ã‚’è¨ˆç®—ã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è©•ä¾¡
    best_threshold = find_optimal_threshold(
        start_logits, end_logits, validation_dataset, raw_datasets["validation"]
    )

    metrics = compute_metrics(
        start_logits, end_logits, validation_dataset, raw_datasets["validation"],
        null_score_diff_threshold=best_threshold
    )
    print(f"ã‚¨ãƒãƒƒã‚¯ {epoch} (æœ€é©é–¾å€¤: {best_threshold:.2f}):", metrics)

    # ä¿å­˜ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
```

**å®Ÿè¡Œçµæœ:**
```
ã‚¨ãƒãƒƒã‚¯ 0 (æœ€é©é–¾å€¤: 4.00): {'exact': 73.07335972374294, 'f1': 76.27284417400911, 'total': 11873, 'HasAns_exact': 66.31241565452092, 'HasAns_f1': 72.72055986471157, 'HasAns_total': 5928, 'NoAns_exact': 79.81497056349873, 'NoAns_f1': 79.81497056349873, 'NoAns_total': 5945, 'best_exact': 73.07335972374294, 'best_exact_thresh': 0.0, 'best_f1': 76.27284417400917, 'best_f1_thresh': 0.0}
```

## ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
from transformers import pipeline

# SQuAD 2.0å¯¾å¿œã®Pipelineè¨­å®š
model_checkpoint = "bert-finetuned-squad-accelerate"
question_answerer = pipeline(
    "question-answering",
    model=model_checkpoint,
    handle_impossible_answer=True,  # é‡è¦ï¼šSQuAD 2.0ã‚µãƒãƒ¼ãƒˆ
    max_answer_len=30,
    max_seq_len=384,
    doc_stride=128
)

context = """
ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration
between them. It's straightforward to train your models with one before loading them for inference with the other.
"""
question = "Which deep learning libraries back ğŸ¤— Transformers?"

# åŸºæœ¬çš„ãªæ¨è«–
result = question_answerer(question=question, context=context)
print(f"ç­”ãˆ: {result['answer']}")
print(f"ã‚¹ã‚³ã‚¢: {result['score']:.4f}")
print(f"é–‹å§‹ä½ç½®: {result['start']}")
print(f"çµ‚äº†ä½ç½®: {result['end']}")

# è¤‡æ•°ã®å€™è£œã‚’å–å¾—ï¼ˆã‚ˆã‚Šè©³ç´°ãªåˆ†æï¼‰
results = question_answerer(
    question=question,
    context=context,
    top_k=3  # ãƒˆãƒƒãƒ—3ã®å€™è£œã‚’å–å¾—
)
print("\nãƒˆãƒƒãƒ—3ã®å€™è£œ:")
for i, res in enumerate(results):
    print(f"{i+1}. {res['answer']} (ã‚¹ã‚³ã‚¢: {res['score']:.4f})")
```

**å®Ÿè¡Œçµæœ:**
```
ç­”ãˆ: Jax, PyTorch and TensorFlow
ã‚¹ã‚³ã‚¢: 0.8929
é–‹å§‹ä½ç½®: 78
çµ‚äº†ä½ç½®: 105

ãƒˆãƒƒãƒ—3ã®å€™è£œ:
1. Jax, PyTorch and TensorFlow (ã‚¹ã‚³ã‚¢: 0.8929)
2. Jax, PyTorch and TensorFlow â€” (ã‚¹ã‚³ã‚¢: 0.0314)
3.  (ã‚¹ã‚³ã‚¢: 0.0012)
```

## è©•ä¾¡æŒ‡æ¨™ã®è§£èª¬

### Exact Match (EM)
äºˆæ¸¬ã—ãŸç­”ãˆãŒæ­£è§£ã¨å®Œå…¨ã«ä¸€è‡´ã™ã‚‹å‰²åˆã§ã™ã€‚å¤§æ–‡å­—å°æ–‡å­—ã‚„å¥èª­ç‚¹ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚

### F1ã‚¹ã‚³ã‚¢
äºˆæ¸¬ã¨æ­£è§£ã®é–“ã§ã®å˜èªãƒ¬ãƒ™ãƒ«ã®é‡è¤‡ã‚’æ¸¬å®šã—ã¾ã™ã€‚å„äºˆæ¸¬-æ­£è§£ãƒšã‚¢ã«å¯¾ã—ã¦F1ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€æœ€å¤§å€¤ã‚’å–ã‚Šã¾ã™ã€‚

### SQuAD 2.0ç‰¹æœ‰ã®æŒ‡æ¨™
- **HasAns**: ç­”ãˆãŒã‚ã‚‹è³ªå•ã®ã¿ã®æ€§èƒ½
- **NoAns**: ç­”ãˆãŒãªã„è³ªå•ã®ã¿ã®æ€§èƒ½
- **best_exact/best_f1**: æœ€é©ãªé–¾å€¤ã§ã®æ€§èƒ½

## ã¾ã¨ã‚

ã“ã®è¨˜äº‹ã§ã¯ã€BERTãƒ¢ãƒ‡ãƒ«ã‚’SQuADãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã—ãŸã€‚ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

1. **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: é•·ã„æ–‡è„ˆã‚’é©åˆ‡ã«åˆ†å‰²ã—ã€ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ´»ç”¨ã—ã¦ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ
2. **ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**: TrainerAPIã¨ã‚«ã‚¹ã‚¿ãƒ è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®ä¸¡æ–¹ã‚’å®Ÿè£…
3. **è©•ä¾¡**: SQuAD 2.0ã®è¤‡é›‘ãªè©•ä¾¡æŒ‡æ¨™ã‚’ç†è§£ã—ã€ç­”ãˆã®ãªã„è³ªå•ã¸ã®å¯¾å¿œ
4. **å¾Œå‡¦ç†**: ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒ‘ãƒ³ã«å¤‰æ›ã™ã‚‹åŠ¹ç‡çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

æœ€çµ‚çš„ã«å¾—ã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ç´„76%ã®F1ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€å®Ÿç”¨çš„ãªè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦æ´»ç”¨ã§ãã¾ã™ã€‚

## å‚è€ƒè³‡æ–™

- [SQuAD Dataset](https://rajpurkar.github.io/SQuAD-explorer/)
- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers)
- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)
- [SQuAD 2.0 Paper](https://arxiv.org/abs/1806.03822)